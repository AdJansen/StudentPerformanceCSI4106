{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FN score he got was around 90% in macro, more then 80\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "# we can use the LabelEncoder to encode the gender feature\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, cross_val_score, GridSearchCV, cross_validate\n",
    "\n",
    "# importing two different imputation methods that take into consideration all the features when predicting the missing values\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#multiclass imports\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.dummy import DummyClassifier #Will identify the maority calss base line, model needs to do better then the baseline\n",
    "\n",
    "# oversample the minority class using SMOTE\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "# to reduce randomness then you put the seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Data shape: \n",
      "(145, 31)\n",
      "\n",
      "Data size: \n",
      "4495\n",
      "\n",
      "Data ndim: \n",
      "2\n",
      "\n",
      "_____________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/student_prediction.csv\")\n",
    "\n",
    "df.rename(columns = {'KIDS':'PARENT_STATUS'}) #There is a column name error in the data noted in the Kaggle description, this fixes it.\n",
    "df = df.drop([\"STUDENTID\", \"COURSE ID\"], axis=1)\n",
    "\n",
    "gathered_df = pd.read_csv(\"./data/Higher Education Students Performance Evaluation.csv\")\n",
    "gathered_df.rename(columns = {'KIDS':'PARENT_STATUS'})\n",
    "res = list(set(df).difference(set(gathered_df)))\n",
    "print(res)\n",
    "#df = pd.concat([df, gathered_df], axis=0)\n",
    "print(f\"Data shape: \\n{df.shape}\\n\")\n",
    "print(f\"Data size: \\n{df.size}\\n\")\n",
    "print(f\"Data ndim: \\n{df.ndim}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampled Data shape: \n",
      "(280, 31)\n",
      "\n",
      "Oversampled Data size: \n",
      "8680\n",
      "\n",
      "Oversampled Data ndim: \n",
      "2\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "New Class Distribution: Counter({1: 35, 2: 35, 5: 35, 0: 35, 3: 35, 4: 35, 7: 35, 6: 35})\n",
      "_____________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oversample = SMOTE()\n",
    "x_over, y_over = oversample.fit_resample(df.drop([\"GRADE\"], axis=1), df.drop(df.columns[0:-1],axis=1))\n",
    "df = pd.concat([x_over, y_over], axis=1)\n",
    "\n",
    "# print the dimensionality of the oversampled training dataset (0.5)\n",
    "print(f\"Oversampled Data shape: \\n{df.shape}\\n\")\n",
    "print(f\"Oversampled Data size: \\n{df.size}\\n\")\n",
    "print(f\"Oversampled Data ndim: \\n{df.ndim}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "\n",
    "\n",
    "# print the new class distribution using the Counter (1)\n",
    "print(f\"New Class Distribution: {Counter(df['GRADE'])}\")\n",
    "print(\"_____________________________________________\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data shape: \n",
      "     AGE  GENDER  HS_TYPE  SCHOLARSHIP  WORK  ACTIVITY  PARTNER  SALARY  \\\n",
      "86     2       2        2            4     2         2        2       1   \n",
      "137    1       1        1            5     2         1        2       1   \n",
      "184    2       2        2            4     1         2        2       1   \n",
      "5      2       2        2            3     2         2        2       2   \n",
      "124    1       1        2            4     1         1        1       1   \n",
      "..   ...     ...      ...          ...   ...       ...      ...     ...   \n",
      "188    1       2        2            3     1         2        1       4   \n",
      "71     1       1        3            4     2         2        2       1   \n",
      "106    1       2        2            4     2         1        2       1   \n",
      "270    1       2        2            4     2         1        1       1   \n",
      "102    1       2        2            3     2         2        1       1   \n",
      "\n",
      "     TRANSPORT  LIVING  ...  ATTEND  PREP_STUDY  PREP_EXAM  NOTES  LISTENS  \\\n",
      "86           4       2  ...       1           1          1      3        2   \n",
      "137          1       1  ...       1           1          1      3        1   \n",
      "184          1       1  ...       1           1          1      3        2   \n",
      "5            1       1  ...       1           1          1      1        2   \n",
      "124          1       3  ...       1           2          2      3        3   \n",
      "..         ...     ...  ...     ...         ...        ...    ...      ...   \n",
      "188          1       1  ...       1           1          1      1        2   \n",
      "71           1       3  ...       1           1          1      2        3   \n",
      "106          1       2  ...       1           3          2      2        2   \n",
      "270          1       2  ...       1           1          1      3        2   \n",
      "102          1       2  ...       1           1          1      3        1   \n",
      "\n",
      "     LIKES_DISCUSS  CLASSROOM  CUML_GPA  EXP_GPA  GRADE  \n",
      "86               3          2         5        4      5  \n",
      "137              3          1         2        4      2  \n",
      "184              2          1         4        3      3  \n",
      "5                1          2         4        4      2  \n",
      "124              2          1         3        3      3  \n",
      "..             ...        ...       ...      ...    ...  \n",
      "188              2          1         4        3      3  \n",
      "71               3          3         2        2      6  \n",
      "106              2          1         4        4      7  \n",
      "270              3          2         2        3      7  \n",
      "102              2          1         3        4      7  \n",
      "\n",
      "[224 rows x 31 columns]\n",
      "\n",
      "Test Data shape: \n",
      "     AGE  GENDER  HS_TYPE  SCHOLARSHIP  WORK  ACTIVITY  PARTNER  SALARY  \\\n",
      "33     2       1        2            3     1         2        1       1   \n",
      "108    2       1        1            5     2         1        2       2   \n",
      "240    1       2        2            3     1         1        2       1   \n",
      "259    1       1        2            4     1         1        2       1   \n",
      "154    1       1        1            3     1         1        1       1   \n",
      "9      2       1        2            3     2         2        1       3   \n",
      "146    1       1        1            3     1         1        1       1   \n",
      "203    1       2        2            4     1         1        2       1   \n",
      "144    1       1        1            5     2         2        2       3   \n",
      "155    1       1        1            4     2         1        1       1   \n",
      "221    1       1        2            1     1         2        1       1   \n",
      "92     1       2        2            3     2         2        2       1   \n",
      "222    2       1        2            3     1         1        1       1   \n",
      "209    1       2        2            2     1         2        1       1   \n",
      "42     2       2        2            3     2         1        2       1   \n",
      "210    2       1        2            3     1         1        1       1   \n",
      "66     2       2        2            3     2         2        1       1   \n",
      "90     2       1        2            3     2         1        1       1   \n",
      "119    2       1        2            4     2         1        2       1   \n",
      "142    1       1        1            4     2         2        2       1   \n",
      "262    1       2        2            3     1         2        1       1   \n",
      "268    1       2        2            3     2         1        1       1   \n",
      "206    2       1        2            3     1         1        2       1   \n",
      "238    2       1        2            4     1         1        1       1   \n",
      "46     2       2        2            3     2         2        1       1   \n",
      "77     1       2        1            2     2         2        1       2   \n",
      "68     2       1        2            4     1         2        2       1   \n",
      "75     1       2        2            4     2         1        2       1   \n",
      "216    2       2        1            2     1         1        2       1   \n",
      "277    1       2        1            2     2         2        1       2   \n",
      "45     1       2        2            3     2         2        1       4   \n",
      "111    1       1        1            5     2         1        2       1   \n",
      "60     2       1        2            3     2         2        2       5   \n",
      "217    2       1        2            3     1         1        1       1   \n",
      "143    2       1        2            4     1         1        1       5   \n",
      "30     2       2        2            5     1         1        1       1   \n",
      "22     2       2        2            3     1         2        1       1   \n",
      "24     2       2        2            3     2         2        2       2   \n",
      "127    1       1        2            4     2         2        2       1   \n",
      "176    1       2        2            3     1         2        1       3   \n",
      "79     2       2        2            4     2         2        2       1   \n",
      "264    1       2        1            3     2         1        1       1   \n",
      "237    2       1        2            4     2         2        1       1   \n",
      "120    2       1        1            3     1         1        1       2   \n",
      "196    1       1        1            3     1         1        1       1   \n",
      "245    1       1        2            3     1         1        1       1   \n",
      "168    1       1        1            4     2         1        1       1   \n",
      "6      1       2        2            4     2         2        2       1   \n",
      "239    2       1        2            3     1         2        1       1   \n",
      "73     2       2        2            4     2         2        2       1   \n",
      "84     3       2        3            3     1         2        1       3   \n",
      "56     2       2        2            3     2         1        2       1   \n",
      "25     2       2        2            3     2         2        1       1   \n",
      "97     1       2        2            4     1         2        2       1   \n",
      "147    1       1        1            4     1         2        1       1   \n",
      "19     1       2        1            3     2         2        1       2   \n",
      "\n",
      "     TRANSPORT  LIVING  ...  ATTEND  PREP_STUDY  PREP_EXAM  NOTES  LISTENS  \\\n",
      "33           1       1  ...       1           1          1      1        3   \n",
      "108          2       1  ...       2           1          1      2        3   \n",
      "240          1       2  ...       1           1          1      2        2   \n",
      "259          1       3  ...       1           1          1      2        3   \n",
      "154          1       1  ...       1           1          1      2        2   \n",
      "9            4       2  ...       2           1          1      2        2   \n",
      "146          1       2  ...       1           2          1      2        2   \n",
      "203          1       1  ...       1           1          1      3        2   \n",
      "144          1       1  ...       1           2          1      3        2   \n",
      "155          2       1  ...       1           1          1      2        2   \n",
      "221          1       1  ...       1           1          1      2        3   \n",
      "92           1       1  ...       1           1          1      3        2   \n",
      "222          1       2  ...       1           1          1      2        1   \n",
      "209          1       1  ...       1           1          1      3        1   \n",
      "42           4       2  ...       1           1          1      2        1   \n",
      "210          1       1  ...       1           1          1      2        3   \n",
      "66           1       1  ...       1           1          1      3        2   \n",
      "90           2       3  ...       1           1          1      2        3   \n",
      "119          1       2  ...       1           1          2      2        2   \n",
      "142          1       1  ...       1           1          1      3        3   \n",
      "262          1       1  ...       1           1          1      3        2   \n",
      "268          1       2  ...       1           1          1      2        1   \n",
      "206          1       1  ...       1           1          1      3        2   \n",
      "238          1       1  ...       1           1          1      2        2   \n",
      "46           1       1  ...       1           1          1      2        2   \n",
      "77           2       2  ...       2           3          1      2        2   \n",
      "68           1       1  ...       2           1          1      2        2   \n",
      "75           1       3  ...       1           1          1      2        2   \n",
      "216          1       1  ...       1           1          1      2        1   \n",
      "277          1       2  ...       1           2          1      2        2   \n",
      "45           1       1  ...       1           1          1      2        2   \n",
      "111          1       2  ...       1           1          1      3        1   \n",
      "60           2       1  ...       1           1          1      1        3   \n",
      "217          1       1  ...       1           1          1      2        3   \n",
      "143          2       3  ...       1           2          1      2        1   \n",
      "30           1       2  ...       1           2          1      2        3   \n",
      "22           1       1  ...       1           1          2      3        1   \n",
      "24           1       1  ...       1           1          1      2        1   \n",
      "127          4       3  ...       1           1          1      3        2   \n",
      "176          1       1  ...       2           2          1      2        1   \n",
      "79           1       1  ...       1           1          1      3        3   \n",
      "264          1       1  ...       1           1          1      2        2   \n",
      "237          1       1  ...       1           2          1      2        2   \n",
      "120          2       3  ...       2           2          1      3        3   \n",
      "196          1       1  ...       1           1          1      3        2   \n",
      "245          1       2  ...       1           1          1      2        2   \n",
      "168          3       2  ...       1           1          1      2        2   \n",
      "6            1       3  ...       2           1          1      3        3   \n",
      "239          1       1  ...       1           1          1      2        2   \n",
      "73           1       2  ...       1           1          2      3        2   \n",
      "84           1       2  ...       1           3          3      3        3   \n",
      "56           1       1  ...       1           1          2      3        2   \n",
      "25           1       2  ...       1           1          1      2        1   \n",
      "97           1       3  ...       1           1          1      3        2   \n",
      "147          1       1  ...       1           1          1      2        2   \n",
      "19           2       2  ...       1           1          1      3        2   \n",
      "\n",
      "     LIKES_DISCUSS  CLASSROOM  CUML_GPA  EXP_GPA  GRADE  \n",
      "33               2          2         2        3      2  \n",
      "108              1          2         3        3      6  \n",
      "240              2          1         2        2      6  \n",
      "259              2          2         2        2      6  \n",
      "154              2          2         3        2      0  \n",
      "9                2          2         1        2      0  \n",
      "146              2          1         2        2      0  \n",
      "203              3          2         4        3      4  \n",
      "144              3          1         5        4      3  \n",
      "155              2          2         3        2      0  \n",
      "221              2          2         2        2      4  \n",
      "92               3          3         2        2      7  \n",
      "222              2          1         3        3      5  \n",
      "209              3          2         2        2      4  \n",
      "42               3          1         2        3      1  \n",
      "210              1          1         3        2      4  \n",
      "66               2          3         5        4      5  \n",
      "90               2          3         4        2      6  \n",
      "119              3          1         3        3      2  \n",
      "142              2          1         4        3      1  \n",
      "262              2          3         2        2      7  \n",
      "268              2          1         3        4      7  \n",
      "206              2          1         2        2      4  \n",
      "238              3          2         4        3      5  \n",
      "46               3          1         4        2      5  \n",
      "77               2          2         1        1      7  \n",
      "68               3          2         4        3      5  \n",
      "75               2          2         4        1      7  \n",
      "216              2          1         4        3      4  \n",
      "277              2          1         1        1      7  \n",
      "45               2          1         4        3      3  \n",
      "111              3          3         4        3      2  \n",
      "60               3          1         2        1      2  \n",
      "217              1          1         3        2      4  \n",
      "143              2          1         5        3      4  \n",
      "30               3          3         5        4      5  \n",
      "22               2          3         3        3      3  \n",
      "24               3          2         4        4      2  \n",
      "127              2          1         2        2      1  \n",
      "176              2          1         2        2      2  \n",
      "79               3          2         4        4      3  \n",
      "264              3          1         4        4      7  \n",
      "237              2          1         3        2      5  \n",
      "120              3          2         2        2      1  \n",
      "196              2          2         2        3      3  \n",
      "245              2          1         3        2      6  \n",
      "168              2          1         2        2      0  \n",
      "6                3          3         4        4      5  \n",
      "239              2          2         4        3      5  \n",
      "73               3          1         5        3      6  \n",
      "84               3          3         5        4      7  \n",
      "56               3          3         5        4      5  \n",
      "25               3          2         1        2      3  \n",
      "97               2          1         3        3      6  \n",
      "147              2          2         3        2      0  \n",
      "19               2          3         2        3      3  \n",
      "\n",
      "[56 rows x 31 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "print(f\"Train Data shape: \\n{data_train}\\n\")\n",
    "print(f\"Test Data shape: \\n{data_test}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>HS_TYPE</th>\n",
       "      <th>SCHOLARSHIP</th>\n",
       "      <th>WORK</th>\n",
       "      <th>ACTIVITY</th>\n",
       "      <th>PARTNER</th>\n",
       "      <th>SALARY</th>\n",
       "      <th>TRANSPORT</th>\n",
       "      <th>LIVING</th>\n",
       "      <th>...</th>\n",
       "      <th>ATTEND</th>\n",
       "      <th>PREP_STUDY</th>\n",
       "      <th>PREP_EXAM</th>\n",
       "      <th>NOTES</th>\n",
       "      <th>LISTENS</th>\n",
       "      <th>LIKES_DISCUSS</th>\n",
       "      <th>CLASSROOM</th>\n",
       "      <th>CUML_GPA</th>\n",
       "      <th>EXP_GPA</th>\n",
       "      <th>GRADE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AGE  GENDER  HS_TYPE  SCHOLARSHIP  WORK  ACTIVITY  PARTNER  SALARY  \\\n",
       "0      2       2        3            3     1         2        2       1   \n",
       "1      2       2        3            3     1         2        2       1   \n",
       "2      2       2        2            3     2         2        2       2   \n",
       "3      1       1        1            3     1         2        1       2   \n",
       "4      2       2        1            3     2         2        1       3   \n",
       "..   ...     ...      ...          ...   ...       ...      ...     ...   \n",
       "275    1       2        2            4     1         2        1       1   \n",
       "276    1       2        2            4     2         1        1       1   \n",
       "277    1       2        1            2     2         2        1       2   \n",
       "278    1       2        2            4     2         1        1       1   \n",
       "279    1       2        2            4     2         1        2       1   \n",
       "\n",
       "     TRANSPORT  LIVING  ...  ATTEND  PREP_STUDY  PREP_EXAM  NOTES  LISTENS  \\\n",
       "0            1       1  ...       1           1          1      3        2   \n",
       "1            1       1  ...       1           1          1      3        2   \n",
       "2            4       2  ...       1           1          1      2        2   \n",
       "3            1       2  ...       1           1          2      3        2   \n",
       "4            1       4  ...       1           2          1      2        2   \n",
       "..         ...     ...  ...     ...         ...        ...    ...      ...   \n",
       "275          1       1  ...       1           1          1      3        2   \n",
       "276          1       2  ...       1           1          1      3        2   \n",
       "277          1       2  ...       1           2          1      2        2   \n",
       "278          1       1  ...       1           1          1      3        2   \n",
       "279          1       1  ...       1           2          1      2        2   \n",
       "\n",
       "     LIKES_DISCUSS  CLASSROOM  CUML_GPA  EXP_GPA  GRADE  \n",
       "0                1          2         1        1      1  \n",
       "1                3          2         2        3      1  \n",
       "2                1          1         2        2      1  \n",
       "3                2          1         3        2      1  \n",
       "4                2          1         2        2      1  \n",
       "..             ...        ...       ...      ...    ...  \n",
       "275              2          2         3        3      7  \n",
       "276              2          1         2        3      7  \n",
       "277              2          1         1        1      7  \n",
       "278              3          2         2        3      7  \n",
       "279              2          1         3        3      7  \n",
       "\n",
       "[280 rows x 31 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_train: \n",
      "     GRADE\n",
      "86       5\n",
      "137      2\n",
      "184      3\n",
      "5        2\n",
      "124      3\n",
      "..     ...\n",
      "188      3\n",
      "71       6\n",
      "106      7\n",
      "270      7\n",
      "102      7\n",
      "\n",
      "[224 rows x 1 columns]\n",
      "\n",
      "labels_test: \n",
      "     GRADE\n",
      "33       2\n",
      "108      6\n",
      "240      6\n",
      "259      6\n",
      "154      0\n",
      "9        0\n",
      "146      0\n",
      "203      4\n",
      "144      3\n",
      "155      0\n",
      "221      4\n",
      "92       7\n",
      "222      5\n",
      "209      4\n",
      "42       1\n",
      "210      4\n",
      "66       5\n",
      "90       6\n",
      "119      2\n",
      "142      1\n",
      "262      7\n",
      "268      7\n",
      "206      4\n",
      "238      5\n",
      "46       5\n",
      "77       7\n",
      "68       5\n",
      "75       7\n",
      "216      4\n",
      "277      7\n",
      "45       3\n",
      "111      2\n",
      "60       2\n",
      "217      4\n",
      "143      4\n",
      "30       5\n",
      "22       3\n",
      "24       2\n",
      "127      1\n",
      "176      2\n",
      "79       3\n",
      "264      7\n",
      "237      5\n",
      "120      1\n",
      "196      3\n",
      "245      6\n",
      "168      0\n",
      "6        5\n",
      "239      5\n",
      "73       6\n",
      "84       7\n",
      "56       5\n",
      "25       3\n",
      "97       6\n",
      "147      0\n",
      "19       3\n",
      "\n",
      "features_train: \n",
      "     AGE  GENDER  HS_TYPE  SCHOLARSHIP  WORK  ACTIVITY  PARTNER  SALARY  \\\n",
      "86     2       2        2            4     2         2        2       1   \n",
      "137    1       1        1            5     2         1        2       1   \n",
      "184    2       2        2            4     1         2        2       1   \n",
      "5      2       2        2            3     2         2        2       2   \n",
      "124    1       1        2            4     1         1        1       1   \n",
      "..   ...     ...      ...          ...   ...       ...      ...     ...   \n",
      "188    1       2        2            3     1         2        1       4   \n",
      "71     1       1        3            4     2         2        2       1   \n",
      "106    1       2        2            4     2         1        2       1   \n",
      "270    1       2        2            4     2         1        1       1   \n",
      "102    1       2        2            3     2         2        1       1   \n",
      "\n",
      "     TRANSPORT  LIVING  ...  IMPACT  ATTEND  PREP_STUDY  PREP_EXAM  NOTES  \\\n",
      "86           4       2  ...       1       1           1          1      3   \n",
      "137          1       1  ...       1       1           1          1      3   \n",
      "184          1       1  ...       2       1           1          1      3   \n",
      "5            1       1  ...       1       1           1          1      1   \n",
      "124          1       3  ...       1       1           2          2      3   \n",
      "..         ...     ...  ...     ...     ...         ...        ...    ...   \n",
      "188          1       1  ...       1       1           1          1      1   \n",
      "71           1       3  ...       1       1           1          1      2   \n",
      "106          1       2  ...       1       1           3          2      2   \n",
      "270          1       2  ...       1       1           1          1      3   \n",
      "102          1       2  ...       1       1           1          1      3   \n",
      "\n",
      "     LISTENS  LIKES_DISCUSS  CLASSROOM  CUML_GPA  EXP_GPA  \n",
      "86         2              3          2         5        4  \n",
      "137        1              3          1         2        4  \n",
      "184        2              2          1         4        3  \n",
      "5          2              1          2         4        4  \n",
      "124        3              2          1         3        3  \n",
      "..       ...            ...        ...       ...      ...  \n",
      "188        2              2          1         4        3  \n",
      "71         3              3          3         2        2  \n",
      "106        2              2          1         4        4  \n",
      "270        2              3          2         2        3  \n",
      "102        1              2          1         3        4  \n",
      "\n",
      "[224 rows x 30 columns]\n",
      "\n",
      "lfeatures_test: \n",
      "     AGE  GENDER  HS_TYPE  SCHOLARSHIP  WORK  ACTIVITY  PARTNER  SALARY  \\\n",
      "33     2       1        2            3     1         2        1       1   \n",
      "108    2       1        1            5     2         1        2       2   \n",
      "240    1       2        2            3     1         1        2       1   \n",
      "259    1       1        2            4     1         1        2       1   \n",
      "154    1       1        1            3     1         1        1       1   \n",
      "9      2       1        2            3     2         2        1       3   \n",
      "146    1       1        1            3     1         1        1       1   \n",
      "203    1       2        2            4     1         1        2       1   \n",
      "144    1       1        1            5     2         2        2       3   \n",
      "155    1       1        1            4     2         1        1       1   \n",
      "221    1       1        2            1     1         2        1       1   \n",
      "92     1       2        2            3     2         2        2       1   \n",
      "222    2       1        2            3     1         1        1       1   \n",
      "209    1       2        2            2     1         2        1       1   \n",
      "42     2       2        2            3     2         1        2       1   \n",
      "210    2       1        2            3     1         1        1       1   \n",
      "66     2       2        2            3     2         2        1       1   \n",
      "90     2       1        2            3     2         1        1       1   \n",
      "119    2       1        2            4     2         1        2       1   \n",
      "142    1       1        1            4     2         2        2       1   \n",
      "262    1       2        2            3     1         2        1       1   \n",
      "268    1       2        2            3     2         1        1       1   \n",
      "206    2       1        2            3     1         1        2       1   \n",
      "238    2       1        2            4     1         1        1       1   \n",
      "46     2       2        2            3     2         2        1       1   \n",
      "77     1       2        1            2     2         2        1       2   \n",
      "68     2       1        2            4     1         2        2       1   \n",
      "75     1       2        2            4     2         1        2       1   \n",
      "216    2       2        1            2     1         1        2       1   \n",
      "277    1       2        1            2     2         2        1       2   \n",
      "45     1       2        2            3     2         2        1       4   \n",
      "111    1       1        1            5     2         1        2       1   \n",
      "60     2       1        2            3     2         2        2       5   \n",
      "217    2       1        2            3     1         1        1       1   \n",
      "143    2       1        2            4     1         1        1       5   \n",
      "30     2       2        2            5     1         1        1       1   \n",
      "22     2       2        2            3     1         2        1       1   \n",
      "24     2       2        2            3     2         2        2       2   \n",
      "127    1       1        2            4     2         2        2       1   \n",
      "176    1       2        2            3     1         2        1       3   \n",
      "79     2       2        2            4     2         2        2       1   \n",
      "264    1       2        1            3     2         1        1       1   \n",
      "237    2       1        2            4     2         2        1       1   \n",
      "120    2       1        1            3     1         1        1       2   \n",
      "196    1       1        1            3     1         1        1       1   \n",
      "245    1       1        2            3     1         1        1       1   \n",
      "168    1       1        1            4     2         1        1       1   \n",
      "6      1       2        2            4     2         2        2       1   \n",
      "239    2       1        2            3     1         2        1       1   \n",
      "73     2       2        2            4     2         2        2       1   \n",
      "84     3       2        3            3     1         2        1       3   \n",
      "56     2       2        2            3     2         1        2       1   \n",
      "25     2       2        2            3     2         2        1       1   \n",
      "97     1       2        2            4     1         2        2       1   \n",
      "147    1       1        1            4     1         2        1       1   \n",
      "19     1       2        1            3     2         2        1       2   \n",
      "\n",
      "     TRANSPORT  LIVING  ...  IMPACT  ATTEND  PREP_STUDY  PREP_EXAM  NOTES  \\\n",
      "33           1       1  ...       1       1           1          1      1   \n",
      "108          2       1  ...       1       2           1          1      2   \n",
      "240          1       2  ...       1       1           1          1      2   \n",
      "259          1       3  ...       1       1           1          1      2   \n",
      "154          1       1  ...       1       1           1          1      2   \n",
      "9            4       2  ...       1       2           1          1      2   \n",
      "146          1       2  ...       1       1           2          1      2   \n",
      "203          1       1  ...       1       1           1          1      3   \n",
      "144          1       1  ...       1       1           2          1      3   \n",
      "155          2       1  ...       1       1           1          1      2   \n",
      "221          1       1  ...       1       1           1          1      2   \n",
      "92           1       1  ...       1       1           1          1      3   \n",
      "222          1       2  ...       1       1           1          1      2   \n",
      "209          1       1  ...       1       1           1          1      3   \n",
      "42           4       2  ...       1       1           1          1      2   \n",
      "210          1       1  ...       2       1           1          1      2   \n",
      "66           1       1  ...       1       1           1          1      3   \n",
      "90           2       3  ...       1       1           1          1      2   \n",
      "119          1       2  ...       1       1           1          2      2   \n",
      "142          1       1  ...       1       1           1          1      3   \n",
      "262          1       1  ...       1       1           1          1      3   \n",
      "268          1       2  ...       1       1           1          1      2   \n",
      "206          1       1  ...       1       1           1          1      3   \n",
      "238          1       1  ...       1       1           1          1      2   \n",
      "46           1       1  ...       1       1           1          1      2   \n",
      "77           2       2  ...       1       2           3          1      2   \n",
      "68           1       1  ...       1       2           1          1      2   \n",
      "75           1       3  ...       1       1           1          1      2   \n",
      "216          1       1  ...       1       1           1          1      2   \n",
      "277          1       2  ...       1       1           2          1      2   \n",
      "45           1       1  ...       1       1           1          1      2   \n",
      "111          1       2  ...       2       1           1          1      3   \n",
      "60           2       1  ...       1       1           1          1      1   \n",
      "217          1       1  ...       2       1           1          1      2   \n",
      "143          2       3  ...       1       1           2          1      2   \n",
      "30           1       2  ...       1       1           2          1      2   \n",
      "22           1       1  ...       1       1           1          2      3   \n",
      "24           1       1  ...       1       1           1          1      2   \n",
      "127          4       3  ...       1       1           1          1      3   \n",
      "176          1       1  ...       2       2           2          1      2   \n",
      "79           1       1  ...       3       1           1          1      3   \n",
      "264          1       1  ...       1       1           1          1      2   \n",
      "237          1       1  ...       1       1           2          1      2   \n",
      "120          2       3  ...       1       2           2          1      3   \n",
      "196          1       1  ...       1       1           1          1      3   \n",
      "245          1       2  ...       1       1           1          1      2   \n",
      "168          3       2  ...       1       1           1          1      2   \n",
      "6            1       3  ...       1       2           1          1      3   \n",
      "239          1       1  ...       1       1           1          1      2   \n",
      "73           1       2  ...       1       1           1          2      3   \n",
      "84           1       2  ...       1       1           3          3      3   \n",
      "56           1       1  ...       1       1           1          2      3   \n",
      "25           1       2  ...       1       1           1          1      2   \n",
      "97           1       3  ...       1       1           1          1      3   \n",
      "147          1       1  ...       1       1           1          1      2   \n",
      "19           2       2  ...       2       1           1          1      3   \n",
      "\n",
      "     LISTENS  LIKES_DISCUSS  CLASSROOM  CUML_GPA  EXP_GPA  \n",
      "33         3              2          2         2        3  \n",
      "108        3              1          2         3        3  \n",
      "240        2              2          1         2        2  \n",
      "259        3              2          2         2        2  \n",
      "154        2              2          2         3        2  \n",
      "9          2              2          2         1        2  \n",
      "146        2              2          1         2        2  \n",
      "203        2              3          2         4        3  \n",
      "144        2              3          1         5        4  \n",
      "155        2              2          2         3        2  \n",
      "221        3              2          2         2        2  \n",
      "92         2              3          3         2        2  \n",
      "222        1              2          1         3        3  \n",
      "209        1              3          2         2        2  \n",
      "42         1              3          1         2        3  \n",
      "210        3              1          1         3        2  \n",
      "66         2              2          3         5        4  \n",
      "90         3              2          3         4        2  \n",
      "119        2              3          1         3        3  \n",
      "142        3              2          1         4        3  \n",
      "262        2              2          3         2        2  \n",
      "268        1              2          1         3        4  \n",
      "206        2              2          1         2        2  \n",
      "238        2              3          2         4        3  \n",
      "46         2              3          1         4        2  \n",
      "77         2              2          2         1        1  \n",
      "68         2              3          2         4        3  \n",
      "75         2              2          2         4        1  \n",
      "216        1              2          1         4        3  \n",
      "277        2              2          1         1        1  \n",
      "45         2              2          1         4        3  \n",
      "111        1              3          3         4        3  \n",
      "60         3              3          1         2        1  \n",
      "217        3              1          1         3        2  \n",
      "143        1              2          1         5        3  \n",
      "30         3              3          3         5        4  \n",
      "22         1              2          3         3        3  \n",
      "24         1              3          2         4        4  \n",
      "127        2              2          1         2        2  \n",
      "176        1              2          1         2        2  \n",
      "79         3              3          2         4        4  \n",
      "264        2              3          1         4        4  \n",
      "237        2              2          1         3        2  \n",
      "120        3              3          2         2        2  \n",
      "196        2              2          2         2        3  \n",
      "245        2              2          1         3        2  \n",
      "168        2              2          1         2        2  \n",
      "6          3              3          3         4        4  \n",
      "239        2              2          2         4        3  \n",
      "73         2              3          1         5        3  \n",
      "84         3              3          3         5        4  \n",
      "56         2              3          3         5        4  \n",
      "25         1              3          2         1        2  \n",
      "97         2              2          1         3        3  \n",
      "147        2              2          2         3        2  \n",
      "19         2              2          3         2        3  \n",
      "\n",
      "[56 rows x 30 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Extracting Labels\n",
    "\n",
    "columns = data_train.columns.to_list()\n",
    "columns_drop = columns.pop(-1)\n",
    "labels_train = data_train.drop(columns, axis=1)\n",
    "labels_test = data_test.drop(columns, axis=1)\n",
    "\n",
    "print(f\"labels_train: \\n{labels_train}\\n\")\n",
    "print(f\"labels_test: \\n{labels_test}\\n\")\n",
    "\n",
    "features_train = data_train.drop(['GRADE'], axis=1)\n",
    "features_test = data_test.drop(['GRADE'], axis=1)\n",
    "print(f\"features_train: \\n{features_train }\\n\")\n",
    "print(f\"lfeatures_test: \\n{features_test }\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ohenc = OneHotEncoder(sparse=False)\n",
    "ohenc_cols = ohenc.fit(features_train).get_feature_names_out()\n",
    "# temp = np.append(ohenc_cols[0:37],['MOTHER_EDU_6'])\n",
    "# temp2 = np.append(temp, ohenc_cols[37::])\n",
    "# ohenc_cols = temp2\n",
    "# print(ohenc_cols)\n",
    "# encoded_train = ohenc.fit_transform(features_train)\n",
    "data_prepared = pd.DataFrame(ohenc.fit_transform(features_train),columns=ohenc_cols, index=features_train.index)\n",
    "#full_pipeline.fit_transform(data_train)\n",
    "#pd.DataFrame(full_pipeline.fit_transform(train_df),columns=train_df.columns, index=train_df.index)\\\n",
    "\n",
    "zero_data = np.zeros(shape=(len(data_prepared),1))\n",
    "\n",
    "data_prepared.insert(37,\"MOTHER_EDU_6\", zero_data) #Inserting those columns that are not represented in the train data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the following four different models with their default hyperparameter values to be trained using the preprocessed data (0.5 * 4)\n",
    "labelTrainFlat = labels_train.values.ravel()\n",
    "# Gradient Boosting\n",
    "gradientBoosting = OneVsRestClassifier(GradientBoostingClassifier())\n",
    "gradientBoosting = gradientBoosting.fit(data_prepared, labelTrainFlat)\n",
    "\n",
    "# Decision Trees\n",
    "decisionTree = DecisionTreeClassifier()\n",
    "decisionTree = decisionTree.fit(data_prepared,labelTrainFlat)\n",
    "\n",
    "# Random Forests\n",
    "randomForest = RandomForestClassifier()\n",
    "randomForest = randomForest.fit(data_prepared,labelTrainFlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters GradientBoosting: \n",
      "{'estimator__learning_rate': 0.45, 'estimator__min_samples_leaf': 6, 'estimator__min_samples_split': 10, 'estimator__n_estimators': 58}\n",
      "\n",
      "Best estimator GradientBoosting: \n",
      "OneVsRestClassifier(estimator=GradientBoostingClassifier(learning_rate=0.45,\n",
      "                                                         min_samples_leaf=6,\n",
      "                                                         min_samples_split=10,\n",
      "                                                         n_estimators=58))\n",
      "\n",
      "Best score GradientBoosting: \n",
      "0.6876860119047619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parametersGradientBoosting = [\n",
    "    {'estimator__learning_rate': [0.44,0.45,0.46],'estimator__min_samples_leaf': [5,6,7],'estimator__min_samples_split': [7,8,9,10], 'estimator__n_estimators': [57,58,59,60]}\n",
    "]\n",
    "scoringX = {\"accuracy\": \"accuracy\", \"bal_accuracy\": \"balanced_accuracy\", \"F1_macro\": \"f1_macro\"}\n",
    "\n",
    "grid_searchGradientBoosting = GridSearchCV(gradientBoosting, parametersGradientBoosting, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "grid_searchGradientBoosting.fit(data_prepared, labelTrainFlat)\n",
    "\n",
    "print(f\"Best parameters GradientBoosting: \\n{grid_searchGradientBoosting.best_params_}\\n\")\n",
    "print(f\"Best estimator GradientBoosting: \\n{grid_searchGradientBoosting.best_estimator_}\\n\")\n",
    "print(f\"Best score GradientBoosting: \\n{grid_searchGradientBoosting.best_score_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters KNeighbors: \n",
      "{'algorithm': 'auto', 'n_neighbors': 1, 'p': 1, 'weights': 'uniform'}\n",
      "\n",
      "Best estimator KNeighbors: \n",
      "KNeighborsClassifier(n_neighbors=1, p=1)\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.6803977272727272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# KNeighbors\n",
    "kNeighbors = KNeighborsClassifier()\n",
    "kNeighbors = kNeighbors.fit(data_prepared,labelTrainFlat)\n",
    "\n",
    "parametersKNeighbors = [\n",
    "    {'n_neighbors': [1,2,3],'weights':['uniform', 'distance'],'algorithm':['auto'], 'p': [1,2,3]}\n",
    "]\n",
    "scoringX = {\"accuracy\": \"accuracy\", \"bal_accuracy\": \"balanced_accuracy\", \"F1_macro\": \"f1_macro\"}\n",
    "\n",
    "grid_searchKNeighbors = GridSearchCV(kNeighbors, parametersKNeighbors, cv=3, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "grid_searchKNeighbors.fit(data_prepared, labelTrainFlat)\n",
    "\n",
    "print(f\"Best parameters KNeighbors: \\n{grid_searchKNeighbors.best_params_}\\n\")\n",
    "print(f\"Best estimator KNeighbors: \\n{grid_searchKNeighbors.best_estimator_}\\n\")\n",
    "print(f\"Best score KNeighbors: \\n{grid_searchKNeighbors.best_score_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacob\\anaconda3\\envs\\csi4106New\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters Logistic Regression: \n",
      "{'C': 3, 'multi_class': 'ovr', 'penalty': 'l2'}\n",
      "\n",
      "Best estimator Logistic Regression: \n",
      "LogisticRegression(C=3, multi_class='ovr')\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.5927293771043771\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "logisticRegression = LogisticRegression()\n",
    "logisticRegression = logisticRegression.fit(data_prepared,labelTrainFlat)\n",
    "\n",
    "parametersLogisticRegression = [\n",
    "    {'multi_class': ['ovr'],'penalty':['none','l2'], 'C': [1,2,3]}\n",
    "]\n",
    "scoringX = {\"accuracy\": \"accuracy\", \"bal_accuracy\": \"balanced_accuracy\", \"F1_macro\": \"f1_macro\"}\n",
    "\n",
    "grid_searchLogisticRegression = GridSearchCV(logisticRegression, parametersLogisticRegression, cv=3, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "grid_searchLogisticRegression.fit(data_prepared, labelTrainFlat)\n",
    "\n",
    "print(f\"Best parameters Logistic Regression: \\n{grid_searchLogisticRegression.best_params_}\\n\")\n",
    "print(f\"Best estimator Logistic Regression: \\n{grid_searchLogisticRegression.best_estimator_}\\n\")\n",
    "print(f\"Best score Logistic Regression: \\n{grid_searchLogisticRegression.best_score_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters DecisionTree: \n",
      "{'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 3}\n",
      "\n",
      "Best estimator DecisionTree: \n",
      "DecisionTreeClassifier(max_depth=4, min_samples_leaf=4, min_samples_split=3)\n",
      "\n",
      "Best score DecisionTree: \n",
      "0.34593855218855224\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacob\\anaconda3\\envs\\csi4106New\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "36 fits failed out of a total of 108.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "36 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jacob\\anaconda3\\envs\\csi4106New\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jacob\\anaconda3\\envs\\csi4106New\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\jacob\\anaconda3\\envs\\csi4106New\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\jacob\\anaconda3\\envs\\csi4106New\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.18306306 0.18306306        nan 0.18306306 0.18306306\n",
      "        nan 0.18306306 0.18306306        nan 0.22780781 0.22780781\n",
      "        nan 0.22780781 0.22780781        nan 0.22780781 0.22780781\n",
      "        nan 0.28588589 0.28588589        nan 0.28144144 0.28144144\n",
      "        nan 0.29033033 0.29033033        nan 0.33927928 0.34372372\n",
      "        nan 0.32594595 0.33039039        nan 0.33489489 0.33489489]\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacob\\anaconda3\\envs\\csi4106New\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan 0.22991797 0.22991797        nan 0.22991797 0.22991797\n",
      "        nan 0.22991797 0.22991797        nan 0.33032066 0.33032066\n",
      "        nan 0.33032066 0.33032066        nan 0.33032066 0.33032066\n",
      "        nan 0.44189411 0.44189411        nan 0.43741984 0.43741984\n",
      "        nan 0.43297539 0.43297539        nan 0.54686055 0.54686055\n",
      "        nan 0.53343773 0.53343773        nan 0.52453393 0.52453393]\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacob\\anaconda3\\envs\\csi4106New\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.17777778 0.17777778        nan 0.17777778 0.17777778\n",
      "        nan 0.17777778 0.17777778        nan 0.22108586 0.22108586\n",
      "        nan 0.22108586 0.22108586        nan 0.22108586 0.22108586\n",
      "        nan 0.28341751 0.28341751        nan 0.27962963 0.27962963\n",
      "        nan 0.28720539 0.28720539        nan 0.34130892 0.34593855\n",
      "        nan 0.32826178 0.33289141        nan 0.33583754 0.33583754]\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacob\\anaconda3\\envs\\csi4106New\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan 0.21638471 0.21638471        nan 0.21638471 0.21638471\n",
      "        nan 0.21638471 0.21638471        nan 0.32091339 0.32091339\n",
      "        nan 0.32091339 0.32091339        nan 0.32091339 0.32091339\n",
      "        nan 0.43892349 0.43892349        nan 0.43498831 0.43498831\n",
      "        nan 0.43032561 0.43032561        nan 0.54559192 0.54559192\n",
      "        nan 0.53210812 0.53239748        nan 0.5228158  0.5228158 ]\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacob\\anaconda3\\envs\\csi4106New\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.08159788 0.08159788        nan 0.08159788 0.08159788\n",
      "        nan 0.08159788 0.08159788        nan 0.1591942  0.1591942\n",
      "        nan 0.1591942  0.1591942         nan 0.1591942  0.1591942\n",
      "        nan 0.25024731 0.25024731        nan 0.24306847 0.24306847\n",
      "        nan 0.25085023 0.25085023        nan 0.31625589 0.31875896\n",
      "        nan 0.3064626  0.31375561        nan 0.31099151 0.31099151]\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacob\\anaconda3\\envs\\csi4106New\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan 0.10353815 0.10353815        nan 0.10353815 0.10353815\n",
      "        nan 0.10353815 0.10353815        nan 0.22069425 0.22069425\n",
      "        nan 0.22069425 0.22069425        nan 0.22069425 0.22069425\n",
      "        nan 0.3828876  0.3828876         nan 0.37133704 0.37133704\n",
      "        nan 0.37402363 0.37402363        nan 0.52799706 0.52799706\n",
      "        nan 0.52273129 0.52455111        nan 0.50550498 0.50550498]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "parametersDecisionTree = [\n",
    "    {'max_depth': [1,2,3,4], 'min_samples_leaf': [4,5,6], 'min_samples_split': [1,2,3]}\n",
    "]\n",
    "\n",
    "grid_searchDecisionTree = GridSearchCV(decisionTree, parametersDecisionTree, cv=3, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "grid_searchDecisionTree.fit(data_prepared, labelTrainFlat)\n",
    "\n",
    "print(f\"Best parameters DecisionTree: \\n{grid_searchDecisionTree.best_params_}\\n\")\n",
    "print(f\"Best estimator DecisionTree: \\n{grid_searchDecisionTree.best_estimator_}\\n\")\n",
    "print(f\"Best score DecisionTree: \\n{grid_searchDecisionTree.best_score_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters RandomForest: \n",
      "{'bootstrap': False, 'max_depth': 10, 'min_impurity_decrease': 0.0, 'min_samples_split': 2, 'n_estimators': 145}\n",
      "\n",
      "Best estimator RandomForest: \n",
      "RandomForestClassifier(bootstrap=False, max_depth=10, n_estimators=145)\n",
      "\n",
      "Best score RandomForest: \n",
      "0.6705729166666667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parametersRandomForest = [\n",
    "    {'n_estimators': [145,150,155,190],'max_depth': [10,12], 'bootstrap': [True, False],\n",
    "     \"min_impurity_decrease\" : [.0,0.01,1,0.009, 0.04], 'min_samples_split': [0.05,2]}\n",
    "]\n",
    "\n",
    "grid_searchRandomForest = GridSearchCV(randomForest, parametersRandomForest, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "grid_searchRandomForest.fit(data_prepared, labelTrainFlat)\n",
    "\n",
    "print(f\"Best parameters RandomForest: \\n{grid_searchRandomForest.best_params_}\\n\")\n",
    "\n",
    "print(f\"Best estimator RandomForest: \\n{grid_searchRandomForest.best_estimator_}\\n\")\n",
    "\n",
    "print(f\"Best score RandomForest: \\n{grid_searchRandomForest.best_score_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test Accuracy for GradientBoosting: \n",
      "[0.63392857 0.64732143 0.65178571 0.65178571 0.62946429 0.63392857\n",
      " 0.64285714 0.64285714 0.625      0.63392857 0.64732143 0.65625\n",
      " 0.64285714 0.64732143 0.65178571 0.64285714 0.65625    0.66517857\n",
      " 0.65625    0.64732143 0.66071429 0.66964286 0.64732143 0.64732143\n",
      " 0.64285714 0.65625    0.66517857 0.625      0.63839286 0.65625\n",
      " 0.64732143 0.66517857 0.63392857 0.625      0.63839286 0.61160714\n",
      " 0.625      0.62946429 0.61160714 0.62946429 0.63392857 0.625\n",
      " 0.625      0.61160714 0.64285714 0.63392857 0.61607143 0.625\n",
      " 0.66071429 0.63392857 0.64285714 0.66071429 0.66071429 0.64285714\n",
      " 0.65625    0.63839286 0.65625    0.64285714 0.65178571 0.63839286\n",
      " 0.64285714 0.64732143 0.65178571 0.64285714 0.66964286 0.66964286\n",
      " 0.67857143 0.66964286 0.65178571 0.66964286 0.66071429 0.66517857\n",
      " 0.66964286 0.67410714 0.65178571 0.65625    0.67410714 0.6875\n",
      " 0.66071429 0.66517857 0.65625    0.65178571 0.64285714 0.63839286\n",
      " 0.66071429 0.65625    0.62946429 0.64732143 0.66071429 0.65178571\n",
      " 0.65625    0.63839286 0.66517857 0.64285714 0.64285714 0.64732143\n",
      " 0.65625    0.65178571 0.63839286 0.64732143 0.63839286 0.65178571\n",
      " 0.64732143 0.63392857 0.65178571 0.63392857 0.63839286 0.64285714\n",
      " 0.65178571 0.64285714 0.64285714 0.64285714 0.64285714 0.64285714\n",
      " 0.64285714 0.65178571 0.63839286 0.66071429 0.65178571 0.65178571\n",
      " 0.62946429 0.64285714 0.65625    0.66964286 0.64285714 0.64732143\n",
      " 0.66071429 0.65178571 0.65625    0.64285714 0.64732143 0.66071429\n",
      " 0.64285714 0.65178571 0.64732143 0.65625    0.64285714 0.64732143\n",
      " 0.65625    0.66071429 0.66517857 0.65625    0.63839286 0.65178571]\n",
      "\n",
      "Balanced Test Accuracy for GradientBoosting: \n",
      "[0.6359747  0.64825149 0.65383185 0.65215774 0.63206845 0.63541667\n",
      " 0.6437872  0.6437872  0.62630208 0.63541667 0.64825149 0.65662202\n",
      " 0.64434524 0.64825149 0.65215774 0.64490327 0.65699405 0.66610863\n",
      " 0.65625    0.64601935 0.65959821 0.671875   0.64657738 0.64750744\n",
      " 0.64341518 0.65699405 0.66592262 0.62537202 0.63839286 0.65625\n",
      " 0.64769345 0.66350446 0.63411458 0.62593006 0.63932292 0.61235119\n",
      " 0.62593006 0.62983631 0.6125372  0.6296503  0.63485863 0.62593006\n",
      " 0.62593006 0.61309524 0.64508929 0.63485863 0.61700149 0.62574405\n",
      " 0.66052827 0.63523065 0.64490327 0.66034226 0.66294643 0.64490327\n",
      " 0.65829613 0.63969494 0.65959821 0.64304315 0.65345982 0.63783482\n",
      " 0.64434524 0.64862351 0.65457589 0.64285714 0.66908482 0.66834077\n",
      " 0.68043155 0.66852679 0.65290179 0.6703869  0.66108631 0.66629464\n",
      " 0.66964286 0.67540923 0.65234375 0.65792411 0.67373512 0.68768601\n",
      " 0.66015625 0.66517857 0.65755208 0.65420387 0.64397321 0.64006696\n",
      " 0.66145833 0.65885417 0.63058036 0.64862351 0.66071429 0.65364583\n",
      " 0.65755208 0.64025298 0.66536458 0.6452753  0.64267113 0.64862351\n",
      " 0.6577381  0.65513393 0.64155506 0.64806548 0.64099702 0.65327381\n",
      " 0.64936756 0.63523065 0.65383185 0.63653274 0.6391369  0.64360119\n",
      " 0.65197173 0.64490327 0.64546131 0.64360119 0.64546131 0.64415923\n",
      " 0.64285714 0.65383185 0.64025298 0.66164435 0.65383185 0.65383185\n",
      " 0.63002232 0.64415923 0.65829613 0.671875   0.64304315 0.64918155\n",
      " 0.66294643 0.65252976 0.65811012 0.64397321 0.6484375  0.66108631\n",
      " 0.64322917 0.65364583 0.6484375  0.65680804 0.64322917 0.6484375\n",
      " 0.65680804 0.66183036 0.66703869 0.65736607 0.64006696 0.65345982]\n",
      "\n",
      "Mean F1 Macro for GradientBoosting: \n",
      "[0.62820072 0.64156676 0.64573484 0.64781716 0.62429235 0.62776598\n",
      " 0.63858183 0.63595258 0.61923165 0.62738648 0.63986187 0.65139773\n",
      " 0.63699885 0.64397722 0.64688341 0.63847768 0.65346371 0.65986129\n",
      " 0.64631665 0.63973452 0.65207666 0.66114259 0.63600778 0.64218566\n",
      " 0.63823709 0.65101032 0.65982811 0.6163233  0.63399064 0.65007596\n",
      " 0.63864611 0.65708642 0.62133795 0.61545139 0.62934202 0.60156119\n",
      " 0.61484898 0.61968369 0.60446882 0.61730428 0.62447571 0.61535123\n",
      " 0.61745559 0.60252638 0.6328158  0.62549918 0.60801417 0.61231986\n",
      " 0.65697862 0.62914427 0.63900595 0.65035735 0.65794955 0.63775138\n",
      " 0.64993905 0.63472506 0.64997446 0.64036741 0.64802963 0.63385134\n",
      " 0.64241585 0.64276027 0.64540458 0.63500467 0.65628198 0.66258309\n",
      " 0.66742859 0.66155267 0.63912596 0.65932157 0.65339863 0.65096466\n",
      " 0.65938249 0.66502202 0.6405043  0.64822944 0.66482207 0.67691949\n",
      " 0.65025095 0.65461663 0.65103429 0.64523546 0.63375124 0.63057042\n",
      " 0.65443628 0.65012908 0.6211405  0.64144665 0.65411069 0.64621062\n",
      " 0.64758165 0.63260533 0.65884725 0.63701791 0.63147749 0.64110964\n",
      " 0.65264192 0.64702415 0.63178118 0.64397342 0.63092388 0.64872868\n",
      " 0.64252407 0.62969499 0.64517374 0.63340221 0.63963221 0.64149814\n",
      " 0.65100909 0.63840735 0.64123074 0.63866709 0.63505485 0.63633091\n",
      " 0.63774861 0.64749103 0.63211032 0.65673517 0.64620336 0.64769357\n",
      " 0.62285727 0.63815927 0.64817773 0.66367057 0.63676228 0.64122804\n",
      " 0.65553135 0.64666399 0.64735228 0.63502587 0.64437273 0.65025896\n",
      " 0.63243421 0.64621013 0.63938809 0.64885921 0.63243421 0.63746245\n",
      " 0.64961413 0.65055498 0.65406079 0.64556291 0.63213851 0.64672619]\n",
      "\n",
      "Mean Test Accuracy for Decision Trees: \n",
      "[       nan 0.18306306 0.18306306        nan 0.18306306 0.18306306\n",
      "        nan 0.18306306 0.18306306        nan 0.22780781 0.22780781\n",
      "        nan 0.22780781 0.22780781        nan 0.22780781 0.22780781\n",
      "        nan 0.28588589 0.28588589        nan 0.28144144 0.28144144\n",
      "        nan 0.29033033 0.29033033        nan 0.33927928 0.34372372\n",
      "        nan 0.32594595 0.33039039        nan 0.33489489 0.33489489]\n",
      "\n",
      "Balanced Test Accuracy for Decision Trees: \n",
      "[       nan 0.17777778 0.17777778        nan 0.17777778 0.17777778\n",
      "        nan 0.17777778 0.17777778        nan 0.22108586 0.22108586\n",
      "        nan 0.22108586 0.22108586        nan 0.22108586 0.22108586\n",
      "        nan 0.28341751 0.28341751        nan 0.27962963 0.27962963\n",
      "        nan 0.28720539 0.28720539        nan 0.34130892 0.34593855\n",
      "        nan 0.32826178 0.33289141        nan 0.33583754 0.33583754]\n",
      "\n",
      "Mean F1 Macro for Decision Trees: \n",
      "[       nan 0.08159788 0.08159788        nan 0.08159788 0.08159788\n",
      "        nan 0.08159788 0.08159788        nan 0.1591942  0.1591942\n",
      "        nan 0.1591942  0.1591942         nan 0.1591942  0.1591942\n",
      "        nan 0.25024731 0.25024731        nan 0.24306847 0.24306847\n",
      "        nan 0.25085023 0.25085023        nan 0.31625589 0.31875896\n",
      "        nan 0.3064626  0.31375561        nan 0.31099151 0.31099151]\n",
      "\n",
      "Mean Test Accuracy for Random Forests: \n",
      "[0.58928571 0.57142857 0.57589286 0.59821429 0.625      0.62946429\n",
      " 0.65178571 0.62946429 0.59375    0.59375    0.58035714 0.5625\n",
      " 0.62053571 0.59821429 0.60267857 0.62053571 0.13392857 0.13839286\n",
      " 0.13839286 0.13839286 0.13839286 0.13839286 0.13839286 0.13839286\n",
      " 0.58482143 0.55357143 0.58035714 0.58482143 0.60267857 0.62053571\n",
      " 0.59821429 0.62053571 0.25446429 0.28571429 0.30803571 0.27232143\n",
      " 0.26785714 0.25892857 0.26339286 0.28125    0.59375    0.61607143\n",
      " 0.58035714 0.58928571 0.61607143 0.64285714 0.64285714 0.64732143\n",
      " 0.56696429 0.58482143 0.58928571 0.57142857 0.61607143 0.59821429\n",
      " 0.59375    0.60714286 0.13839286 0.13839286 0.13839286 0.13839286\n",
      " 0.13392857 0.13839286 0.13839286 0.13839286 0.57142857 0.58928571\n",
      " 0.58928571 0.58035714 0.59821429 0.60714286 0.61160714 0.63839286\n",
      " 0.26785714 0.29017857 0.25892857 0.29017857 0.28125    0.30803571\n",
      " 0.27678571 0.26785714 0.60714286 0.58482143 0.58482143 0.62946429\n",
      " 0.66517857 0.64732143 0.66071429 0.65178571 0.56696429 0.55357143\n",
      " 0.54464286 0.56696429 0.5625     0.59375    0.55803571 0.55803571\n",
      " 0.13839286 0.13839286 0.13839286 0.13839286 0.13839286 0.13839286\n",
      " 0.13839286 0.13839286 0.57589286 0.58928571 0.57142857 0.58482143\n",
      " 0.57589286 0.58035714 0.58482143 0.5625     0.16964286 0.16964286\n",
      " 0.16964286 0.16964286 0.16964286 0.16964286 0.16964286 0.16964286\n",
      " 0.5625     0.58035714 0.62053571 0.60714286 0.66071429 0.64285714\n",
      " 0.66071429 0.66517857 0.5625     0.57142857 0.56696429 0.54910714\n",
      " 0.55357143 0.55803571 0.58482143 0.57142857 0.13839286 0.13839286\n",
      " 0.13839286 0.13839286 0.13839286 0.13839286 0.13839286 0.13839286\n",
      " 0.57589286 0.58928571 0.58482143 0.56696429 0.60267857 0.57589286\n",
      " 0.59375    0.60267857 0.16964286 0.16964286 0.16964286 0.16964286\n",
      " 0.16964286 0.16964286 0.16964286 0.16964286]\n",
      "\n",
      "Balanced Test Accuracy for Random Forests: \n",
      "[0.59561012 0.57477679 0.58110119 0.60267857 0.63188244 0.63578869\n",
      " 0.65885417 0.63485863 0.60026042 0.59951637 0.58333333 0.5656622\n",
      " 0.62295387 0.60323661 0.60900298 0.62797619 0.125      0.125\n",
      " 0.125      0.125      0.125      0.125      0.125      0.125\n",
      " 0.58965774 0.55766369 0.58184524 0.5874256  0.60695685 0.625\n",
      " 0.60379464 0.6281622  0.24479167 0.2749256  0.2983631  0.26041667\n",
      " 0.26153274 0.24944196 0.25725446 0.2702753  0.59877232 0.62332589\n",
      " 0.5859375  0.59542411 0.62165179 0.64955357 0.64918155 0.65271577\n",
      " 0.5703125  0.58965774 0.59468006 0.57700893 0.62258185 0.60379464\n",
      " 0.59672619 0.61216518 0.125      0.125      0.125      0.125\n",
      " 0.125      0.125      0.125      0.125      0.57366071 0.59430804\n",
      " 0.59319196 0.5844494  0.60360863 0.61495536 0.61904762 0.6469494\n",
      " 0.25762649 0.28013393 0.25       0.27901786 0.2719494  0.29761905\n",
      " 0.26488095 0.25706845 0.61290923 0.59319196 0.59244792 0.63802083\n",
      " 0.67057292 0.65271577 0.66778274 0.65643601 0.57012649 0.55840774\n",
      " 0.54985119 0.5718006  0.5671503  0.59654018 0.56305804 0.5656622\n",
      " 0.125      0.125      0.125      0.125      0.125      0.125\n",
      " 0.125      0.125      0.58017113 0.59486607 0.57756696 0.59095982\n",
      " 0.5796131  0.58575149 0.59095982 0.56808036 0.15848214 0.15848214\n",
      " 0.15848214 0.15848214 0.15848214 0.15848214 0.15848214 0.15848214\n",
      " 0.56659226 0.58500744 0.62630208 0.61235119 0.66703869 0.64732143\n",
      " 0.66592262 0.66982887 0.56808036 0.57440476 0.57068452 0.55375744\n",
      " 0.55952381 0.56529018 0.5905878  0.57328869 0.125      0.125\n",
      " 0.125      0.125      0.125      0.125      0.125      0.125\n",
      " 0.58091518 0.59561012 0.59040179 0.57105655 0.60695685 0.57886905\n",
      " 0.59877232 0.60714286 0.15848214 0.15848214 0.15848214 0.15848214\n",
      " 0.15848214 0.15848214 0.15848214 0.15848214]\n",
      "\n",
      "Mean F1 Macro for Random Forests: \n",
      "[0.58706038 0.56304887 0.5631205  0.58813767 0.60884271 0.62324778\n",
      " 0.64720767 0.61307127 0.58676514 0.58831548 0.57351607 0.55261345\n",
      " 0.60509122 0.5868687  0.58830233 0.6098628  0.02951389 0.03038194\n",
      " 0.03038194 0.03038194 0.03038194 0.03038194 0.03038194 0.03038194\n",
      " 0.58125903 0.53762099 0.56158679 0.5679553  0.59178007 0.60856642\n",
      " 0.58501382 0.60252569 0.17420441 0.20193866 0.21295062 0.17916019\n",
      " 0.18085128 0.17015115 0.18680532 0.1856252  0.58412744 0.59952017\n",
      " 0.58265363 0.5780972  0.60294086 0.6299295  0.63068622 0.63452566\n",
      " 0.55580376 0.57698512 0.57685536 0.56037903 0.60001685 0.58454163\n",
      " 0.58738427 0.59387974 0.03038194 0.03038194 0.03038194 0.03038194\n",
      " 0.02951389 0.03038194 0.03038194 0.03038194 0.56238217 0.58033563\n",
      " 0.58442124 0.56463535 0.58421767 0.59816056 0.60069295 0.62830448\n",
      " 0.16819488 0.21369153 0.17342702 0.2057808  0.18192369 0.20722602\n",
      " 0.17239783 0.17714536 0.59783214 0.57982052 0.57139975 0.62310478\n",
      " 0.65266661 0.63544145 0.65285922 0.63746306 0.55466605 0.53767986\n",
      " 0.53342869 0.55391352 0.5488306  0.58059468 0.54258881 0.55309987\n",
      " 0.03038194 0.03038194 0.03038194 0.03038194 0.03038194 0.03038194\n",
      " 0.03038194 0.03038194 0.56883823 0.57368743 0.55556479 0.57265039\n",
      " 0.5669647  0.56933047 0.57151836 0.55423611 0.06027255 0.06027255\n",
      " 0.06027255 0.06027255 0.06027255 0.06027255 0.06027255 0.06027255\n",
      " 0.55631671 0.56757853 0.60499038 0.59731426 0.65315969 0.62954863\n",
      " 0.64912522 0.65476208 0.55631785 0.5557929  0.55800174 0.54159303\n",
      " 0.54798976 0.54147974 0.57836089 0.56059337 0.03038194 0.03038194\n",
      " 0.03038194 0.03038194 0.03038194 0.03038194 0.03038194 0.03038194\n",
      " 0.56661179 0.58342055 0.57037706 0.5550356  0.5933223  0.5653666\n",
      " 0.58730459 0.59064974 0.06027255 0.06027255 0.06027255 0.06027255\n",
      " 0.06027255 0.06027255 0.06027255 0.06027255]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the grid search cross-validation results listing the above mentioned evaluation methods (3)\n",
    "cross_val_resultsGB = grid_searchGradientBoosting.cv_results_\n",
    "cross_val_resultsDT = grid_searchDecisionTree.cv_results_\n",
    "cross_val_resultsRF = grid_searchRandomForest.cv_results_\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Mean Test Accuracy for GradientBoosting: \\n{cross_val_resultsGB['mean_test_accuracy']}\\n\")\n",
    "print(f\"Balanced Test Accuracy for GradientBoosting: \\n{cross_val_resultsGB['mean_test_bal_accuracy']}\\n\")\n",
    "print(f\"Mean F1 Macro for GradientBoosting: \\n{cross_val_resultsGB['mean_test_F1_macro']}\\n\")\n",
    "\n",
    "#DTC\n",
    "print(f\"Mean Test Accuracy for Decision Trees: \\n{cross_val_resultsDT['mean_test_accuracy']}\\n\")\n",
    "print(f\"Balanced Test Accuracy for Decision Trees: \\n{cross_val_resultsDT['mean_test_bal_accuracy']}\\n\")\n",
    "print(f\"Mean F1 Macro for Decision Trees: \\n{cross_val_resultsDT['mean_test_F1_macro']}\\n\")\n",
    "\n",
    "#RFC\n",
    "print(f\"Mean Test Accuracy for Random Forests: \\n{cross_val_resultsRF['mean_test_accuracy']}\\n\")\n",
    "print(f\"Balanced Test Accuracy for Random Forests: \\n{cross_val_resultsRF['mean_test_bal_accuracy']}\\n\")\n",
    "print(f\"Mean F1 Macro for Random Forests: \\n{cross_val_resultsRF['mean_test_F1_macro']}\\n\")\n",
    "\n",
    "#NB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Prediction: \n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1]\n",
      "\n",
      "Dummy Score: \n",
      "0.13839285714285715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use a dummy classifier to identify a simple baseline (i.e., a majority class baseline) so that you can compare your prediction results (3)\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(data_prepared, labelTrainFlat)\n",
    "DummyClassifier(strategy='most_frequent')\n",
    "print(f\"Dummy Prediction: \\n{dummy_clf.predict(data_prepared)}\\n\") \n",
    "print(f\"Dummy Score: \\n{dummy_clf.score(data_prepared, labelTrainFlat)}\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86         6\n",
      "           1       0.50      0.50      0.50         4\n",
      "           2       0.60      0.50      0.55         6\n",
      "           3       0.67      0.57      0.62         7\n",
      "           4       0.89      1.00      0.94         8\n",
      "           5       0.67      0.60      0.63        10\n",
      "           6       0.36      0.57      0.44         7\n",
      "           7       0.75      0.38      0.50         8\n",
      "\n",
      "    accuracy                           0.64        56\n",
      "   macro avg       0.65      0.64      0.63        56\n",
      "weighted avg       0.66      0.64      0.64        56\n",
      "\n",
      "[[6 0 0 0 0 0 0 0]\n",
      " [1 2 0 0 0 0 0 1]\n",
      " [0 1 3 0 0 1 1 0]\n",
      " [0 1 1 4 0 0 1 0]\n",
      " [0 0 0 0 8 0 0 0]\n",
      " [0 0 0 0 0 6 4 0]\n",
      " [1 0 0 0 0 2 4 0]\n",
      " [0 0 1 2 1 0 1 3]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ohenc_test = OneHotEncoder(sparse=False)\n",
    "ohenc_cols_test = ohenc_test.fit(features_test).get_feature_names_out()\n",
    "\n",
    "missing_cols_from_test = ['MOTHER_JOB_5', 'LIVING_4', 'FATHER_EDU_6']\n",
    "missing_cols_from_train = ['MOTHER_EDU_6']\n",
    "\n",
    "data_prepared_test = pd.DataFrame(ohenc.fit_transform(features_test),columns=ohenc_cols_test, index=features_test.index)\n",
    "missing_cols_df = pd.DataFrame(0, index=np.arange(56), columns=missing_cols_from_test)\n",
    "res = list(set(ohenc_cols).difference(set(ohenc_cols_test)))\n",
    "\n",
    "zero_data = np.zeros(shape=(len(data_prepared_test),1))\n",
    "\n",
    "data_prepared_test.insert(54,\"MOTHER_JOB_5\", zero_data) #Inserting those columns that are not represented in the test data\n",
    "data_prepared_test.insert(31,\"LIVING_4\", zero_data)\n",
    "data_prepared_test.insert(43,\"FATHER_EDU_6\", zero_data)\n",
    "\n",
    "\n",
    "\n",
    "# obtain predictions on test data using the best model from GridSearchCV (i.e., .best_estimator_) (2)\n",
    "predictions_test = grid_searchGradientBoosting.best_estimator_.predict(data_prepared_test)\n",
    "\n",
    "# generate the classification report and the confusion matrix for test predictions (3)\n",
    "print(classification_report(labels_test.values.ravel(),predictions_test))\n",
    "print(confusion_matrix(labels_test, predictions_test))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af4e0a0d28143374aa5d305078a03b698686e6b7df811af5a427e46b8cc107ac"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
