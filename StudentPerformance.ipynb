{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FN score he got was around 90% in macro, more then 80\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "# we can use the LabelEncoder to encode the gender feature\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, cross_val_score, GridSearchCV, cross_validate\n",
    "\n",
    "# importing two different imputation methods that take into consideration all the features when predicting the missing values\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.dummy import DummyClassifier #Will identify the maority calss base line, model needs to do better then the baseline\n",
    "\n",
    "# oversample the minority class using SMOTE\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "# to reduce randomness then you put the seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: \n",
      "(145, 32)\n",
      "\n",
      "Data size: \n",
      "4640\n",
      "\n",
      "Data ndim: \n",
      "2\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Train Data shape: \n",
      "     AGE  GENDER  HS_TYPE  SCHOLARSHIP  WORK  ACTIVITY  PARTNER  SALARY  \\\n",
      "9      2       1        2            3     2         2        1       3   \n",
      "4      2       2        1            3     2         2        1       3   \n",
      "26     2       2        2            3     2         1        1       1   \n",
      "120    2       1        1            3     1         1        1       2   \n",
      "125    1       1        2            5     1         1        2       1   \n",
      "..   ...     ...      ...          ...   ...       ...      ...     ...   \n",
      "71     1       1        3            4     2         2        2       1   \n",
      "106    1       2        2            4     2         1        2       1   \n",
      "14     3       2        2            4     1         1        2       3   \n",
      "92     1       2        2            3     2         2        2       1   \n",
      "102    1       2        2            3     2         2        1       1   \n",
      "\n",
      "     TRANSPORT  LIVING  ...  PREP_STUDY  PREP_EXAM  NOTES  LISTENS  \\\n",
      "9            4       2  ...           1          1      2        2   \n",
      "4            1       4  ...           2          1      2        2   \n",
      "26           1       1  ...           1          1      3        3   \n",
      "120          2       3  ...           2          1      3        3   \n",
      "125          1       3  ...           1          2      3        2   \n",
      "..         ...     ...  ...         ...        ...    ...      ...   \n",
      "71           1       3  ...           1          1      2        3   \n",
      "106          1       2  ...           3          2      2        2   \n",
      "14           4       2  ...           1          1      2        3   \n",
      "92           1       1  ...           1          1      3        2   \n",
      "102          1       2  ...           1          1      3        1   \n",
      "\n",
      "     LIKES_DISCUSS  CLASSROOM  CUML_GPA  EXP_GPA  COURSE ID  GRADE  \n",
      "9                2          2         1        2          1      0  \n",
      "4                2          1         2        2          1      1  \n",
      "26               3          2         2        1          1      1  \n",
      "120              3          2         2        2          8      1  \n",
      "125              3          1         1        3          9      2  \n",
      "..             ...        ...       ...      ...        ...    ...  \n",
      "71               3          3         2        2          3      6  \n",
      "106              2          1         4        4          7      7  \n",
      "14               2          1         4        4          1      2  \n",
      "92               3          3         2        2          6      7  \n",
      "102              2          1         3        4          7      7  \n",
      "\n",
      "[116 rows x 32 columns]\n",
      "\n",
      "Test Data shape: \n",
      "     AGE  GENDER  HS_TYPE  SCHOLARSHIP  WORK  ACTIVITY  PARTNER  SALARY  \\\n",
      "69     2       1        2            4     2         2        1       1   \n",
      "140    2       1        2            3     1         1        2       1   \n",
      "27     1       2        1            3     1         2        2       1   \n",
      "19     1       2        1            3     2         2        1       2   \n",
      "42     2       2        2            3     2         1        2       1   \n",
      "117    3       1        1            3     2         1        2       1   \n",
      "126    1       1        1            4     1         1        1       3   \n",
      "108    2       1        1            5     2         1        2       2   \n",
      "84     3       2        3            3     1         2        1       3   \n",
      "18     1       1        2            4     2         2        2       3   \n",
      "12     1       1        1            4     2         2        2       1   \n",
      "55     3       2        2            3     1         2        1       4   \n",
      "128    1       1        2            4     2         1        1       1   \n",
      "78     2       1        2            4     1         1        2       1   \n",
      "73     2       2        2            4     2         2        2       1   \n",
      "36     2       2        3            4     1         2        1       3   \n",
      "112    2       1        3            3     1         2        2       1   \n",
      "133    1       1        2            5     2         2        1       1   \n",
      "100    1       2        2            4     2         2        2       1   \n",
      "101    1       2        2            4     2         2        1       2   \n",
      "94     2       2        2            3     2         2        1       1   \n",
      "136    1       1        2            3     1         1        1       1   \n",
      "11     1       1        1            4     1         1        2       4   \n",
      "66     2       2        2            3     2         2        1       1   \n",
      "31     3       2        2            3     1         2        2       1   \n",
      "45     1       2        2            3     2         2        1       4   \n",
      "51     2       1        3            3     1         1        2       1   \n",
      "76     2       2        1            2     2         1        2       2   \n",
      "111    1       1        1            5     2         1        2       1   \n",
      "\n",
      "     TRANSPORT  LIVING  ...  PREP_STUDY  PREP_EXAM  NOTES  LISTENS  \\\n",
      "69           1       1  ...           2          1      3        2   \n",
      "140          1       2  ...           1          1      2        1   \n",
      "27           1       1  ...           1          1      3        1   \n",
      "19           2       2  ...           1          1      3        2   \n",
      "42           4       2  ...           1          1      2        1   \n",
      "117          1       2  ...           1          1      2        3   \n",
      "126          2       3  ...           2          1      3        3   \n",
      "108          2       1  ...           1          1      2        3   \n",
      "84           1       2  ...           3          3      3        3   \n",
      "18           1       1  ...           1          1      3        1   \n",
      "12           1       1  ...           1          1      2        2   \n",
      "55           1       2  ...           3          3      1        3   \n",
      "128          4       3  ...           1          1      3        2   \n",
      "78           1       1  ...           1          1      3        3   \n",
      "73           1       2  ...           1          2      3        2   \n",
      "36           1       1  ...           2          1      2        1   \n",
      "112          3       3  ...           2          1      3        3   \n",
      "133          1       1  ...           1          1      3        3   \n",
      "100          2       3  ...           1          1      2        2   \n",
      "101          1       3  ...           1          1      3        3   \n",
      "94           1       1  ...           1          1      3        2   \n",
      "136          2       3  ...           3          1      3        2   \n",
      "11           2       3  ...           3          2      3        1   \n",
      "66           1       1  ...           1          1      3        2   \n",
      "31           1       2  ...           1          1      3        3   \n",
      "45           1       1  ...           1          1      2        2   \n",
      "51           1       1  ...           1          1      2        3   \n",
      "76           1       1  ...           3          2      2        1   \n",
      "111          1       2  ...           1          1      3        1   \n",
      "\n",
      "     LIKES_DISCUSS  CLASSROOM  CUML_GPA  EXP_GPA  COURSE ID  GRADE  \n",
      "69               3          1         3        2          3      5  \n",
      "140              2          1         3        3          9      5  \n",
      "27               2          1         2        1          1      1  \n",
      "19               2          3         2        3          1      3  \n",
      "42               3          1         2        3          1      1  \n",
      "117              2          1         2        3          8      1  \n",
      "126              3          1         2        2          9      3  \n",
      "108              1          2         3        3          7      6  \n",
      "84               3          3         5        4          5      7  \n",
      "18               3          3         3        3          1      2  \n",
      "12               2          3         4        2          1      0  \n",
      "55               3          3         5        4          1      3  \n",
      "128              2          1         2        2          9      0  \n",
      "78               2          2         2        2          4      4  \n",
      "73               3          1         5        3          3      6  \n",
      "36               2          1         4        3          1      2  \n",
      "112              3          1         4        2          8      2  \n",
      "133              3          2         5        3          9      3  \n",
      "100              2          1         3        3          7      6  \n",
      "101              2          1         2        3          7      7  \n",
      "94               2          3         5        4          6      6  \n",
      "136              2          1         2        2          9      0  \n",
      "11               3          3         4        3          1      0  \n",
      "66               2          3         5        4          2      5  \n",
      "31               2          3         4        3          1      3  \n",
      "45               2          1         4        3          1      3  \n",
      "51               3          1         3        3          1      4  \n",
      "76               2          3         2        2          4      4  \n",
      "111              3          3         4        3          8      2  \n",
      "\n",
      "[29 rows x 32 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/student_prediction.csv\")\n",
    "df.rename(columns = {'KIDS':'PARENT_STATUS'}) #There is a column name error in the data noted in the Kaggle description, this fixes it.\n",
    "df = df.drop([\"STUDENTID\"], axis=1)\n",
    "print(f\"Data shape: \\n{df.shape}\\n\")\n",
    "print(f\"Data size: \\n{df.size}\\n\")\n",
    "print(f\"Data ndim: \\n{df.ndim}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "\n",
    "data_train, data_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "print(f\"Train Data shape: \\n{data_train}\\n\")\n",
    "print(f\"Test Data shape: \\n{data_test}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>HS_TYPE</th>\n",
       "      <th>SCHOLARSHIP</th>\n",
       "      <th>WORK</th>\n",
       "      <th>ACTIVITY</th>\n",
       "      <th>PARTNER</th>\n",
       "      <th>SALARY</th>\n",
       "      <th>TRANSPORT</th>\n",
       "      <th>LIVING</th>\n",
       "      <th>...</th>\n",
       "      <th>PREP_STUDY</th>\n",
       "      <th>PREP_EXAM</th>\n",
       "      <th>NOTES</th>\n",
       "      <th>LISTENS</th>\n",
       "      <th>LIKES_DISCUSS</th>\n",
       "      <th>CLASSROOM</th>\n",
       "      <th>CUML_GPA</th>\n",
       "      <th>EXP_GPA</th>\n",
       "      <th>COURSE ID</th>\n",
       "      <th>GRADE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AGE  GENDER  HS_TYPE  SCHOLARSHIP  WORK  ACTIVITY  PARTNER  SALARY  \\\n",
       "0      2       2        3            3     1         2        2       1   \n",
       "1      2       2        3            3     1         2        2       1   \n",
       "2      2       2        2            3     2         2        2       2   \n",
       "3      1       1        1            3     1         2        1       2   \n",
       "4      2       2        1            3     2         2        1       3   \n",
       "..   ...     ...      ...          ...   ...       ...      ...     ...   \n",
       "140    2       1        2            3     1         1        2       1   \n",
       "141    1       1        2            4     2         2        2       1   \n",
       "142    1       1        1            4     2         2        2       1   \n",
       "143    2       1        2            4     1         1        1       5   \n",
       "144    1       1        1            5     2         2        2       3   \n",
       "\n",
       "     TRANSPORT  LIVING  ...  PREP_STUDY  PREP_EXAM  NOTES  LISTENS  \\\n",
       "0            1       1  ...           1          1      3        2   \n",
       "1            1       1  ...           1          1      3        2   \n",
       "2            4       2  ...           1          1      2        2   \n",
       "3            1       2  ...           1          2      3        2   \n",
       "4            1       4  ...           2          1      2        2   \n",
       "..         ...     ...  ...         ...        ...    ...      ...   \n",
       "140          1       2  ...           1          1      2        1   \n",
       "141          4       2  ...           1          1      3        2   \n",
       "142          1       1  ...           1          1      3        3   \n",
       "143          2       3  ...           2          1      2        1   \n",
       "144          1       1  ...           2          1      3        2   \n",
       "\n",
       "     LIKES_DISCUSS  CLASSROOM  CUML_GPA  EXP_GPA  COURSE ID  GRADE  \n",
       "0                1          2         1        1          1      1  \n",
       "1                3          2         2        3          1      1  \n",
       "2                1          1         2        2          1      1  \n",
       "3                2          1         3        2          1      1  \n",
       "4                2          1         2        2          1      1  \n",
       "..             ...        ...       ...      ...        ...    ...  \n",
       "140              2          1         3        3          9      5  \n",
       "141              2          1         5        3          9      5  \n",
       "142              2          1         4        3          9      1  \n",
       "143              2          1         5        3          9      4  \n",
       "144              3          1         5        4          9      3  \n",
       "\n",
       "[145 rows x 32 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_train: \n",
      "     GRADE\n",
      "9        0\n",
      "4        1\n",
      "26       1\n",
      "120      1\n",
      "125      2\n",
      "..     ...\n",
      "71       6\n",
      "106      7\n",
      "14       2\n",
      "92       7\n",
      "102      7\n",
      "\n",
      "[116 rows x 1 columns]\n",
      "\n",
      "labels_test: \n",
      "     GRADE\n",
      "69       5\n",
      "140      5\n",
      "27       1\n",
      "19       3\n",
      "42       1\n",
      "117      1\n",
      "126      3\n",
      "108      6\n",
      "84       7\n",
      "18       2\n",
      "12       0\n",
      "55       3\n",
      "128      0\n",
      "78       4\n",
      "73       6\n",
      "36       2\n",
      "112      2\n",
      "133      3\n",
      "100      6\n",
      "101      7\n",
      "94       6\n",
      "136      0\n",
      "11       0\n",
      "66       5\n",
      "31       3\n",
      "45       3\n",
      "51       4\n",
      "76       4\n",
      "111      2\n",
      "\n",
      "features_train: \n",
      "     AGE  GENDER  HS_TYPE  SCHOLARSHIP  WORK  ACTIVITY  PARTNER  SALARY  \\\n",
      "9      2       1        2            3     2         2        1       3   \n",
      "4      2       2        1            3     2         2        1       3   \n",
      "26     2       2        2            3     2         1        1       1   \n",
      "120    2       1        1            3     1         1        1       2   \n",
      "125    1       1        2            5     1         1        2       1   \n",
      "..   ...     ...      ...          ...   ...       ...      ...     ...   \n",
      "71     1       1        3            4     2         2        2       1   \n",
      "106    1       2        2            4     2         1        2       1   \n",
      "14     3       2        2            4     1         1        2       3   \n",
      "92     1       2        2            3     2         2        2       1   \n",
      "102    1       2        2            3     2         2        1       1   \n",
      "\n",
      "     TRANSPORT  LIVING  ...  ATTEND  PREP_STUDY  PREP_EXAM  NOTES  LISTENS  \\\n",
      "9            4       2  ...       2           1          1      2        2   \n",
      "4            1       4  ...       1           2          1      2        2   \n",
      "26           1       1  ...       1           1          1      3        3   \n",
      "120          2       3  ...       2           2          1      3        3   \n",
      "125          1       3  ...       1           1          2      3        2   \n",
      "..         ...     ...  ...     ...         ...        ...    ...      ...   \n",
      "71           1       3  ...       1           1          1      2        3   \n",
      "106          1       2  ...       1           3          2      2        2   \n",
      "14           4       2  ...       1           1          1      2        3   \n",
      "92           1       1  ...       1           1          1      3        2   \n",
      "102          1       2  ...       1           1          1      3        1   \n",
      "\n",
      "     LIKES_DISCUSS  CLASSROOM  CUML_GPA  EXP_GPA  COURSE ID  \n",
      "9                2          2         1        2          1  \n",
      "4                2          1         2        2          1  \n",
      "26               3          2         2        1          1  \n",
      "120              3          2         2        2          8  \n",
      "125              3          1         1        3          9  \n",
      "..             ...        ...       ...      ...        ...  \n",
      "71               3          3         2        2          3  \n",
      "106              2          1         4        4          7  \n",
      "14               2          1         4        4          1  \n",
      "92               3          3         2        2          6  \n",
      "102              2          1         3        4          7  \n",
      "\n",
      "[116 rows x 31 columns]\n",
      "\n",
      "lfeatures_test: \n",
      "     AGE  GENDER  HS_TYPE  SCHOLARSHIP  WORK  ACTIVITY  PARTNER  SALARY  \\\n",
      "69     2       1        2            4     2         2        1       1   \n",
      "140    2       1        2            3     1         1        2       1   \n",
      "27     1       2        1            3     1         2        2       1   \n",
      "19     1       2        1            3     2         2        1       2   \n",
      "42     2       2        2            3     2         1        2       1   \n",
      "117    3       1        1            3     2         1        2       1   \n",
      "126    1       1        1            4     1         1        1       3   \n",
      "108    2       1        1            5     2         1        2       2   \n",
      "84     3       2        3            3     1         2        1       3   \n",
      "18     1       1        2            4     2         2        2       3   \n",
      "12     1       1        1            4     2         2        2       1   \n",
      "55     3       2        2            3     1         2        1       4   \n",
      "128    1       1        2            4     2         1        1       1   \n",
      "78     2       1        2            4     1         1        2       1   \n",
      "73     2       2        2            4     2         2        2       1   \n",
      "36     2       2        3            4     1         2        1       3   \n",
      "112    2       1        3            3     1         2        2       1   \n",
      "133    1       1        2            5     2         2        1       1   \n",
      "100    1       2        2            4     2         2        2       1   \n",
      "101    1       2        2            4     2         2        1       2   \n",
      "94     2       2        2            3     2         2        1       1   \n",
      "136    1       1        2            3     1         1        1       1   \n",
      "11     1       1        1            4     1         1        2       4   \n",
      "66     2       2        2            3     2         2        1       1   \n",
      "31     3       2        2            3     1         2        2       1   \n",
      "45     1       2        2            3     2         2        1       4   \n",
      "51     2       1        3            3     1         1        2       1   \n",
      "76     2       2        1            2     2         1        2       2   \n",
      "111    1       1        1            5     2         1        2       1   \n",
      "\n",
      "     TRANSPORT  LIVING  ...  ATTEND  PREP_STUDY  PREP_EXAM  NOTES  LISTENS  \\\n",
      "69           1       1  ...       1           2          1      3        2   \n",
      "140          1       2  ...       1           1          1      2        1   \n",
      "27           1       1  ...       2           1          1      3        1   \n",
      "19           2       2  ...       1           1          1      3        2   \n",
      "42           4       2  ...       1           1          1      2        1   \n",
      "117          1       2  ...       2           1          1      2        3   \n",
      "126          2       3  ...       1           2          1      3        3   \n",
      "108          2       1  ...       2           1          1      2        3   \n",
      "84           1       2  ...       1           3          3      3        3   \n",
      "18           1       1  ...       2           1          1      3        1   \n",
      "12           1       1  ...       1           1          1      2        2   \n",
      "55           1       2  ...       1           3          3      1        3   \n",
      "128          4       3  ...       1           1          1      3        2   \n",
      "78           1       1  ...       2           1          1      3        3   \n",
      "73           1       2  ...       1           1          2      3        2   \n",
      "36           1       1  ...       2           2          1      2        1   \n",
      "112          3       3  ...       1           2          1      3        3   \n",
      "133          1       1  ...       1           1          1      3        3   \n",
      "100          2       3  ...       1           1          1      2        2   \n",
      "101          1       3  ...       1           1          1      3        3   \n",
      "94           1       1  ...       1           1          1      3        2   \n",
      "136          2       3  ...       1           3          1      3        2   \n",
      "11           2       3  ...       1           3          2      3        1   \n",
      "66           1       1  ...       1           1          1      3        2   \n",
      "31           1       2  ...       1           1          1      3        3   \n",
      "45           1       1  ...       1           1          1      2        2   \n",
      "51           1       1  ...       2           1          1      2        3   \n",
      "76           1       1  ...       1           3          2      2        1   \n",
      "111          1       2  ...       1           1          1      3        1   \n",
      "\n",
      "     LIKES_DISCUSS  CLASSROOM  CUML_GPA  EXP_GPA  COURSE ID  \n",
      "69               3          1         3        2          3  \n",
      "140              2          1         3        3          9  \n",
      "27               2          1         2        1          1  \n",
      "19               2          3         2        3          1  \n",
      "42               3          1         2        3          1  \n",
      "117              2          1         2        3          8  \n",
      "126              3          1         2        2          9  \n",
      "108              1          2         3        3          7  \n",
      "84               3          3         5        4          5  \n",
      "18               3          3         3        3          1  \n",
      "12               2          3         4        2          1  \n",
      "55               3          3         5        4          1  \n",
      "128              2          1         2        2          9  \n",
      "78               2          2         2        2          4  \n",
      "73               3          1         5        3          3  \n",
      "36               2          1         4        3          1  \n",
      "112              3          1         4        2          8  \n",
      "133              3          2         5        3          9  \n",
      "100              2          1         3        3          7  \n",
      "101              2          1         2        3          7  \n",
      "94               2          3         5        4          6  \n",
      "136              2          1         2        2          9  \n",
      "11               3          3         4        3          1  \n",
      "66               2          3         5        4          2  \n",
      "31               2          3         4        3          1  \n",
      "45               2          1         4        3          1  \n",
      "51               3          1         3        3          1  \n",
      "76               2          3         2        2          4  \n",
      "111              3          3         4        3          8  \n",
      "\n",
      "[29 rows x 31 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Extracting Labels\n",
    "\n",
    "columns = data_train.columns.to_list()\n",
    "columns_drop = columns.pop(-1)\n",
    "labels_train = data_train.drop(columns, axis=1)\n",
    "labels_test = data_test.drop(columns, axis=1)\n",
    "\n",
    "print(f\"labels_train: \\n{labels_train}\\n\")\n",
    "print(f\"labels_test: \\n{labels_test}\\n\")\n",
    "\n",
    "features_train = data_train.drop(['GRADE'], axis=1)\n",
    "features_test = data_test.drop(['GRADE'], axis=1)\n",
    "print(f\"features_train: \\n{features_train }\\n\")\n",
    "print(f\"lfeatures_test: \\n{features_test }\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     AGE_1  AGE_2  AGE_3  GENDER_1  GENDER_2  HS_TYPE_1  HS_TYPE_2  HS_TYPE_3  \\\n",
      "9      0.0    1.0    0.0       1.0       0.0        0.0        1.0        0.0   \n",
      "4      0.0    1.0    0.0       0.0       1.0        1.0        0.0        0.0   \n",
      "26     0.0    1.0    0.0       0.0       1.0        0.0        1.0        0.0   \n",
      "120    0.0    1.0    0.0       1.0       0.0        1.0        0.0        0.0   \n",
      "125    1.0    0.0    0.0       1.0       0.0        0.0        1.0        0.0   \n",
      "..     ...    ...    ...       ...       ...        ...        ...        ...   \n",
      "71     1.0    0.0    0.0       1.0       0.0        0.0        0.0        1.0   \n",
      "106    1.0    0.0    0.0       0.0       1.0        0.0        1.0        0.0   \n",
      "14     0.0    0.0    1.0       0.0       1.0        0.0        1.0        0.0   \n",
      "92     1.0    0.0    0.0       0.0       1.0        0.0        1.0        0.0   \n",
      "102    1.0    0.0    0.0       0.0       1.0        0.0        1.0        0.0   \n",
      "\n",
      "     SCHOLARSHIP_1  SCHOLARSHIP_2  ...  EXP_GPA_4  COURSE ID_1  COURSE ID_2  \\\n",
      "9              0.0            0.0  ...        0.0          1.0          0.0   \n",
      "4              0.0            0.0  ...        0.0          1.0          0.0   \n",
      "26             0.0            0.0  ...        0.0          1.0          0.0   \n",
      "120            0.0            0.0  ...        0.0          0.0          0.0   \n",
      "125            0.0            0.0  ...        0.0          0.0          0.0   \n",
      "..             ...            ...  ...        ...          ...          ...   \n",
      "71             0.0            0.0  ...        0.0          0.0          0.0   \n",
      "106            0.0            0.0  ...        1.0          0.0          0.0   \n",
      "14             0.0            0.0  ...        1.0          1.0          0.0   \n",
      "92             0.0            0.0  ...        0.0          0.0          0.0   \n",
      "102            0.0            0.0  ...        1.0          0.0          0.0   \n",
      "\n",
      "     COURSE ID_3  COURSE ID_4  COURSE ID_5  COURSE ID_6  COURSE ID_7  \\\n",
      "9            0.0          0.0          0.0          0.0          0.0   \n",
      "4            0.0          0.0          0.0          0.0          0.0   \n",
      "26           0.0          0.0          0.0          0.0          0.0   \n",
      "120          0.0          0.0          0.0          0.0          0.0   \n",
      "125          0.0          0.0          0.0          0.0          0.0   \n",
      "..           ...          ...          ...          ...          ...   \n",
      "71           1.0          0.0          0.0          0.0          0.0   \n",
      "106          0.0          0.0          0.0          0.0          1.0   \n",
      "14           0.0          0.0          0.0          0.0          0.0   \n",
      "92           0.0          0.0          0.0          1.0          0.0   \n",
      "102          0.0          0.0          0.0          0.0          1.0   \n",
      "\n",
      "     COURSE ID_8  COURSE ID_9  \n",
      "9            0.0          0.0  \n",
      "4            0.0          0.0  \n",
      "26           0.0          0.0  \n",
      "120          1.0          0.0  \n",
      "125          0.0          1.0  \n",
      "..           ...          ...  \n",
      "71           0.0          0.0  \n",
      "106          0.0          0.0  \n",
      "14           0.0          0.0  \n",
      "92           0.0          0.0  \n",
      "102          0.0          0.0  \n",
      "\n",
      "[116 rows x 112 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ohenc = OneHotEncoder(sparse=False)\n",
    "ohenc_cols = ohenc.fit(features_train).get_feature_names_out()\n",
    "\n",
    "data_prepared = pd.DataFrame(ohenc.fit_transform(features_train),columns=ohenc_cols, index=features_train.index)\n",
    "#full_pipeline.fit_transform(data_train)\n",
    "#pd.DataFrame(full_pipeline.fit_transform(train_df),columns=train_df.columns, index=train_df.index)\n",
    "print(data_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the following four different models with their default hyperparameter values to be trained using the preprocessed data (0.5 * 4)\n",
    "labelTrainFlat = labels_train.values.ravel()\n",
    "# Gradient Boosting\n",
    "gradientBoosting = GradientBoostingClassifier()\n",
    "gradientBoosting = gradientBoosting.fit(data_prepared, labelTrainFlat)\n",
    "\n",
    "# Decision Trees\n",
    "decisionTree = DecisionTreeClassifier()\n",
    "decisionTree = decisionTree.fit(data_prepared,labelTrainFlat)\n",
    "\n",
    "# Random Forests\n",
    "randomForest = RandomForestClassifier()\n",
    "randomForest = randomForest.fit(data_prepared,labelTrainFlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters GradientBoosting: \n",
      "{'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "\n",
      "Best estimator GradientBoosting: \n",
      "GradientBoostingClassifier(n_estimators=10)\n",
      "\n",
      "Best score GradientBoosting: \n",
      "0.365530303030303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parametersGradientBoosting = [\n",
    "    {'min_samples_leaf': [0.00001, 1,2,4, 10],'min_samples_split': [2,3,4], 'n_estimators': [10,100,50, 120]}\n",
    "]\n",
    "scoringX = {\"accuracy\": \"accuracy\", \"bal_accuracy\": \"balanced_accuracy\", \"F1_macro\": \"f1_macro\"}\n",
    "\n",
    "grid_searchGradientBoosting = GridSearchCV(gradientBoosting, parametersGradientBoosting, cv=3, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "grid_searchGradientBoosting.fit(data_prepared, labelTrainFlat)\n",
    "\n",
    "print(f\"Best parameters GradientBoosting: \\n{grid_searchGradientBoosting.best_params_}\\n\")\n",
    "print(f\"Best estimator GradientBoosting: \\n{grid_searchGradientBoosting.best_estimator_}\\n\")\n",
    "print(f\"Best score GradientBoosting: \\n{grid_searchGradientBoosting.best_score_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametersDecisionTree = [\n",
    "    {'max_depth': [1,2,3,4], 'min_samples_leaf': [4,5,6], 'min_samples_split': [1,2,3]}\n",
    "]\n",
    "\n",
    "grid_searchDecisionTree = GridSearchCV(decisionTree, parametersDecisionTree, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "grid_searchDecisionTree.fit(data_prepared, labelTrainFlat)\n",
    "\n",
    "print(f\"Best parameters DecisionTree: \\n{grid_searchDecisionTree.best_params_}\\n\")\n",
    "print(f\"Best estimator DecisionTree: \\n{grid_searchDecisionTree.best_estimator_}\\n\")\n",
    "print(f\"Best score DecisionTree: \\n{grid_searchDecisionTree.best_score_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters RandomForest: \n",
      "{'bootstrap': False, 'max_depth': 333, 'n_estimators': 155}\n",
      "\n",
      "Best estimator RandomForest: \n",
      "RandomForestClassifier(bootstrap=False, max_depth=333, n_estimators=155)\n",
      "\n",
      "Best score RandomForest: \n",
      "0.32161458333333337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parametersRandomForest = [\n",
    "    {'n_estimators': [145,150,155,190],'max_depth': [5,6,7], 'bootstrap': [True, False]}\n",
    "]\n",
    "\n",
    "grid_searchRandomForest = GridSearchCV(randomForest, parametersRandomForest, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "grid_searchRandomForest.fit(data_prepared, labelTrainFlat)\n",
    "\n",
    "print(f\"Best parameters RandomForest: \\n{grid_searchRandomForest.best_params_}\\n\")\n",
    "\n",
    "print(f\"Best estimator RandomForest: \\n{grid_searchRandomForest.best_estimator_}\\n\")\n",
    "\n",
    "print(f\"Best score RandomForest: \\n{grid_searchRandomForest.best_score_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test Accuracy for GradientBoosting: \n",
      "[0.42150247 0.35267656 0.36122357 0.33558255 0.38731444 0.34390463\n",
      " 0.38708952 0.34390463 0.3699955  0.31848853 0.34435448 0.36167341\n",
      " 0.4217274  0.35290148 0.3699955  0.33558255 0.39608637 0.33535762\n",
      " 0.39608637 0.3699955  0.39586145 0.31848853 0.3699955  0.3097166\n",
      " 0.37854251 0.35357625 0.3879892  0.35380117 0.37854251 0.35380117\n",
      " 0.37089519 0.34502924 0.35290148 0.37089519 0.37112011 0.36234818\n",
      " 0.35245164 0.37899235 0.31826361 0.35312641 0.36077373 0.31871345\n",
      " 0.30994152 0.35335133 0.36954566 0.33625731 0.34412955 0.32726046\n",
      " 0.34435448 0.34435448 0.36977058 0.34435448 0.34435448 0.34435448\n",
      " 0.36977058 0.33580747 0.34435448 0.36144849 0.36977058 0.35290148]\n",
      "\n",
      "Balanced Test Accuracy for GradientBoosting: \n",
      "[0.32564935 0.27624459 0.29237915 0.2508658  0.29945887 0.25995671\n",
      " 0.30727814 0.26489899 0.27108586 0.2385101  0.26559343 0.28017677\n",
      " 0.3655303  0.26614358 0.29090909 0.25440115 0.29646465 0.26450216\n",
      " 0.31422258 0.2895202  0.29370491 0.24305556 0.29160354 0.23611111\n",
      " 0.29446248 0.27166306 0.32239358 0.26372655 0.29446248 0.29451659\n",
      " 0.31443903 0.27450397 0.26489899 0.3113456  0.31088564 0.31094877\n",
      " 0.31648629 0.34474206 0.30165043 0.28857323 0.32281746 0.28668831\n",
      " 0.29786255 0.28640873 0.32660534 0.27666847 0.32464827 0.30335498\n",
      " 0.24172078 0.3100018  0.31966089 0.31553932 0.24172078 0.3100018\n",
      " 0.31966089 0.30720599 0.24172078 0.32212302 0.31966089 0.3214917 ]\n",
      "\n",
      "Mean F1 Macro for GradientBoosting: \n",
      "[0.30887731 0.27533102 0.29003205 0.24109239 0.28323266 0.24722823\n",
      " 0.30622391 0.25693529 0.24834957 0.22822111 0.2608053  0.27325993\n",
      " 0.32438272 0.2622955  0.28353616 0.24291158 0.27579126 0.25626119\n",
      " 0.30920533 0.28462997 0.27107152 0.2374219  0.28660002 0.22887807\n",
      " 0.2856768  0.25557714 0.30715473 0.24544454 0.2857582  0.26422258\n",
      " 0.28806387 0.26060486 0.24588152 0.2802768  0.28146571 0.28255982\n",
      " 0.29296968 0.32859279 0.2915421  0.27854076 0.30523995 0.26732585\n",
      " 0.29170761 0.28408402 0.30895768 0.26828004 0.31107595 0.28825679\n",
      " 0.21444137 0.26874486 0.30030119 0.26596031 0.21444137 0.26874486\n",
      " 0.30030119 0.26498391 0.21444137 0.28169932 0.30030119 0.27741864]\n",
      "\n",
      "Mean Test Accuracy for Decision Trees: \n",
      "[       nan 0.34482759 0.34482759        nan 0.34482759 0.34482759\n",
      "        nan 0.34482759 0.34482759        nan 0.35344828 0.35344828\n",
      "        nan 0.37931034 0.37931034        nan 0.37068966 0.37068966\n",
      "        nan 0.3362069  0.3362069         nan 0.37068966 0.37068966\n",
      "        nan 0.34482759 0.34482759        nan 0.30172414 0.30172414\n",
      "        nan 0.27586207 0.27586207        nan 0.27586207 0.25862069]\n",
      "\n",
      "Balanced Test Accuracy for Decision Trees: \n",
      "[       nan 0.19270833 0.19270833        nan 0.19270833 0.19270833\n",
      "        nan 0.19270833 0.19270833        nan 0.21223958 0.21223958\n",
      "        nan 0.24088542 0.24088542        nan 0.22526042 0.22526042\n",
      "        nan 0.19140625 0.19140625        nan 0.23515625 0.23515625\n",
      "        nan 0.22291667 0.22291667        nan 0.21041667 0.21041667\n",
      "        nan 0.20807292 0.20807292        nan 0.20104167 0.19322917]\n",
      "\n",
      "Mean F1 Macro for Decision Trees: \n",
      "[       nan 0.13322829 0.13322829        nan 0.13322829 0.13322829\n",
      "        nan 0.13322829 0.13322829        nan 0.150821   0.150821\n",
      "        nan 0.18648118 0.18648118        nan 0.16993706 0.16993706\n",
      "        nan 0.1414831  0.1414831         nan 0.1957425  0.1957425\n",
      "        nan 0.19435361 0.19435361        nan 0.18870035 0.18870035\n",
      "        nan 0.19668532 0.19668532        nan 0.1787115  0.17251955]\n",
      "\n",
      "Mean Test Accuracy for Random Forests: \n",
      "[0.35344828 0.34482759 0.36206897 0.35344828 0.34482759 0.37931034\n",
      " 0.3362069  0.37068966 0.34482759 0.37068966 0.35344828 0.34482759\n",
      " 0.35344828 0.37931034 0.4137931  0.36206897 0.40517241 0.39655172\n",
      " 0.39655172 0.42241379 0.37931034 0.38793103 0.40517241 0.43103448\n",
      " 0.38793103 0.38793103 0.4137931  0.39655172 0.4137931  0.39655172\n",
      " 0.43965517 0.38793103]\n",
      "\n",
      "Balanced Test Accuracy for Random Forests: \n",
      "[0.20885417 0.21015625 0.2375     0.22708333 0.21770833 0.25442708\n",
      " 0.20989583 0.24739583 0.2296875  0.24427083 0.22291667 0.22291667\n",
      " 0.24375    0.25572917 0.27734375 0.25338542 0.284375   0.275\n",
      " 0.27890625 0.2984375  0.275      0.28697917 0.29869792 0.31119792\n",
      " 0.28671875 0.28020833 0.2921875  0.284375   0.30598958 0.31171875\n",
      " 0.32161458 0.28776042]\n",
      "\n",
      "Mean F1 Macro for Random Forests: \n",
      "[0.17579445 0.1686385  0.22382733 0.18956281 0.19237736 0.21743882\n",
      " 0.18084996 0.22330237 0.20287698 0.21689346 0.1910769  0.19523591\n",
      " 0.22688124 0.24283257 0.2460775  0.22271924 0.24943641 0.25645674\n",
      " 0.25956469 0.27893954 0.25576161 0.27108657 0.2888438  0.28787451\n",
      " 0.26014791 0.25315657 0.26785587 0.25776786 0.28559659 0.28731754\n",
      " 0.30052012 0.27270595]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the grid search cross-validation results listing the above mentioned evaluation methods (3)\n",
    "cross_val_resultsGB = grid_searchGradientBoosting.cv_results_\n",
    "cross_val_resultsDT = grid_searchDecisionTree.cv_results_\n",
    "cross_val_resultsRF = grid_searchRandomForest.cv_results_\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Mean Test Accuracy for GradientBoosting: \\n{cross_val_resultsGB['mean_test_accuracy']}\\n\")\n",
    "print(f\"Balanced Test Accuracy for GradientBoosting: \\n{cross_val_resultsGB['mean_test_bal_accuracy']}\\n\")\n",
    "print(f\"Mean F1 Macro for GradientBoosting: \\n{cross_val_resultsGB['mean_test_F1_macro']}\\n\")\n",
    "\n",
    "#DTC\n",
    "print(f\"Mean Test Accuracy for Decision Trees: \\n{cross_val_resultsDT['mean_test_accuracy']}\\n\")\n",
    "print(f\"Balanced Test Accuracy for Decision Trees: \\n{cross_val_resultsDT['mean_test_bal_accuracy']}\\n\")\n",
    "print(f\"Mean F1 Macro for Decision Trees: \\n{cross_val_resultsDT['mean_test_F1_macro']}\\n\")\n",
    "\n",
    "#RFC\n",
    "print(f\"Mean Test Accuracy for Random Forests: \\n{cross_val_resultsRF['mean_test_accuracy']}\\n\")\n",
    "print(f\"Balanced Test Accuracy for Random Forests: \\n{cross_val_resultsRF['mean_test_bal_accuracy']}\\n\")\n",
    "print(f\"Mean F1 Macro for Random Forests: \\n{cross_val_resultsRF['mean_test_F1_macro']}\\n\")\n",
    "\n",
    "#NB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Prediction: \n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1]\n",
      "\n",
      "Dummy Score: \n",
      "0.27586206896551724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use a dummy classifier to identify a simple baseline (i.e., a majority class baseline) so that you can compare your prediction results (3)\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(data_prepared, labelTrainFlat)\n",
    "DummyClassifier(strategy='most_frequent')\n",
    "print(f\"Dummy Prediction: \\n{dummy_clf.predict(data_prepared)}\\n\") \n",
    "print(f\"Dummy Score: \\n{dummy_clf.score(data_prepared, labelTrainFlat)}\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AGE_1' 'AGE_2' 'AGE_3' 'GENDER_1' 'GENDER_2' 'HS_TYPE_1' 'HS_TYPE_2'\n",
      " 'HS_TYPE_3' 'SCHOLARSHIP_2' 'SCHOLARSHIP_3' 'SCHOLARSHIP_4'\n",
      " 'SCHOLARSHIP_5' 'WORK_1' 'WORK_2' 'ACTIVITY_1' 'ACTIVITY_2' 'PARTNER_1'\n",
      " 'PARTNER_2' 'SALARY_1' 'SALARY_2' 'SALARY_3' 'SALARY_4' 'TRANSPORT_1'\n",
      " 'TRANSPORT_2' 'TRANSPORT_3' 'TRANSPORT_4' 'LIVING_1' 'LIVING_2'\n",
      " 'LIVING_3' 'MOTHER_EDU_1' 'MOTHER_EDU_2' 'MOTHER_EDU_3' 'MOTHER_EDU_4'\n",
      " 'MOTHER_EDU_5' 'FATHER_EDU_1' 'FATHER_EDU_2' 'FATHER_EDU_3'\n",
      " 'FATHER_EDU_4' 'FATHER_EDU_5' 'FATHER_EDU_6' '#_SIBLINGS_1'\n",
      " '#_SIBLINGS_2' '#_SIBLINGS_3' '#_SIBLINGS_4' '#_SIBLINGS_5' 'KIDS_1'\n",
      " 'KIDS_2' 'KIDS_3' 'MOTHER_JOB_1' 'MOTHER_JOB_2' 'MOTHER_JOB_3'\n",
      " 'MOTHER_JOB_4' 'FATHER_JOB_1' 'FATHER_JOB_2' 'FATHER_JOB_3'\n",
      " 'FATHER_JOB_4' 'FATHER_JOB_5' 'STUDY_HRS_1' 'STUDY_HRS_2' 'STUDY_HRS_3'\n",
      " 'STUDY_HRS_4' 'STUDY_HRS_5' 'READ_FREQ_1' 'READ_FREQ_2' 'READ_FREQ_3'\n",
      " 'READ_FREQ_SCI_1' 'READ_FREQ_SCI_2' 'READ_FREQ_SCI_3' 'ATTEND_DEPT_1'\n",
      " 'ATTEND_DEPT_2' 'IMPACT_1' 'IMPACT_2' 'IMPACT_3' 'ATTEND_1' 'ATTEND_2'\n",
      " 'PREP_STUDY_1' 'PREP_STUDY_2' 'PREP_STUDY_3' 'PREP_EXAM_1' 'PREP_EXAM_2'\n",
      " 'PREP_EXAM_3' 'NOTES_1' 'NOTES_2' 'NOTES_3' 'LISTENS_1' 'LISTENS_2'\n",
      " 'LISTENS_3' 'LIKES_DISCUSS_1' 'LIKES_DISCUSS_2' 'LIKES_DISCUSS_3'\n",
      " 'CLASSROOM_1' 'CLASSROOM_2' 'CLASSROOM_3' 'CUML_GPA_2' 'CUML_GPA_3'\n",
      " 'CUML_GPA_4' 'CUML_GPA_5' 'EXP_GPA_1' 'EXP_GPA_2' 'EXP_GPA_3' 'EXP_GPA_4'\n",
      " 'COURSE ID_1' 'COURSE ID_2' 'COURSE ID_3' 'COURSE ID_4' 'COURSE ID_5'\n",
      " 'COURSE ID_6' 'COURSE ID_7' 'COURSE ID_8' 'COURSE ID_9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- FATHER_EDU_6\n",
      "- MOTHER_EDU_5\n",
      "- PREP_EXAM_3\n",
      "- TRANSPORT_3\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- CUML_GPA_1\n",
      "- LIVING_4\n",
      "- MOTHER_EDU_6\n",
      "- MOTHER_JOB_5\n",
      "- SALARY_5\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 110 features, but GradientBoostingClassifier is expecting 112 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\adamj\\Documents\\GitHub\\StudentPerformanceCSI4106\\StudentPerformance.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/StudentPerformanceCSI4106/StudentPerformance.ipynb#ch0000012?line=2'>3</a>\u001b[0m data_prepared_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(ohenc\u001b[39m.\u001b[39mfit_transform(features_test),columns\u001b[39m=\u001b[39mohenc_cols_test, index\u001b[39m=\u001b[39mfeatures_test\u001b[39m.\u001b[39mindex)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/StudentPerformanceCSI4106/StudentPerformance.ipynb#ch0000012?line=4'>5</a>\u001b[0m \u001b[39m# obtain predictions on test data using the best model from GridSearchCV (i.e., .best_estimator_) (2)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/StudentPerformanceCSI4106/StudentPerformance.ipynb#ch0000012?line=5'>6</a>\u001b[0m predictions_test \u001b[39m=\u001b[39m grid_searchGradientBoosting\u001b[39m.\u001b[39;49mbest_estimator_\u001b[39m.\u001b[39;49mpredict(data_prepared_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/StudentPerformanceCSI4106/StudentPerformance.ipynb#ch0000012?line=7'>8</a>\u001b[0m \u001b[39m# generate the classification report and the confusion matrix for test predictions (3)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adamj/Documents/GitHub/StudentPerformanceCSI4106/StudentPerformance.ipynb#ch0000012?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(classification_report(labels_test\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mravel(),predictions_test))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1359\u001b[0m, in \u001b[0;36mGradientBoostingClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=1343'>1344</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m   <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=1344'>1345</a>\u001b[0m     \u001b[39m\"\"\"Predict class for X.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=1345'>1346</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=1346'>1347</a>\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=1356'>1357</a>\u001b[0m \u001b[39m        The predicted values.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=1357'>1358</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=1358'>1359</a>\u001b[0m     raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[0;32m   <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=1359'>1360</a>\u001b[0m     encoded_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_\u001b[39m.\u001b[39m_raw_prediction_to_decision(raw_predictions)\n\u001b[0;32m   <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=1360'>1361</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(encoded_labels, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1312\u001b[0m, in \u001b[0;36mGradientBoostingClassifier.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=1292'>1293</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecision_function\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m   <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=1293'>1294</a>\u001b[0m     \u001b[39m\"\"\"Compute the decision function of ``X``.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=1294'>1295</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=1295'>1296</a>\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=1309'>1310</a>\u001b[0m \u001b[39m        array of shape (n_samples,).\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=1310'>1311</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=1311'>1312</a>\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=1312'>1313</a>\u001b[0m         X, dtype\u001b[39m=\u001b[39;49mDTYPE, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=1313'>1314</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=1314'>1315</a>\u001b[0m     raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raw_predict(X)\n\u001b[0;32m   <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/ensemble/_gb.py?line=1315'>1316</a>\u001b[0m     \u001b[39mif\u001b[39;00m raw_predictions\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/base.py?line=581'>582</a>\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/base.py?line=583'>584</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/base.py?line=584'>585</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/base.py?line=586'>587</a>\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/base.py?line=396'>397</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/base.py?line=398'>399</a>\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/base.py?line=399'>400</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/base.py?line=400'>401</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/base.py?line=401'>402</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/adamj/AppData/Local/Programs/Python/Python310/lib/site-packages/sklearn/base.py?line=402'>403</a>\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 110 features, but GradientBoostingClassifier is expecting 112 features as input."
     ]
    }
   ],
   "source": [
    "\n",
    "ohenc_cols_test = ohenc.fit(features_test).get_feature_names_out()\n",
    "print(ohenc_cols_test)\n",
    "data_prepared_test = pd.DataFrame(ohenc.fit_transform(features_test),columns=ohenc_cols_test, index=features_test.index)\n",
    "\n",
    "# obtain predictions on test data using the best model from GridSearchCV (i.e., .best_estimator_) (2)\n",
    "predictions_test = grid_searchGradientBoosting.best_estimator_.predict(data_prepared_test)\n",
    "\n",
    "# generate the classification report and the confusion matrix for test predictions (3)\n",
    "print(classification_report(labels_test.values.ravel(),predictions_test))\n",
    "print(confusion_matrix(labels_test, predictions_test))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af4e0a0d28143374aa5d305078a03b698686e6b7df811af5a427e46b8cc107ac"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
