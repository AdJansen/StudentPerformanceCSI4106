{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FN score he got was around 90% in macro, more then 80\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "# we can use the LabelEncoder to encode the gender feature\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, cross_val_score, GridSearchCV, cross_validate\n",
    "\n",
    "# importing two different imputation methods that take into consideration all the features when predicting the missing values\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#multiclass imports\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.dummy import DummyClassifier #Will identify the maority calss base line, model needs to do better then the baseline\n",
    "\n",
    "# oversample the minority class using SMOTE\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "# to reduce randomness then you put the seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Data shape: \n",
      "(145, 31)\n",
      "\n",
      "Data size: \n",
      "4495\n",
      "\n",
      "Data ndim: \n",
      "2\n",
      "\n",
      "_____________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/student_prediction.csv\")\n",
    "\n",
    "df = df.rename(columns = {'KIDS':'PARENT_STATUS'}) #There is a column name error in the data noted in the Kaggle description, this fixes it.\n",
    "df = df.drop([\"STUDENTID\", \"COURSE ID\"], axis=1)\n",
    "\n",
    "gathered_df = pd.read_csv(\"./data/Higher Education Students Performance Evaluation.csv\")\n",
    "gathered_df = gathered_df.rename(columns = {'KIDS':'PARENT_STATUS'})\n",
    "res = list(set(df).difference(set(gathered_df)))\n",
    "print(res)\n",
    "#df = pd.concat([df, gathered_df], axis=0)\n",
    "print(f\"Data shape: \\n{df.shape}\\n\")\n",
    "print(f\"Data size: \\n{df.size}\\n\")\n",
    "print(f\"Data ndim: \\n{df.ndim}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampled Data shape: \n",
      "(280, 31)\n",
      "\n",
      "Oversampled Data size: \n",
      "8680\n",
      "\n",
      "Oversampled Data ndim: \n",
      "2\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "New Class Distribution: Counter({1: 35, 2: 35, 5: 35, 0: 35, 3: 35, 4: 35, 7: 35, 6: 35})\n",
      "_____________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oversample = SMOTE()\n",
    "x_over, y_over = oversample.fit_resample(df.drop([\"GRADE\"], axis=1), df.drop(df.columns[0:-1],axis=1))\n",
    "df = pd.concat([x_over, y_over], axis=1)\n",
    "\n",
    "# print the dimensionality of the oversampled training dataset (0.5)\n",
    "print(f\"Oversampled Data shape: \\n{df.shape}\\n\")\n",
    "print(f\"Oversampled Data size: \\n{df.size}\\n\")\n",
    "print(f\"Oversampled Data ndim: \\n{df.ndim}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "\n",
    "\n",
    "# print the new class distribution using the Counter (1)\n",
    "print(f\"New Class Distribution: {Counter(df['GRADE'])}\")\n",
    "print(\"_____________________________________________\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data shape: \n",
      "     AGE  GENDER  HS_TYPE  SCHOLARSHIP  WORK  ACTIVITY  PARTNER  SALARY  \\\n",
      "86     2       2        2            4     2         2        2       1   \n",
      "137    1       1        1            5     2         1        2       1   \n",
      "184    2       2        2            4     1         2        2       1   \n",
      "5      2       2        2            3     2         2        2       2   \n",
      "124    1       1        2            4     1         1        1       1   \n",
      "..   ...     ...      ...          ...   ...       ...      ...     ...   \n",
      "188    1       2        2            3     1         2        1       4   \n",
      "71     1       1        3            4     2         2        2       1   \n",
      "106    1       2        2            4     2         1        2       1   \n",
      "270    1       2        2            4     2         1        1       1   \n",
      "102    1       2        2            3     2         2        1       1   \n",
      "\n",
      "     TRANSPORT  LIVING  ...  ATTEND  PREP_STUDY  PREP_EXAM  NOTES  LISTENS  \\\n",
      "86           4       2  ...       1           1          1      3        2   \n",
      "137          1       1  ...       1           1          1      3        1   \n",
      "184          1       1  ...       1           1          1      3        2   \n",
      "5            1       1  ...       1           1          1      1        2   \n",
      "124          1       3  ...       1           2          2      3        3   \n",
      "..         ...     ...  ...     ...         ...        ...    ...      ...   \n",
      "188          1       1  ...       1           1          1      1        2   \n",
      "71           1       3  ...       1           1          1      2        3   \n",
      "106          1       2  ...       1           3          2      2        2   \n",
      "270          1       2  ...       1           1          1      3        2   \n",
      "102          1       2  ...       1           1          1      3        1   \n",
      "\n",
      "     LIKES_DISCUSS  CLASSROOM  CUML_GPA  EXP_GPA  GRADE  \n",
      "86               3          2         5        4      5  \n",
      "137              3          1         2        4      2  \n",
      "184              2          1         4        3      3  \n",
      "5                1          2         4        4      2  \n",
      "124              2          1         3        3      3  \n",
      "..             ...        ...       ...      ...    ...  \n",
      "188              2          1         4        3      3  \n",
      "71               3          3         2        2      6  \n",
      "106              2          1         4        4      7  \n",
      "270              3          2         2        3      7  \n",
      "102              2          1         3        4      7  \n",
      "\n",
      "[224 rows x 31 columns]\n",
      "\n",
      "Test Data shape: \n",
      "     AGE  GENDER  HS_TYPE  SCHOLARSHIP  WORK  ACTIVITY  PARTNER  SALARY  \\\n",
      "33     2       1        2            3     1         2        1       1   \n",
      "108    2       1        1            5     2         1        2       2   \n",
      "240    1       2        2            3     1         1        2       1   \n",
      "259    1       1        2            4     1         1        2       1   \n",
      "154    1       1        1            3     1         1        1       1   \n",
      "9      2       1        2            3     2         2        1       3   \n",
      "146    1       1        1            3     1         1        1       1   \n",
      "203    1       2        2            4     1         1        2       1   \n",
      "144    1       1        1            5     2         2        2       3   \n",
      "155    1       1        1            4     2         1        1       1   \n",
      "221    1       1        2            1     1         2        1       1   \n",
      "92     1       2        2            3     2         2        2       1   \n",
      "222    2       1        2            3     1         1        1       1   \n",
      "209    1       2        2            2     1         2        1       1   \n",
      "42     2       2        2            3     2         1        2       1   \n",
      "210    2       1        2            3     1         1        1       1   \n",
      "66     2       2        2            3     2         2        1       1   \n",
      "90     2       1        2            3     2         1        1       1   \n",
      "119    2       1        2            4     2         1        2       1   \n",
      "142    1       1        1            4     2         2        2       1   \n",
      "262    1       2        2            3     1         2        1       1   \n",
      "268    1       2        2            3     2         1        1       1   \n",
      "206    2       1        2            3     1         1        2       1   \n",
      "238    2       1        2            4     1         1        1       1   \n",
      "46     2       2        2            3     2         2        1       1   \n",
      "77     1       2        1            2     2         2        1       2   \n",
      "68     2       1        2            4     1         2        2       1   \n",
      "75     1       2        2            4     2         1        2       1   \n",
      "216    2       2        1            2     1         1        2       1   \n",
      "277    1       2        1            2     2         2        1       2   \n",
      "45     1       2        2            3     2         2        1       4   \n",
      "111    1       1        1            5     2         1        2       1   \n",
      "60     2       1        2            3     2         2        2       5   \n",
      "217    2       1        2            3     1         1        1       1   \n",
      "143    2       1        2            4     1         1        1       5   \n",
      "30     2       2        2            5     1         1        1       1   \n",
      "22     2       2        2            3     1         2        1       1   \n",
      "24     2       2        2            3     2         2        2       2   \n",
      "127    1       1        2            4     2         2        2       1   \n",
      "176    1       2        2            3     1         2        1       3   \n",
      "79     2       2        2            4     2         2        2       1   \n",
      "264    1       2        1            3     2         1        1       1   \n",
      "237    2       1        2            4     2         2        1       1   \n",
      "120    2       1        1            3     1         1        1       2   \n",
      "196    1       1        1            3     1         1        1       1   \n",
      "245    1       1        2            3     1         1        1       1   \n",
      "168    1       1        1            4     2         1        1       1   \n",
      "6      1       2        2            4     2         2        2       1   \n",
      "239    2       1        2            3     1         2        1       1   \n",
      "73     2       2        2            4     2         2        2       1   \n",
      "84     3       2        3            3     1         2        1       3   \n",
      "56     2       2        2            3     2         1        2       1   \n",
      "25     2       2        2            3     2         2        1       1   \n",
      "97     1       2        2            4     1         2        2       1   \n",
      "147    1       1        1            4     1         2        1       1   \n",
      "19     1       2        1            3     2         2        1       2   \n",
      "\n",
      "     TRANSPORT  LIVING  ...  ATTEND  PREP_STUDY  PREP_EXAM  NOTES  LISTENS  \\\n",
      "33           1       1  ...       1           1          1      1        3   \n",
      "108          2       1  ...       2           1          1      2        3   \n",
      "240          1       2  ...       1           1          1      2        2   \n",
      "259          1       3  ...       1           1          1      2        3   \n",
      "154          1       1  ...       1           1          1      2        2   \n",
      "9            4       2  ...       2           1          1      2        2   \n",
      "146          1       2  ...       1           2          1      2        2   \n",
      "203          1       1  ...       1           1          1      3        2   \n",
      "144          1       1  ...       1           2          1      3        2   \n",
      "155          2       1  ...       1           1          1      2        2   \n",
      "221          1       1  ...       1           1          1      2        3   \n",
      "92           1       1  ...       1           1          1      3        2   \n",
      "222          1       2  ...       1           1          1      2        1   \n",
      "209          1       1  ...       1           1          1      3        1   \n",
      "42           4       2  ...       1           1          1      2        1   \n",
      "210          1       1  ...       1           1          1      2        3   \n",
      "66           1       1  ...       1           1          1      3        2   \n",
      "90           2       3  ...       1           1          1      2        3   \n",
      "119          1       2  ...       1           1          2      2        2   \n",
      "142          1       1  ...       1           1          1      3        3   \n",
      "262          1       1  ...       1           1          1      3        2   \n",
      "268          1       2  ...       1           1          1      2        1   \n",
      "206          1       1  ...       1           1          1      3        2   \n",
      "238          1       1  ...       1           1          1      2        2   \n",
      "46           1       1  ...       1           1          1      2        2   \n",
      "77           2       2  ...       2           3          1      2        2   \n",
      "68           1       1  ...       2           1          1      2        2   \n",
      "75           1       3  ...       1           1          1      2        2   \n",
      "216          1       1  ...       1           1          1      2        1   \n",
      "277          1       2  ...       1           2          1      2        2   \n",
      "45           1       1  ...       1           1          1      2        2   \n",
      "111          1       2  ...       1           1          1      3        1   \n",
      "60           2       1  ...       1           1          1      1        3   \n",
      "217          1       1  ...       1           1          1      2        3   \n",
      "143          2       3  ...       1           2          1      2        1   \n",
      "30           1       2  ...       1           2          1      2        3   \n",
      "22           1       1  ...       1           1          2      3        1   \n",
      "24           1       1  ...       1           1          1      2        1   \n",
      "127          4       3  ...       1           1          1      3        2   \n",
      "176          1       1  ...       2           2          1      2        1   \n",
      "79           1       1  ...       1           1          1      3        3   \n",
      "264          1       1  ...       1           1          1      2        2   \n",
      "237          1       1  ...       1           2          1      2        2   \n",
      "120          2       3  ...       2           2          1      3        3   \n",
      "196          1       1  ...       1           1          1      3        2   \n",
      "245          1       2  ...       1           1          1      2        2   \n",
      "168          3       2  ...       1           1          1      2        2   \n",
      "6            1       3  ...       2           1          1      3        3   \n",
      "239          1       1  ...       1           1          1      2        2   \n",
      "73           1       2  ...       1           1          2      3        2   \n",
      "84           1       2  ...       1           3          3      3        3   \n",
      "56           1       1  ...       1           1          2      3        2   \n",
      "25           1       2  ...       1           1          1      2        1   \n",
      "97           1       3  ...       1           1          1      3        2   \n",
      "147          1       1  ...       1           1          1      2        2   \n",
      "19           2       2  ...       1           1          1      3        2   \n",
      "\n",
      "     LIKES_DISCUSS  CLASSROOM  CUML_GPA  EXP_GPA  GRADE  \n",
      "33               2          2         2        3      2  \n",
      "108              1          2         3        3      6  \n",
      "240              2          1         2        2      6  \n",
      "259              2          2         2        2      6  \n",
      "154              2          2         3        2      0  \n",
      "9                2          2         1        2      0  \n",
      "146              2          1         2        2      0  \n",
      "203              3          2         4        3      4  \n",
      "144              3          1         5        4      3  \n",
      "155              2          2         3        2      0  \n",
      "221              2          2         2        2      4  \n",
      "92               3          3         2        2      7  \n",
      "222              2          1         3        3      5  \n",
      "209              3          2         2        2      4  \n",
      "42               3          1         2        3      1  \n",
      "210              1          1         3        2      4  \n",
      "66               2          3         5        4      5  \n",
      "90               2          3         4        2      6  \n",
      "119              3          1         3        3      2  \n",
      "142              2          1         4        3      1  \n",
      "262              2          3         2        2      7  \n",
      "268              2          1         3        4      7  \n",
      "206              2          1         2        2      4  \n",
      "238              3          2         4        3      5  \n",
      "46               3          1         4        2      5  \n",
      "77               2          2         1        1      7  \n",
      "68               3          2         4        3      5  \n",
      "75               2          2         4        1      7  \n",
      "216              2          1         4        3      4  \n",
      "277              2          1         1        1      7  \n",
      "45               2          1         4        3      3  \n",
      "111              3          3         4        3      2  \n",
      "60               3          1         2        1      2  \n",
      "217              1          1         3        2      4  \n",
      "143              2          1         5        3      4  \n",
      "30               3          3         5        4      5  \n",
      "22               2          3         3        3      3  \n",
      "24               3          2         4        4      2  \n",
      "127              2          1         2        2      1  \n",
      "176              2          1         2        2      2  \n",
      "79               3          2         4        4      3  \n",
      "264              3          1         4        4      7  \n",
      "237              2          1         3        2      5  \n",
      "120              3          2         2        2      1  \n",
      "196              2          2         2        3      3  \n",
      "245              2          1         3        2      6  \n",
      "168              2          1         2        2      0  \n",
      "6                3          3         4        4      5  \n",
      "239              2          2         4        3      5  \n",
      "73               3          1         5        3      6  \n",
      "84               3          3         5        4      7  \n",
      "56               3          3         5        4      5  \n",
      "25               3          2         1        2      3  \n",
      "97               2          1         3        3      6  \n",
      "147              2          2         3        2      0  \n",
      "19               2          3         2        3      3  \n",
      "\n",
      "[56 rows x 31 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "print(f\"Train Data shape: \\n{data_train}\\n\")\n",
    "print(f\"Test Data shape: \\n{data_test}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>HS_TYPE</th>\n",
       "      <th>SCHOLARSHIP</th>\n",
       "      <th>WORK</th>\n",
       "      <th>ACTIVITY</th>\n",
       "      <th>PARTNER</th>\n",
       "      <th>SALARY</th>\n",
       "      <th>TRANSPORT</th>\n",
       "      <th>LIVING</th>\n",
       "      <th>...</th>\n",
       "      <th>ATTEND</th>\n",
       "      <th>PREP_STUDY</th>\n",
       "      <th>PREP_EXAM</th>\n",
       "      <th>NOTES</th>\n",
       "      <th>LISTENS</th>\n",
       "      <th>LIKES_DISCUSS</th>\n",
       "      <th>CLASSROOM</th>\n",
       "      <th>CUML_GPA</th>\n",
       "      <th>EXP_GPA</th>\n",
       "      <th>GRADE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AGE  GENDER  HS_TYPE  SCHOLARSHIP  WORK  ACTIVITY  PARTNER  SALARY  \\\n",
       "0      2       2        3            3     1         2        2       1   \n",
       "1      2       2        3            3     1         2        2       1   \n",
       "2      2       2        2            3     2         2        2       2   \n",
       "3      1       1        1            3     1         2        1       2   \n",
       "4      2       2        1            3     2         2        1       3   \n",
       "..   ...     ...      ...          ...   ...       ...      ...     ...   \n",
       "275    1       2        2            4     1         2        1       1   \n",
       "276    1       2        2            4     2         1        1       1   \n",
       "277    1       2        1            2     2         2        1       2   \n",
       "278    1       2        2            4     2         1        1       1   \n",
       "279    1       2        2            4     2         1        2       1   \n",
       "\n",
       "     TRANSPORT  LIVING  ...  ATTEND  PREP_STUDY  PREP_EXAM  NOTES  LISTENS  \\\n",
       "0            1       1  ...       1           1          1      3        2   \n",
       "1            1       1  ...       1           1          1      3        2   \n",
       "2            4       2  ...       1           1          1      2        2   \n",
       "3            1       2  ...       1           1          2      3        2   \n",
       "4            1       4  ...       1           2          1      2        2   \n",
       "..         ...     ...  ...     ...         ...        ...    ...      ...   \n",
       "275          1       1  ...       1           1          1      3        2   \n",
       "276          1       2  ...       1           1          1      3        2   \n",
       "277          1       2  ...       1           2          1      2        2   \n",
       "278          1       1  ...       1           1          1      3        2   \n",
       "279          1       1  ...       1           2          1      2        2   \n",
       "\n",
       "     LIKES_DISCUSS  CLASSROOM  CUML_GPA  EXP_GPA  GRADE  \n",
       "0                1          2         1        1      1  \n",
       "1                3          2         2        3      1  \n",
       "2                1          1         2        2      1  \n",
       "3                2          1         3        2      1  \n",
       "4                2          1         2        2      1  \n",
       "..             ...        ...       ...      ...    ...  \n",
       "275              2          2         3        3      7  \n",
       "276              2          1         2        3      7  \n",
       "277              2          1         1        1      7  \n",
       "278              3          2         2        3      7  \n",
       "279              2          1         3        3      7  \n",
       "\n",
       "[280 rows x 31 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_train: \n",
      "     GRADE\n",
      "86       5\n",
      "137      2\n",
      "184      3\n",
      "5        2\n",
      "124      3\n",
      "..     ...\n",
      "188      3\n",
      "71       6\n",
      "106      7\n",
      "270      7\n",
      "102      7\n",
      "\n",
      "[224 rows x 1 columns]\n",
      "\n",
      "labels_test: \n",
      "     GRADE\n",
      "33       2\n",
      "108      6\n",
      "240      6\n",
      "259      6\n",
      "154      0\n",
      "9        0\n",
      "146      0\n",
      "203      4\n",
      "144      3\n",
      "155      0\n",
      "221      4\n",
      "92       7\n",
      "222      5\n",
      "209      4\n",
      "42       1\n",
      "210      4\n",
      "66       5\n",
      "90       6\n",
      "119      2\n",
      "142      1\n",
      "262      7\n",
      "268      7\n",
      "206      4\n",
      "238      5\n",
      "46       5\n",
      "77       7\n",
      "68       5\n",
      "75       7\n",
      "216      4\n",
      "277      7\n",
      "45       3\n",
      "111      2\n",
      "60       2\n",
      "217      4\n",
      "143      4\n",
      "30       5\n",
      "22       3\n",
      "24       2\n",
      "127      1\n",
      "176      2\n",
      "79       3\n",
      "264      7\n",
      "237      5\n",
      "120      1\n",
      "196      3\n",
      "245      6\n",
      "168      0\n",
      "6        5\n",
      "239      5\n",
      "73       6\n",
      "84       7\n",
      "56       5\n",
      "25       3\n",
      "97       6\n",
      "147      0\n",
      "19       3\n",
      "\n",
      "features_train: \n",
      "     AGE  GENDER  HS_TYPE  SCHOLARSHIP  WORK  ACTIVITY  PARTNER  SALARY  \\\n",
      "86     2       2        2            4     2         2        2       1   \n",
      "137    1       1        1            5     2         1        2       1   \n",
      "184    2       2        2            4     1         2        2       1   \n",
      "5      2       2        2            3     2         2        2       2   \n",
      "124    1       1        2            4     1         1        1       1   \n",
      "..   ...     ...      ...          ...   ...       ...      ...     ...   \n",
      "188    1       2        2            3     1         2        1       4   \n",
      "71     1       1        3            4     2         2        2       1   \n",
      "106    1       2        2            4     2         1        2       1   \n",
      "270    1       2        2            4     2         1        1       1   \n",
      "102    1       2        2            3     2         2        1       1   \n",
      "\n",
      "     TRANSPORT  LIVING  ...  IMPACT  ATTEND  PREP_STUDY  PREP_EXAM  NOTES  \\\n",
      "86           4       2  ...       1       1           1          1      3   \n",
      "137          1       1  ...       1       1           1          1      3   \n",
      "184          1       1  ...       2       1           1          1      3   \n",
      "5            1       1  ...       1       1           1          1      1   \n",
      "124          1       3  ...       1       1           2          2      3   \n",
      "..         ...     ...  ...     ...     ...         ...        ...    ...   \n",
      "188          1       1  ...       1       1           1          1      1   \n",
      "71           1       3  ...       1       1           1          1      2   \n",
      "106          1       2  ...       1       1           3          2      2   \n",
      "270          1       2  ...       1       1           1          1      3   \n",
      "102          1       2  ...       1       1           1          1      3   \n",
      "\n",
      "     LISTENS  LIKES_DISCUSS  CLASSROOM  CUML_GPA  EXP_GPA  \n",
      "86         2              3          2         5        4  \n",
      "137        1              3          1         2        4  \n",
      "184        2              2          1         4        3  \n",
      "5          2              1          2         4        4  \n",
      "124        3              2          1         3        3  \n",
      "..       ...            ...        ...       ...      ...  \n",
      "188        2              2          1         4        3  \n",
      "71         3              3          3         2        2  \n",
      "106        2              2          1         4        4  \n",
      "270        2              3          2         2        3  \n",
      "102        1              2          1         3        4  \n",
      "\n",
      "[224 rows x 30 columns]\n",
      "\n",
      "lfeatures_test: \n",
      "     AGE  GENDER  HS_TYPE  SCHOLARSHIP  WORK  ACTIVITY  PARTNER  SALARY  \\\n",
      "33     2       1        2            3     1         2        1       1   \n",
      "108    2       1        1            5     2         1        2       2   \n",
      "240    1       2        2            3     1         1        2       1   \n",
      "259    1       1        2            4     1         1        2       1   \n",
      "154    1       1        1            3     1         1        1       1   \n",
      "9      2       1        2            3     2         2        1       3   \n",
      "146    1       1        1            3     1         1        1       1   \n",
      "203    1       2        2            4     1         1        2       1   \n",
      "144    1       1        1            5     2         2        2       3   \n",
      "155    1       1        1            4     2         1        1       1   \n",
      "221    1       1        2            1     1         2        1       1   \n",
      "92     1       2        2            3     2         2        2       1   \n",
      "222    2       1        2            3     1         1        1       1   \n",
      "209    1       2        2            2     1         2        1       1   \n",
      "42     2       2        2            3     2         1        2       1   \n",
      "210    2       1        2            3     1         1        1       1   \n",
      "66     2       2        2            3     2         2        1       1   \n",
      "90     2       1        2            3     2         1        1       1   \n",
      "119    2       1        2            4     2         1        2       1   \n",
      "142    1       1        1            4     2         2        2       1   \n",
      "262    1       2        2            3     1         2        1       1   \n",
      "268    1       2        2            3     2         1        1       1   \n",
      "206    2       1        2            3     1         1        2       1   \n",
      "238    2       1        2            4     1         1        1       1   \n",
      "46     2       2        2            3     2         2        1       1   \n",
      "77     1       2        1            2     2         2        1       2   \n",
      "68     2       1        2            4     1         2        2       1   \n",
      "75     1       2        2            4     2         1        2       1   \n",
      "216    2       2        1            2     1         1        2       1   \n",
      "277    1       2        1            2     2         2        1       2   \n",
      "45     1       2        2            3     2         2        1       4   \n",
      "111    1       1        1            5     2         1        2       1   \n",
      "60     2       1        2            3     2         2        2       5   \n",
      "217    2       1        2            3     1         1        1       1   \n",
      "143    2       1        2            4     1         1        1       5   \n",
      "30     2       2        2            5     1         1        1       1   \n",
      "22     2       2        2            3     1         2        1       1   \n",
      "24     2       2        2            3     2         2        2       2   \n",
      "127    1       1        2            4     2         2        2       1   \n",
      "176    1       2        2            3     1         2        1       3   \n",
      "79     2       2        2            4     2         2        2       1   \n",
      "264    1       2        1            3     2         1        1       1   \n",
      "237    2       1        2            4     2         2        1       1   \n",
      "120    2       1        1            3     1         1        1       2   \n",
      "196    1       1        1            3     1         1        1       1   \n",
      "245    1       1        2            3     1         1        1       1   \n",
      "168    1       1        1            4     2         1        1       1   \n",
      "6      1       2        2            4     2         2        2       1   \n",
      "239    2       1        2            3     1         2        1       1   \n",
      "73     2       2        2            4     2         2        2       1   \n",
      "84     3       2        3            3     1         2        1       3   \n",
      "56     2       2        2            3     2         1        2       1   \n",
      "25     2       2        2            3     2         2        1       1   \n",
      "97     1       2        2            4     1         2        2       1   \n",
      "147    1       1        1            4     1         2        1       1   \n",
      "19     1       2        1            3     2         2        1       2   \n",
      "\n",
      "     TRANSPORT  LIVING  ...  IMPACT  ATTEND  PREP_STUDY  PREP_EXAM  NOTES  \\\n",
      "33           1       1  ...       1       1           1          1      1   \n",
      "108          2       1  ...       1       2           1          1      2   \n",
      "240          1       2  ...       1       1           1          1      2   \n",
      "259          1       3  ...       1       1           1          1      2   \n",
      "154          1       1  ...       1       1           1          1      2   \n",
      "9            4       2  ...       1       2           1          1      2   \n",
      "146          1       2  ...       1       1           2          1      2   \n",
      "203          1       1  ...       1       1           1          1      3   \n",
      "144          1       1  ...       1       1           2          1      3   \n",
      "155          2       1  ...       1       1           1          1      2   \n",
      "221          1       1  ...       1       1           1          1      2   \n",
      "92           1       1  ...       1       1           1          1      3   \n",
      "222          1       2  ...       1       1           1          1      2   \n",
      "209          1       1  ...       1       1           1          1      3   \n",
      "42           4       2  ...       1       1           1          1      2   \n",
      "210          1       1  ...       2       1           1          1      2   \n",
      "66           1       1  ...       1       1           1          1      3   \n",
      "90           2       3  ...       1       1           1          1      2   \n",
      "119          1       2  ...       1       1           1          2      2   \n",
      "142          1       1  ...       1       1           1          1      3   \n",
      "262          1       1  ...       1       1           1          1      3   \n",
      "268          1       2  ...       1       1           1          1      2   \n",
      "206          1       1  ...       1       1           1          1      3   \n",
      "238          1       1  ...       1       1           1          1      2   \n",
      "46           1       1  ...       1       1           1          1      2   \n",
      "77           2       2  ...       1       2           3          1      2   \n",
      "68           1       1  ...       1       2           1          1      2   \n",
      "75           1       3  ...       1       1           1          1      2   \n",
      "216          1       1  ...       1       1           1          1      2   \n",
      "277          1       2  ...       1       1           2          1      2   \n",
      "45           1       1  ...       1       1           1          1      2   \n",
      "111          1       2  ...       2       1           1          1      3   \n",
      "60           2       1  ...       1       1           1          1      1   \n",
      "217          1       1  ...       2       1           1          1      2   \n",
      "143          2       3  ...       1       1           2          1      2   \n",
      "30           1       2  ...       1       1           2          1      2   \n",
      "22           1       1  ...       1       1           1          2      3   \n",
      "24           1       1  ...       1       1           1          1      2   \n",
      "127          4       3  ...       1       1           1          1      3   \n",
      "176          1       1  ...       2       2           2          1      2   \n",
      "79           1       1  ...       3       1           1          1      3   \n",
      "264          1       1  ...       1       1           1          1      2   \n",
      "237          1       1  ...       1       1           2          1      2   \n",
      "120          2       3  ...       1       2           2          1      3   \n",
      "196          1       1  ...       1       1           1          1      3   \n",
      "245          1       2  ...       1       1           1          1      2   \n",
      "168          3       2  ...       1       1           1          1      2   \n",
      "6            1       3  ...       1       2           1          1      3   \n",
      "239          1       1  ...       1       1           1          1      2   \n",
      "73           1       2  ...       1       1           1          2      3   \n",
      "84           1       2  ...       1       1           3          3      3   \n",
      "56           1       1  ...       1       1           1          2      3   \n",
      "25           1       2  ...       1       1           1          1      2   \n",
      "97           1       3  ...       1       1           1          1      3   \n",
      "147          1       1  ...       1       1           1          1      2   \n",
      "19           2       2  ...       2       1           1          1      3   \n",
      "\n",
      "     LISTENS  LIKES_DISCUSS  CLASSROOM  CUML_GPA  EXP_GPA  \n",
      "33         3              2          2         2        3  \n",
      "108        3              1          2         3        3  \n",
      "240        2              2          1         2        2  \n",
      "259        3              2          2         2        2  \n",
      "154        2              2          2         3        2  \n",
      "9          2              2          2         1        2  \n",
      "146        2              2          1         2        2  \n",
      "203        2              3          2         4        3  \n",
      "144        2              3          1         5        4  \n",
      "155        2              2          2         3        2  \n",
      "221        3              2          2         2        2  \n",
      "92         2              3          3         2        2  \n",
      "222        1              2          1         3        3  \n",
      "209        1              3          2         2        2  \n",
      "42         1              3          1         2        3  \n",
      "210        3              1          1         3        2  \n",
      "66         2              2          3         5        4  \n",
      "90         3              2          3         4        2  \n",
      "119        2              3          1         3        3  \n",
      "142        3              2          1         4        3  \n",
      "262        2              2          3         2        2  \n",
      "268        1              2          1         3        4  \n",
      "206        2              2          1         2        2  \n",
      "238        2              3          2         4        3  \n",
      "46         2              3          1         4        2  \n",
      "77         2              2          2         1        1  \n",
      "68         2              3          2         4        3  \n",
      "75         2              2          2         4        1  \n",
      "216        1              2          1         4        3  \n",
      "277        2              2          1         1        1  \n",
      "45         2              2          1         4        3  \n",
      "111        1              3          3         4        3  \n",
      "60         3              3          1         2        1  \n",
      "217        3              1          1         3        2  \n",
      "143        1              2          1         5        3  \n",
      "30         3              3          3         5        4  \n",
      "22         1              2          3         3        3  \n",
      "24         1              3          2         4        4  \n",
      "127        2              2          1         2        2  \n",
      "176        1              2          1         2        2  \n",
      "79         3              3          2         4        4  \n",
      "264        2              3          1         4        4  \n",
      "237        2              2          1         3        2  \n",
      "120        3              3          2         2        2  \n",
      "196        2              2          2         2        3  \n",
      "245        2              2          1         3        2  \n",
      "168        2              2          1         2        2  \n",
      "6          3              3          3         4        4  \n",
      "239        2              2          2         4        3  \n",
      "73         2              3          1         5        3  \n",
      "84         3              3          3         5        4  \n",
      "56         2              3          3         5        4  \n",
      "25         1              3          2         1        2  \n",
      "97         2              2          1         3        3  \n",
      "147        2              2          2         3        2  \n",
      "19         2              2          3         2        3  \n",
      "\n",
      "[56 rows x 30 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Extracting Labels\n",
    "\n",
    "columns = data_train.columns.to_list()\n",
    "columns_drop = columns.pop(-1)\n",
    "labels_train = data_train.drop(columns, axis=1)\n",
    "labels_test = data_test.drop(columns, axis=1)\n",
    "\n",
    "print(f\"labels_train: \\n{labels_train}\\n\")\n",
    "print(f\"labels_test: \\n{labels_test}\\n\")\n",
    "\n",
    "features_train = data_train.drop(['GRADE'], axis=1)\n",
    "features_test = data_test.drop(['GRADE'], axis=1)\n",
    "print(f\"features_train: \\n{features_train }\\n\")\n",
    "print(f\"lfeatures_test: \\n{features_test }\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ohenc = OneHotEncoder(sparse=False)\n",
    "\n",
    "ohenc_cols = ohenc.fit(features_train.drop(['AGE', 'SCHOLARSHIP', 'SALARY', 'MOTHER_EDU', 'FATHER_EDU', '#_SIBLINGS', 'STUDY_HRS', \n",
    "                'READ_FREQ', 'READ_FREQ_SCI', 'IMPACT', 'ATTEND', 'NOTES', 'LISTENS', 'LIKES_DISCUSS',\n",
    "                'CUML_GPA', 'EXP_GPA'], axis=1)).get_feature_names_out()\n",
    "\n",
    "\n",
    "ord_attribs = ['AGE', 'SCHOLARSHIP', 'SALARY', 'MOTHER_EDU', 'FATHER_EDU', '#_SIBLINGS', 'STUDY_HRS', \n",
    "                'READ_FREQ', 'READ_FREQ_SCI', 'IMPACT', 'ATTEND', 'NOTES', 'LISTENS', 'LIKES_DISCUSS',\n",
    "                'CUML_GPA', 'EXP_GPA']\n",
    "nom_attribs = ['GENDER', 'HS_TYPE', 'WORK', 'ACTIVITY', 'PARTNER', 'TRANSPORT', 'LIVING', 'PARENT_STATUS',\n",
    "                'MOTHER_JOB', 'FATHER_JOB', 'ATTEND_DEPT', 'PREP_STUDY', 'PREP_EXAM', 'CLASSROOM']\n",
    "\n",
    "pipe_cols = ['AGE' ,'GENDER_1' ,'GENDER_2' ,'HS_TYPE_1' ,'HS_TYPE_2' ,'HS_TYPE_3', 'SCHOLARSHIP' ,'WORK_1',\n",
    "             'WORK_2' ,'ACTIVITY_1', 'ACTIVITY_2', 'PARTNER_1' ,'PARTNER_2' ,'SALARY', 'TRANSPORT_1',\n",
    "             'TRANSPORT_2', 'TRANSPORT_3' ,'TRANSPORT_4' ,'LIVING_1' ,'LIVING_2', 'LIVING_3', 'LIVING_4',\n",
    "             'MOTHER_EDU', 'FATHER_EDU', '#_SIBLINGS', 'PARENT_STATUS_1' ,'PARENT_STATUS_2', 'PARENT_STATUS_3',\n",
    "             'MOTHER_JOB_1' ,'MOTHER_JOB_2' ,'MOTHER_JOB_3', 'MOTHER_JOB_4' ,'MOTHER_JOB_5' ,'FATHER_JOB_1' , \n",
    "             'FATHER_JOB_2', 'FATHER_JOB_3' ,'FATHER_JOB_4' ,'FATHER_JOB_5', 'STUDY_HRS', 'READ_FREQ',\n",
    "             'READ_FREQ_SCI',  'ATTEND_DEPT_1', 'ATTEND_DEPT_2', 'IMPACT', 'ATTEND','PREP_STUDY_1' ,'PREP_STUDY_2', \n",
    "             'PREP_STUDY_3', 'PREP_EXAM_1', 'PREP_EXAM_2' ,'PREP_EXAM_3' ,'NOTES', 'LISTENS', 'LIKES_DISCUSS', \n",
    "             'CLASSROOM_1' ,'CLASSROOM_2', 'CLASSROOM_3','CUML_GPA', 'EXP_GPA']\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"Nominal\", OneHotEncoder(), nom_attribs),\n",
    "        (\"Ordinal\", OrdinalEncoder(), ord_attribs)\n",
    "    ])\n",
    "\n",
    "data_prepared = pd.DataFrame(full_pipeline.fit_transform(features_train),columns=pipe_cols, index=features_train.index)\n",
    "#full_pipeline.fit_transform(data_train)\n",
    "#pd.DataFrame(full_pipeline.fit_transform(train_df),columns=train_df.columns, index=train_df.index)\\\n",
    "\n",
    "zero_data = np.zeros(shape=(len(data_prepared),1))\n",
    "\n",
    "#data_prepared.insert(37,\"MOTHER_EDU_6\", zero_data) #Inserting those columns that are not represented in the train data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the following four different models with their default hyperparameter values to be trained using the preprocessed data (0.5 * 4)\n",
    "labelTrainFlat = labels_train.values.ravel()\n",
    "# Gradient Boosting\n",
    "gradientBoosting = OneVsRestClassifier(GradientBoostingClassifier())\n",
    "gradientBoosting = gradientBoosting.fit(data_prepared, labelTrainFlat)\n",
    "\n",
    "# Decision Trees\n",
    "decisionTree = DecisionTreeClassifier()\n",
    "decisionTree = decisionTree.fit(data_prepared,labelTrainFlat)\n",
    "\n",
    "# Random Forests\n",
    "randomForest = RandomForestClassifier()\n",
    "randomForest = randomForest.fit(data_prepared,labelTrainFlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters GradientBoosting: \n",
      "{'estimator__learning_rate': 0.46, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 7, 'estimator__n_estimators': 60}\n",
      "\n",
      "Best estimator GradientBoosting: \n",
      "OneVsRestClassifier(estimator=GradientBoostingClassifier(learning_rate=0.46,\n",
      "                                                         min_samples_leaf=5,\n",
      "                                                         min_samples_split=7,\n",
      "                                                         n_estimators=60))\n",
      "\n",
      "Best score GradientBoosting: \n",
      "0.6821056547619048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parametersGradientBoosting = [\n",
    "    {'estimator__learning_rate': [0.44,0.45,0.46],'estimator__min_samples_leaf': [5,6,7],'estimator__min_samples_split': [7,8,9,10], 'estimator__n_estimators': [57,58,59,60]}\n",
    "]\n",
    "scoringX = {\"accuracy\": \"accuracy\", \"bal_accuracy\": \"balanced_accuracy\", \"F1_macro\": \"f1_macro\"}\n",
    "\n",
    "grid_searchGradientBoosting = GridSearchCV(gradientBoosting, parametersGradientBoosting, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "grid_searchGradientBoosting.fit(data_prepared, labelTrainFlat)\n",
    "\n",
    "print(f\"Best parameters GradientBoosting: \\n{grid_searchGradientBoosting.best_params_}\\n\")\n",
    "print(f\"Best estimator GradientBoosting: \\n{grid_searchGradientBoosting.best_estimator_}\\n\")\n",
    "print(f\"Best score GradientBoosting: \\n{grid_searchGradientBoosting.best_score_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters KNeighbors: \n",
      "{'algorithm': 'auto', 'n_neighbors': 2, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "Best estimator KNeighbors: \n",
      "KNeighborsClassifier(n_neighbors=2, weights='distance')\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.6709701178451177\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# KNeighbors\n",
    "kNeighbors = KNeighborsClassifier()\n",
    "kNeighbors = kNeighbors.fit(data_prepared,labelTrainFlat)\n",
    "\n",
    "parametersKNeighbors = [\n",
    "    {'n_neighbors': [1,2,3],'weights':['uniform', 'distance'],'algorithm':['auto'], 'p': [1,2,3]}\n",
    "]\n",
    "scoringX = {\"accuracy\": \"accuracy\", \"bal_accuracy\": \"balanced_accuracy\", \"F1_macro\": \"f1_macro\"}\n",
    "\n",
    "grid_searchKNeighbors = GridSearchCV(kNeighbors, parametersKNeighbors, cv=3, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "grid_searchKNeighbors.fit(data_prepared, labelTrainFlat)\n",
    "\n",
    "print(f\"Best parameters KNeighbors: \\n{grid_searchKNeighbors.best_params_}\\n\")\n",
    "print(f\"Best estimator KNeighbors: \\n{grid_searchKNeighbors.best_estimator_}\\n\")\n",
    "print(f\"Best score KNeighbors: \\n{grid_searchKNeighbors.best_score_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters Logistic Regression: \n",
      "{'C': 2, 'multi_class': 'ovr', 'penalty': 'l2'}\n",
      "\n",
      "Best estimator Logistic Regression: \n",
      "LogisticRegression(C=2, multi_class='ovr')\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.5035563973063972\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "logisticRegression = LogisticRegression()\n",
    "logisticRegression = logisticRegression.fit(data_prepared,labelTrainFlat)\n",
    "\n",
    "parametersLogisticRegression = [\n",
    "    {'multi_class': ['ovr'],'penalty':['none','l2'], 'C': [1,2,3]}\n",
    "]\n",
    "scoringX = {\"accuracy\": \"accuracy\", \"bal_accuracy\": \"balanced_accuracy\", \"F1_macro\": \"f1_macro\"}\n",
    "\n",
    "grid_searchLogisticRegression = GridSearchCV(logisticRegression, parametersLogisticRegression, cv=3, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "grid_searchLogisticRegression.fit(data_prepared, labelTrainFlat)\n",
    "\n",
    "print(f\"Best parameters Logistic Regression: \\n{grid_searchLogisticRegression.best_params_}\\n\")\n",
    "print(f\"Best estimator Logistic Regression: \\n{grid_searchLogisticRegression.best_estimator_}\\n\")\n",
    "print(f\"Best score Logistic Regression: \\n{grid_searchLogisticRegression.best_score_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters DecisionTree: \n",
      "{'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "\n",
      "Best estimator DecisionTree: \n",
      "DecisionTreeClassifier(max_depth=4, min_samples_leaf=4)\n",
      "\n",
      "Best score DecisionTree: \n",
      "0.33188131313131314\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "36 fits failed out of a total of 108.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "36 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.16954955 0.16954955        nan 0.16954955 0.16954955\n",
      "        nan 0.16954955 0.16954955        nan 0.20108108 0.20108108\n",
      "        nan 0.20108108 0.20108108        nan 0.20108108 0.20108108\n",
      "        nan 0.25891892 0.25891892        nan 0.26342342 0.26342342\n",
      "        nan 0.25459459 0.25459459        nan 0.33063063 0.33063063\n",
      "        nan 0.32612613 0.32612613        nan 0.32162162 0.32162162]\n",
      "  warnings.warn(\n",
      "C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan 0.22547353 0.22547353        nan 0.22547353 0.22547353\n",
      "        nan 0.22547353 0.22547353        nan 0.32143177 0.32143177\n",
      "        nan 0.32143177 0.32143177        nan 0.32143177 0.32143177\n",
      "        nan 0.42851603 0.42851603        nan 0.41956749 0.41956749\n",
      "        nan 0.41734526 0.41734526        nan 0.54456376 0.54456376\n",
      "        nan 0.53561521 0.53561521        nan 0.52444444 0.52444444]\n",
      "  warnings.warn(\n",
      "C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.16527778 0.16527778        nan 0.16527778 0.16527778\n",
      "        nan 0.16527778 0.16527778        nan 0.19583333 0.19583333\n",
      "        nan 0.19583333 0.19583333        nan 0.19583333 0.19583333\n",
      "        nan 0.25273569 0.25273569        nan 0.25690236 0.25690236\n",
      "        nan 0.2493266  0.2493266         nan 0.33188131 0.33188131\n",
      "        nan 0.32563131 0.32563131        nan 0.32146465 0.32146465]\n",
      "  warnings.warn(\n",
      "C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan 0.21158104 0.21158104        nan 0.21158104 0.21158104\n",
      "        nan 0.21158104 0.21158104        nan 0.31030876 0.31030876\n",
      "        nan 0.31030876 0.31030876        nan 0.31030876 0.31030876\n",
      "        nan 0.42131196 0.42131196        nan 0.41251566 0.41251566\n",
      "        nan 0.41132519 0.41132519        nan 0.54244217 0.54244217\n",
      "        nan 0.53367723 0.53367723        nan 0.52293814 0.52293814]\n",
      "  warnings.warn(\n",
      "C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.07495072 0.07495072        nan 0.07495072 0.07495072\n",
      "        nan 0.07495072 0.07495072        nan 0.13269273 0.13269273\n",
      "        nan 0.13269273 0.13269273        nan 0.13269273 0.13269273\n",
      "        nan 0.20221925 0.20219223        nan 0.20520266 0.20520266\n",
      "        nan 0.19733457 0.19733457        nan 0.3046655  0.3046655\n",
      "        nan 0.30049553 0.30049553        nan 0.2879162  0.2879162 ]\n",
      "  warnings.warn(\n",
      "C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan 0.1013433  0.1013433         nan 0.1013433  0.1013433\n",
      "        nan 0.1013433  0.1013433         nan 0.20890103 0.20890103\n",
      "        nan 0.20890103 0.20890103        nan 0.20890103 0.20890103\n",
      "        nan 0.35379002 0.35379002        nan 0.34626887 0.34626887\n",
      "        nan 0.34275374 0.34275374        nan 0.50939947 0.50939947\n",
      "        nan 0.5030768  0.5030768         nan 0.4848833  0.4848833 ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "parametersDecisionTree = [\n",
    "    {'max_depth': [1,2,3,4], 'min_samples_leaf': [4,5,6], 'min_samples_split': [1,2,3]}\n",
    "]\n",
    "\n",
    "grid_searchDecisionTree = GridSearchCV(decisionTree, parametersDecisionTree, cv=3, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "grid_searchDecisionTree.fit(data_prepared, labelTrainFlat)\n",
    "\n",
    "print(f\"Best parameters DecisionTree: \\n{grid_searchDecisionTree.best_params_}\\n\")\n",
    "print(f\"Best estimator DecisionTree: \\n{grid_searchDecisionTree.best_estimator_}\\n\")\n",
    "print(f\"Best score DecisionTree: \\n{grid_searchDecisionTree.best_score_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters RandomForest: \n",
      "{'bootstrap': False, 'max_depth': 12, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "\n",
      "Best estimator RandomForest: \n",
      "RandomForestClassifier(bootstrap=False, max_depth=12, n_estimators=150)\n",
      "\n",
      "Best score RandomForest: \n",
      "0.6945684523809523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parametersRandomForest = [\n",
    "    {'n_estimators': [145,150,155,190],'max_depth': [10,12], 'bootstrap': [True, False],\n",
    "     'min_samples_split': [0.05,2]}\n",
    "]\n",
    "\n",
    "grid_searchRandomForest = GridSearchCV(randomForest, parametersRandomForest, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "grid_searchRandomForest.fit(data_prepared, labelTrainFlat)\n",
    "\n",
    "print(f\"Best parameters RandomForest: \\n{grid_searchRandomForest.best_params_}\\n\")\n",
    "\n",
    "print(f\"Best estimator RandomForest: \\n{grid_searchRandomForest.best_estimator_}\\n\")\n",
    "\n",
    "print(f\"Best score RandomForest: \\n{grid_searchRandomForest.best_score_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test Accuracy for GradientBoosting: \n",
      "[0.66517857 0.65625    0.64732143 0.65625    0.66517857 0.64732143\n",
      " 0.65178571 0.65178571 0.67857143 0.66071429 0.65625    0.65178571\n",
      " 0.65625    0.64732143 0.65178571 0.66517857 0.65625    0.65625\n",
      " 0.64732143 0.64732143 0.64732143 0.65625    0.65178571 0.65625\n",
      " 0.66071429 0.65625    0.64732143 0.65178571 0.66071429 0.65625\n",
      " 0.65178571 0.65625    0.62946429 0.625      0.63839286 0.62946429\n",
      " 0.63392857 0.61160714 0.63392857 0.64732143 0.625      0.62946429\n",
      " 0.65178571 0.63839286 0.64285714 0.62946429 0.63392857 0.65178571\n",
      " 0.64732143 0.65625    0.66517857 0.65625    0.66517857 0.65625\n",
      " 0.64285714 0.66071429 0.65178571 0.65625    0.65625    0.65625\n",
      " 0.64732143 0.65178571 0.65178571 0.65178571 0.65178571 0.63839286\n",
      " 0.64285714 0.64732143 0.65178571 0.63392857 0.63392857 0.63839286\n",
      " 0.65178571 0.63839286 0.63839286 0.63839286 0.64732143 0.63392857\n",
      " 0.64285714 0.63839286 0.65178571 0.63839286 0.63839286 0.63839286\n",
      " 0.63392857 0.64285714 0.63392857 0.63839286 0.64732143 0.65178571\n",
      " 0.65625    0.64732143 0.64732143 0.63392857 0.64732143 0.64285714\n",
      " 0.66517857 0.66517857 0.67857143 0.67857143 0.66517857 0.66964286\n",
      " 0.66517857 0.67410714 0.66964286 0.65625    0.66517857 0.65625\n",
      " 0.67857143 0.65625    0.66964286 0.66071429 0.66071429 0.64732143\n",
      " 0.65178571 0.65625    0.66517857 0.65178571 0.65625    0.64732143\n",
      " 0.66071429 0.64732143 0.65178571 0.64285714 0.66071429 0.65178571\n",
      " 0.65625    0.65178571 0.63392857 0.63839286 0.64285714 0.62946429\n",
      " 0.63839286 0.63839286 0.62946429 0.64285714 0.62946429 0.64285714\n",
      " 0.64285714 0.64732143 0.625      0.63392857 0.63392857 0.625     ]\n",
      "\n",
      "Balanced Test Accuracy for GradientBoosting: \n",
      "[0.6687128  0.65978423 0.65085565 0.65904018 0.66741071 0.64955357\n",
      " 0.65531994 0.65531994 0.68098958 0.66424851 0.66015625 0.65643601\n",
      " 0.66034226 0.64955357 0.65401786 0.6687128  0.65866815 0.65811012\n",
      " 0.64899554 0.64899554 0.64973958 0.65811012 0.65420387 0.65866815\n",
      " 0.66313244 0.65811012 0.64899554 0.65420387 0.66313244 0.65811012\n",
      " 0.65345982 0.65866815 0.63206845 0.6264881  0.63988095 0.63151042\n",
      " 0.63541667 0.61216518 0.63541667 0.65029762 0.62760417 0.63095238\n",
      " 0.65606399 0.63988095 0.64620536 0.63095238 0.63616071 0.65531994\n",
      " 0.64899554 0.65662202 0.66629464 0.65736607 0.66629464 0.65792411\n",
      " 0.64434524 0.66127232 0.65271577 0.65662202 0.65736607 0.65736607\n",
      " 0.64825149 0.65271577 0.65401786 0.65290179 0.65234375 0.63895089\n",
      " 0.64397321 0.64787946 0.65234375 0.63504464 0.63504464 0.63950893\n",
      " 0.65234375 0.63950893 0.63950893 0.63895089 0.64787946 0.63448661\n",
      " 0.64397321 0.63950893 0.65383185 0.64099702 0.64099702 0.64025298\n",
      " 0.63578869 0.64415923 0.63578869 0.64043899 0.64862351 0.65438988\n",
      " 0.65885417 0.64936756 0.64936756 0.63578869 0.6499256  0.64490327\n",
      " 0.66889881 0.66759673 0.68043155 0.68210565 0.66815476 0.67206101\n",
      " 0.66815476 0.67708333 0.67392113 0.65922619 0.66815476 0.66034226\n",
      " 0.68098958 0.65978423 0.67261905 0.66369048 0.66052827 0.64769345\n",
      " 0.65290179 0.65662202 0.6655506  0.65215774 0.65736607 0.64825149\n",
      " 0.66052827 0.64825149 0.65345982 0.64434524 0.66052827 0.65215774\n",
      " 0.65792411 0.65271577 0.63802083 0.64099702 0.64750744 0.63318452\n",
      " 0.64099702 0.64099702 0.63262649 0.64750744 0.63206845 0.64620536\n",
      " 0.64750744 0.65066964 0.62890625 0.63653274 0.63783482 0.62872024]\n",
      "\n",
      "Mean F1 Macro for GradientBoosting: \n",
      "[0.66058693 0.6521728  0.6404364  0.65367001 0.66084193 0.64447951\n",
      " 0.65020029 0.64859696 0.67410206 0.6557759  0.65073147 0.64745698\n",
      " 0.64933498 0.64609086 0.64747661 0.6599853  0.65586665 0.65394395\n",
      " 0.64598071 0.64331011 0.64358885 0.65289388 0.64957363 0.65316189\n",
      " 0.65965843 0.65394395 0.64598071 0.64776936 0.65681858 0.65399279\n",
      " 0.6488242  0.65157181 0.62073097 0.61972651 0.63414255 0.62277697\n",
      " 0.63035554 0.60443586 0.62910003 0.64364277 0.61770832 0.62735518\n",
      " 0.64814412 0.63393796 0.63724978 0.62615012 0.62993718 0.64793149\n",
      " 0.64879516 0.65661589 0.66598013 0.65452278 0.66554353 0.6549719\n",
      " 0.64287795 0.66053572 0.65135319 0.65725978 0.65690803 0.65333449\n",
      " 0.64687745 0.65312225 0.65182787 0.65193609 0.64812489 0.63596112\n",
      " 0.64230163 0.64759688 0.64750485 0.63348191 0.63260336 0.63668266\n",
      " 0.64748569 0.63755949 0.63593727 0.63688682 0.64125667 0.63196466\n",
      " 0.64355276 0.63703778 0.65179878 0.63956678 0.63907606 0.63914363\n",
      " 0.63279794 0.64052361 0.63270753 0.63696879 0.64724075 0.6534078\n",
      " 0.65768066 0.6489131  0.64648109 0.63382685 0.64739196 0.64265061\n",
      " 0.6630076  0.66559617 0.67949715 0.67860062 0.66511021 0.66988312\n",
      " 0.66908765 0.67593905 0.66863983 0.65722872 0.66906723 0.65826199\n",
      " 0.67916926 0.65662153 0.66969672 0.6635657  0.65968408 0.64241644\n",
      " 0.64887136 0.65382872 0.66448622 0.65033106 0.65340433 0.64468265\n",
      " 0.65920894 0.64270807 0.65180321 0.64072899 0.65920894 0.64992256\n",
      " 0.65601518 0.64921562 0.63065636 0.635727   0.64238784 0.62774241\n",
      " 0.63530418 0.63664275 0.62774376 0.63793419 0.62828537 0.63931956\n",
      " 0.64226151 0.64180417 0.62258145 0.63082849 0.63069261 0.61920682]\n",
      "\n",
      "Mean Test Accuracy for Decision Trees: \n",
      "[       nan 0.16954955 0.16954955        nan 0.16954955 0.16954955\n",
      "        nan 0.16954955 0.16954955        nan 0.20108108 0.20108108\n",
      "        nan 0.20108108 0.20108108        nan 0.20108108 0.20108108\n",
      "        nan 0.25891892 0.25891892        nan 0.26342342 0.26342342\n",
      "        nan 0.25459459 0.25459459        nan 0.33063063 0.33063063\n",
      "        nan 0.32612613 0.32612613        nan 0.32162162 0.32162162]\n",
      "\n",
      "Balanced Test Accuracy for Decision Trees: \n",
      "[       nan 0.16527778 0.16527778        nan 0.16527778 0.16527778\n",
      "        nan 0.16527778 0.16527778        nan 0.19583333 0.19583333\n",
      "        nan 0.19583333 0.19583333        nan 0.19583333 0.19583333\n",
      "        nan 0.25273569 0.25273569        nan 0.25690236 0.25690236\n",
      "        nan 0.2493266  0.2493266         nan 0.33188131 0.33188131\n",
      "        nan 0.32563131 0.32563131        nan 0.32146465 0.32146465]\n",
      "\n",
      "Mean F1 Macro for Decision Trees: \n",
      "[       nan 0.07495072 0.07495072        nan 0.07495072 0.07495072\n",
      "        nan 0.07495072 0.07495072        nan 0.13269273 0.13269273\n",
      "        nan 0.13269273 0.13269273        nan 0.13269273 0.13269273\n",
      "        nan 0.20221925 0.20219223        nan 0.20520266 0.20520266\n",
      "        nan 0.19733457 0.19733457        nan 0.3046655  0.3046655\n",
      "        nan 0.30049553 0.30049553        nan 0.2879162  0.2879162 ]\n",
      "\n",
      "Mean Test Accuracy for Random Forests: \n",
      "[0.5625     0.58928571 0.5625     0.58928571 0.66517857 0.64285714\n",
      " 0.62946429 0.65625    0.59375    0.58482143 0.61607143 0.58928571\n",
      " 0.64285714 0.64732143 0.63392857 0.67410714 0.59821429 0.59821429\n",
      " 0.58035714 0.60267857 0.66071429 0.65625    0.64732143 0.67857143\n",
      " 0.58928571 0.59821429 0.58482143 0.60267857 0.6875     0.6875\n",
      " 0.66517857 0.6875    ]\n",
      "\n",
      "Balanced Test Accuracy for Random Forests: \n",
      "[0.56752232 0.59281994 0.56733631 0.59635417 0.67280506 0.64657738\n",
      " 0.6343006  0.66164435 0.59951637 0.58984375 0.62146577 0.59375\n",
      " 0.64825149 0.65327381 0.64229911 0.67912946 0.60342262 0.60584077\n",
      " 0.58426339 0.60602679 0.66778274 0.66183036 0.65364583 0.68489583\n",
      " 0.59430804 0.60602679 0.59188988 0.60956101 0.69401042 0.69456845\n",
      " 0.67131696 0.69196429]\n",
      "\n",
      "Mean F1 Macro for Random Forests: \n",
      "[0.55580546 0.58084882 0.55105371 0.57870488 0.6523697  0.6331015\n",
      " 0.61509239 0.64324832 0.58763568 0.57405233 0.60549182 0.57762503\n",
      " 0.62731403 0.64106308 0.62395134 0.664833   0.59858569 0.59558443\n",
      " 0.57636387 0.59474607 0.64945762 0.64713632 0.63651652 0.67333043\n",
      " 0.58474312 0.58715349 0.57929293 0.59254677 0.68193344 0.67693234\n",
      " 0.65753661 0.68146379]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the grid search cross-validation results listing the above mentioned evaluation methods (3)\n",
    "cross_val_resultsGB = grid_searchGradientBoosting.cv_results_\n",
    "cross_val_resultsDT = grid_searchDecisionTree.cv_results_\n",
    "cross_val_resultsRF = grid_searchRandomForest.cv_results_\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Mean Test Accuracy for GradientBoosting: \\n{cross_val_resultsGB['mean_test_accuracy']}\\n\")\n",
    "print(f\"Balanced Test Accuracy for GradientBoosting: \\n{cross_val_resultsGB['mean_test_bal_accuracy']}\\n\")\n",
    "print(f\"Mean F1 Macro for GradientBoosting: \\n{cross_val_resultsGB['mean_test_F1_macro']}\\n\")\n",
    "\n",
    "#DTC\n",
    "print(f\"Mean Test Accuracy for Decision Trees: \\n{cross_val_resultsDT['mean_test_accuracy']}\\n\")\n",
    "print(f\"Balanced Test Accuracy for Decision Trees: \\n{cross_val_resultsDT['mean_test_bal_accuracy']}\\n\")\n",
    "print(f\"Mean F1 Macro for Decision Trees: \\n{cross_val_resultsDT['mean_test_F1_macro']}\\n\")\n",
    "\n",
    "#RFC\n",
    "print(f\"Mean Test Accuracy for Random Forests: \\n{cross_val_resultsRF['mean_test_accuracy']}\\n\")\n",
    "print(f\"Balanced Test Accuracy for Random Forests: \\n{cross_val_resultsRF['mean_test_bal_accuracy']}\\n\")\n",
    "print(f\"Mean F1 Macro for Random Forests: \\n{cross_val_resultsRF['mean_test_F1_macro']}\\n\")\n",
    "\n",
    "#NB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Prediction: \n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1]\n",
      "\n",
      "Dummy Score: \n",
      "0.13839285714285715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use a dummy classifier to identify a simple baseline (i.e., a majority class baseline) so that you can compare your prediction results (3)\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(data_prepared, labelTrainFlat)\n",
    "DummyClassifier(strategy='most_frequent')\n",
    "print(f\"Dummy Prediction: \\n{dummy_clf.predict(data_prepared)}\\n\") \n",
    "print(f\"Dummy Score: \\n{dummy_clf.score(data_prepared, labelTrainFlat)}\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71         6\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.80      0.67      0.73         6\n",
      "           3       0.71      0.71      0.71         7\n",
      "           4       0.88      0.88      0.88         8\n",
      "           5       0.83      0.50      0.62        10\n",
      "           6       0.50      0.43      0.46         7\n",
      "           7       0.86      0.75      0.80         8\n",
      "\n",
      "    accuracy                           0.64        56\n",
      "   macro avg       0.64      0.62      0.61        56\n",
      "weighted avg       0.69      0.64      0.65        56\n",
      "\n",
      "[[6 0 0 0 0 0 0 0]\n",
      " [3 0 0 0 0 0 0 1]\n",
      " [0 1 4 0 0 1 0 0]\n",
      " [0 1 1 5 0 0 0 0]\n",
      " [1 0 0 0 7 0 0 0]\n",
      " [0 2 0 0 1 5 2 0]\n",
      " [1 2 0 1 0 0 3 0]\n",
      " [0 0 0 1 0 0 1 6]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ohenc_test = OneHotEncoder(sparse=False)\n",
    "ohenc_cols_test = ohenc.fit(features_test.drop(['AGE', 'SCHOLARSHIP', 'SALARY', 'MOTHER_EDU', 'FATHER_EDU', '#_SIBLINGS', 'STUDY_HRS', \n",
    "                'READ_FREQ', 'READ_FREQ_SCI', 'IMPACT', 'ATTEND', 'NOTES', 'LISTENS', 'LIKES_DISCUSS',\n",
    "                'CUML_GPA', 'EXP_GPA'], axis=1)).get_feature_names_out()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "missing_cols_from_test = ['MOTHER_JOB_5', 'LIVING_4', 'FATHER_EDU_6']\n",
    "missing_cols_from_train = ['MOTHER_EDU_6']\n",
    "\n",
    "ord_attribs_test = ['AGE', 'SCHOLARSHIP', 'SALARY', 'MOTHER_EDU', 'FATHER_EDU', '#_SIBLINGS', 'STUDY_HRS', \n",
    "                'READ_FREQ', 'READ_FREQ_SCI', 'IMPACT', 'ATTEND', 'NOTES', 'LISTENS', 'LIKES_DISCUSS',\n",
    "                'CUML_GPA', 'EXP_GPA']\n",
    "nom_attribs_test = ['GENDER', 'HS_TYPE', 'WORK', 'ACTIVITY', 'PARTNER', 'TRANSPORT', 'LIVING', 'PARENT_STATUS',\n",
    "                'MOTHER_JOB', 'FATHER_JOB', 'ATTEND_DEPT', 'PREP_STUDY', 'PREP_EXAM', 'CLASSROOM']\n",
    "\n",
    "pipe_cols_test = ['AGE' ,'GENDER_1' ,'GENDER_2' ,'HS_TYPE_1' ,'HS_TYPE_2' ,'HS_TYPE_3', 'SCHOLARSHIP' ,'WORK_1',\n",
    "             'WORK_2' ,'ACTIVITY_1', 'ACTIVITY_2', 'PARTNER_1' ,'PARTNER_2' ,'SALARY', 'TRANSPORT_1',\n",
    "             'TRANSPORT_2', 'TRANSPORT_3' ,'TRANSPORT_4' ,'LIVING_1' ,'LIVING_2', 'LIVING_3',\n",
    "             'MOTHER_EDU', 'FATHER_EDU', '#_SIBLINGS', 'PARENT_STATUS_1' ,'PARENT_STATUS_2', 'PARENT_STATUS_3',\n",
    "             'MOTHER_JOB_1' ,'MOTHER_JOB_2' ,'MOTHER_JOB_3', 'MOTHER_JOB_4' ,'FATHER_JOB_1' , \n",
    "             'FATHER_JOB_2', 'FATHER_JOB_3' ,'FATHER_JOB_4' ,'FATHER_JOB_5', 'STUDY_HRS', 'READ_FREQ',\n",
    "             'READ_FREQ_SCI',  'ATTEND_DEPT_1', 'ATTEND_DEPT_2', 'IMPACT', 'ATTEND','PREP_STUDY_1' ,'PREP_STUDY_2', \n",
    "             'PREP_STUDY_3', 'PREP_EXAM_1', 'PREP_EXAM_2' ,'PREP_EXAM_3' ,'NOTES', 'LISTENS', 'LIKES_DISCUSS', \n",
    "             'CLASSROOM_1' ,'CLASSROOM_2', 'CLASSROOM_3','CUML_GPA', 'EXP_GPA']\n",
    "\n",
    "\n",
    "full_pipeline_test = ColumnTransformer([\n",
    "        (\"Nominal\", OneHotEncoder(), nom_attribs),\n",
    "        (\"Ordinal\", OrdinalEncoder(), ord_attribs)\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "data_prepared_test = pd.DataFrame(full_pipeline_test.fit_transform(features_test),columns=pipe_cols_test, index=features_test.index)\n",
    "missing_cols_df = pd.DataFrame(0, index=np.arange(56), columns=missing_cols_from_test)\n",
    "res = list(set(ohenc_cols).difference(set(ohenc_cols_test)))\n",
    "\n",
    "zero_data = np.zeros(shape=(len(data_prepared_test),1))\n",
    "\n",
    "\n",
    "data_prepared_test.insert(31,\"MOTHER_JOB_5\", zero_data) #Inserting those columns that are not represented in the test data\n",
    "data_prepared_test.insert(21,\"LIVING_4\", zero_data)\n",
    "\n",
    "#data_prepared_test.insert(43,\"FATHER_EDU_6\", zero_data)\n",
    "\n",
    "\n",
    "\n",
    "# obtain predictions on test data using the best model from GridSearchCV (i.e., .best_estimator_) (2)\n",
    "predictions_test = grid_searchRandomForest.best_estimator_.predict(data_prepared_test)\n",
    "\n",
    "# generate the classification report and the confusion matrix for test predictions (3)\n",
    "print(classification_report(labels_test.values.ravel(),predictions_test))\n",
    "print(confusion_matrix(labels_test, predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af4e0a0d28143374aa5d305078a03b698686e6b7df811af5a427e46b8cc107ac"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
