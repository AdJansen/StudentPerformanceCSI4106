{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FN score he got was around 90% in macro, more then 80\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "# we can use the LabelEncoder to encode the gender feature\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, cross_val_score, GridSearchCV, cross_validate\n",
    "\n",
    "# importing two different imputation methods that take into consideration all the features when predicting the missing values\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#multiclass imports\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.dummy import DummyClassifier #Will identify the maority calss base line, model needs to do better then the baseline\n",
    "\n",
    "# oversample the minority class using SMOTE\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "# to reduce randomness then you put the seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Data shape: \n",
      "(145, 31)\n",
      "\n",
      "Data size: \n",
      "4495\n",
      "\n",
      "Data ndim: \n",
      "2\n",
      "\n",
      "_____________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/student_prediction.csv\")\n",
    "\n",
    "df = df.rename(columns = {'KIDS':'PARENT_STATUS'}) #There is a column name error in the data noted in the Kaggle description, this fixes it.\n",
    "df = df.drop([\"STUDENTID\", \"COURSE ID\"], axis=1)\n",
    "\n",
    "gathered_df = pd.read_csv(\"./data/Higher Education Students Performance Evaluation.csv\")\n",
    "gathered_df = gathered_df.rename(columns = {'KIDS':'PARENT_STATUS'})\n",
    "res = list(set(df).difference(set(gathered_df)))\n",
    "print(res)\n",
    "#df = pd.concat([df, gathered_df], axis=0)\n",
    "print(f\"Data shape: \\n{df.shape}\\n\")\n",
    "print(f\"Data size: \\n{df.size}\\n\")\n",
    "print(f\"Data ndim: \\n{df.ndim}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampled Data shape: \n",
      "(280, 31)\n",
      "\n",
      "Oversampled Data size: \n",
      "8680\n",
      "\n",
      "Oversampled Data ndim: \n",
      "2\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "New Class Distribution: Counter({1: 35, 2: 35, 5: 35, 0: 35, 3: 35, 4: 35, 7: 35, 6: 35})\n",
      "_____________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oversample = SMOTE()\n",
    "x_over, y_over = oversample.fit_resample(df.drop([\"GRADE\"], axis=1), df.drop(df.columns[0:-1],axis=1))\n",
    "df = pd.concat([x_over, y_over], axis=1)\n",
    "\n",
    "# print the dimensionality of the oversampled training dataset (0.5)\n",
    "print(f\"Oversampled Data shape: \\n{df.shape}\\n\")\n",
    "print(f\"Oversampled Data size: \\n{df.size}\\n\")\n",
    "print(f\"Oversampled Data ndim: \\n{df.ndim}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "\n",
    "\n",
    "# print the new class distribution using the Counter (1)\n",
    "print(f\"New Class Distribution: {Counter(df['GRADE'])}\")\n",
    "print(\"_____________________________________________\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data shape: \n",
      "     AGE  GENDER  HS_TYPE  SCHOLARSHIP  WORK  ACTIVITY  PARTNER  SALARY  \\\n",
      "86     2       2        2            4     2         2        2       1   \n",
      "137    1       1        1            5     2         1        2       1   \n",
      "184    3       2        2            3     2         2        1       1   \n",
      "5      2       2        2            3     2         2        2       2   \n",
      "124    1       1        2            4     1         1        1       1   \n",
      "..   ...     ...      ...          ...   ...       ...      ...     ...   \n",
      "188    1       1        1            5     2         1        1       1   \n",
      "71     1       1        3            4     2         2        2       1   \n",
      "106    1       2        2            4     2         1        2       1   \n",
      "270    1       2        2            3     1         1        2       1   \n",
      "102    1       2        2            3     2         2        1       1   \n",
      "\n",
      "     TRANSPORT  LIVING  ...  ATTEND  PREP_STUDY  PREP_EXAM  NOTES  LISTENS  \\\n",
      "86           4       2  ...       1           1          1      3        2   \n",
      "137          1       1  ...       1           1          1      3        1   \n",
      "184          3       1  ...       1           1          1      3        2   \n",
      "5            1       1  ...       1           1          1      1        2   \n",
      "124          1       3  ...       1           2          2      3        3   \n",
      "..         ...     ...  ...     ...         ...        ...    ...      ...   \n",
      "188          1       1  ...       1           1          1      3        2   \n",
      "71           1       3  ...       1           1          1      2        3   \n",
      "106          1       2  ...       1           3          2      2        2   \n",
      "270          1       1  ...       1           1          1      2        1   \n",
      "102          1       2  ...       1           1          1      3        1   \n",
      "\n",
      "     LIKES_DISCUSS  CLASSROOM  CUML_GPA  EXP_GPA  GRADE  \n",
      "86               3          2         5        4      5  \n",
      "137              3          1         2        4      2  \n",
      "184              2          2         5        4      3  \n",
      "5                1          2         4        4      2  \n",
      "124              2          1         3        3      3  \n",
      "..             ...        ...       ...      ...    ...  \n",
      "188              3          1         5        3      3  \n",
      "71               3          3         2        2      6  \n",
      "106              2          1         4        4      7  \n",
      "270              3          1         2        2      7  \n",
      "102              2          1         3        4      7  \n",
      "\n",
      "[224 rows x 31 columns]\n",
      "\n",
      "Test Data shape: \n",
      "     AGE  GENDER  HS_TYPE  SCHOLARSHIP  WORK  ACTIVITY  PARTNER  SALARY  \\\n",
      "33     2       1        2            3     1         2        1       1   \n",
      "108    2       1        1            5     2         1        2       2   \n",
      "240    1       2        2            3     2         1        1       1   \n",
      "259    1       1        2            4     1         1        2       1   \n",
      "154    1       1        2            4     1         1        1       4   \n",
      "9      2       1        2            3     2         2        1       3   \n",
      "146    1       1        2            3     1         1        1       1   \n",
      "203    1       1        2            3     1         2        1       1   \n",
      "144    1       1        1            5     2         2        2       3   \n",
      "155    1       1        2            4     1         1        1       2   \n",
      "221    1       1        2            3     1         1        1       1   \n",
      "92     1       2        2            3     2         2        2       1   \n",
      "222    1       2        3            4     1         1        1       1   \n",
      "209    1       2        2            1     1         2        1       1   \n",
      "42     2       2        2            3     2         1        2       1   \n",
      "210    1       2        2            3     1         1        1       1   \n",
      "66     2       2        2            3     2         2        1       1   \n",
      "90     2       1        2            3     2         1        1       1   \n",
      "119    2       1        2            4     2         1        2       1   \n",
      "142    1       1        1            4     2         2        2       1   \n",
      "262    1       2        2            4     2         1        1       1   \n",
      "268    2       2        2            3     2         2        2       1   \n",
      "206    1       1        2            3     1         1        1       2   \n",
      "238    2       1        2            3     2         1        1       1   \n",
      "46     2       2        2            3     2         2        1       1   \n",
      "77     1       2        1            2     2         2        1       2   \n",
      "68     2       1        2            4     1         2        2       1   \n",
      "75     1       2        2            4     2         1        2       1   \n",
      "216    1       1        2            2     1         2        1       1   \n",
      "277    1       2        1            3     2         2        1       2   \n",
      "45     1       2        2            3     2         2        1       4   \n",
      "111    1       1        1            5     2         1        2       1   \n",
      "60     2       1        2            3     2         2        2       5   \n",
      "217    1       2        2            2     1         2        1       1   \n",
      "143    2       1        2            4     1         1        1       5   \n",
      "30     2       2        2            5     1         1        1       1   \n",
      "22     2       2        2            3     1         2        1       1   \n",
      "24     2       2        2            3     2         2        2       2   \n",
      "127    1       1        2            4     2         2        2       1   \n",
      "176    1       1        2            3     1         1        1       1   \n",
      "79     2       2        2            4     2         2        2       1   \n",
      "264    1       2        1            4     1         1        1       2   \n",
      "237    2       1        2            3     2         2        1       1   \n",
      "120    2       1        1            3     1         1        1       2   \n",
      "196    1       2        1            3     1         2        1       1   \n",
      "245    1       1        2            3     1         1        1       1   \n",
      "168    1       1        2            3     1         1        1       3   \n",
      "6      1       2        2            4     2         2        2       1   \n",
      "239    2       1        2            3     1         1        1       1   \n",
      "73     2       2        2            4     2         2        2       1   \n",
      "84     3       2        3            3     1         2        1       3   \n",
      "56     2       2        2            3     2         1        2       1   \n",
      "25     2       2        2            3     2         2        1       1   \n",
      "97     1       2        2            4     1         2        2       1   \n",
      "147    1       1        2            3     1         1        1       2   \n",
      "19     1       2        1            3     2         2        1       2   \n",
      "\n",
      "     TRANSPORT  LIVING  ...  ATTEND  PREP_STUDY  PREP_EXAM  NOTES  LISTENS  \\\n",
      "33           1       1  ...       1           1          1      1        3   \n",
      "108          2       1  ...       2           1          1      2        3   \n",
      "240          1       1  ...       1           1          1      2        2   \n",
      "259          1       2  ...       1           1          1      2        2   \n",
      "154          2       3  ...       1           2          1      2        2   \n",
      "9            4       2  ...       2           1          1      2        2   \n",
      "146          2       2  ...       1           2          1      2        2   \n",
      "203          1       1  ...       1           1          1      2        1   \n",
      "144          1       1  ...       1           2          1      3        2   \n",
      "155          3       3  ...       1           1          1      3        2   \n",
      "221          1       1  ...       1           1          1      3        3   \n",
      "92           1       1  ...       1           1          1      3        2   \n",
      "222          3       2  ...       1           1          1      3        2   \n",
      "209          1       1  ...       1           1          1      3        2   \n",
      "42           4       2  ...       1           1          1      2        1   \n",
      "210          1       1  ...       1           1          1      3        1   \n",
      "66           1       1  ...       1           1          1      3        2   \n",
      "90           2       3  ...       1           1          1      2        3   \n",
      "119          1       2  ...       1           1          2      2        2   \n",
      "142          1       1  ...       1           1          1      3        3   \n",
      "262          1       1  ...       1           1          1      2        2   \n",
      "268          3       1  ...       1           1          1      3        2   \n",
      "206          1       1  ...       1           1          1      2        1   \n",
      "238          1       1  ...       1           1          1      3        2   \n",
      "46           1       1  ...       1           1          1      2        2   \n",
      "77           2       2  ...       2           3          1      2        2   \n",
      "68           1       1  ...       2           1          1      2        2   \n",
      "75           1       3  ...       1           1          1      2        2   \n",
      "216          1       1  ...       1           1          1      2        3   \n",
      "277          1       2  ...       1           1          1      2        2   \n",
      "45           1       1  ...       1           1          1      2        2   \n",
      "111          1       2  ...       1           1          1      3        1   \n",
      "60           2       1  ...       1           1          1      1        3   \n",
      "217          1       1  ...       1           1          1      3        1   \n",
      "143          2       3  ...       1           2          1      2        1   \n",
      "30           1       2  ...       1           2          1      2        3   \n",
      "22           1       1  ...       1           1          2      3        1   \n",
      "24           1       1  ...       1           1          1      2        1   \n",
      "127          4       3  ...       1           1          1      3        2   \n",
      "176          1       1  ...       1           1          1      1        2   \n",
      "79           1       1  ...       1           1          1      3        3   \n",
      "264          1       1  ...       1           1          1      2        1   \n",
      "237          1       1  ...       1           1          1      2        2   \n",
      "120          2       3  ...       2           2          1      3        3   \n",
      "196          1       1  ...       1           1          1      3        1   \n",
      "245          1       2  ...       1           1          1      2        2   \n",
      "168          2       3  ...       1           2          1      3        2   \n",
      "6            1       3  ...       2           1          1      3        3   \n",
      "239          1       2  ...       1           1          1      2        1   \n",
      "73           1       2  ...       1           1          2      3        2   \n",
      "84           1       2  ...       1           3          3      3        3   \n",
      "56           1       1  ...       1           1          2      3        2   \n",
      "25           1       2  ...       1           1          1      2        1   \n",
      "97           1       3  ...       1           1          1      3        2   \n",
      "147          2       3  ...       1           2          1      3        2   \n",
      "19           2       2  ...       1           1          1      3        2   \n",
      "\n",
      "     LIKES_DISCUSS  CLASSROOM  CUML_GPA  EXP_GPA  GRADE  \n",
      "33               2          2         2        3      2  \n",
      "108              1          2         3        3      6  \n",
      "240              2          2         2        2      6  \n",
      "259              2          1         4        2      6  \n",
      "154              2          1         1        2      0  \n",
      "9                2          2         1        2      0  \n",
      "146              2          1         1        2      0  \n",
      "203              2          2         3        2      4  \n",
      "144              3          1         5        4      3  \n",
      "155              2          1         1        2      0  \n",
      "221              2          2         2        2      4  \n",
      "92               3          3         2        2      7  \n",
      "222              2          1         4        3      5  \n",
      "209              3          2         2        2      4  \n",
      "42               3          1         2        3      1  \n",
      "210              3          2         3        2      4  \n",
      "66               2          3         5        4      5  \n",
      "90               2          3         4        2      6  \n",
      "119              3          1         3        3      2  \n",
      "142              2          1         4        3      1  \n",
      "262              3          1         3        3      7  \n",
      "268              3          2         1        2      7  \n",
      "206              2          2         3        2      4  \n",
      "238              2          2         4        3      5  \n",
      "46               3          1         4        2      5  \n",
      "77               2          2         1        1      7  \n",
      "68               3          2         4        3      5  \n",
      "75               2          2         4        1      7  \n",
      "216              1          2         3        2      4  \n",
      "277              2          1         1        2      7  \n",
      "45               2          1         4        3      3  \n",
      "111              3          3         4        3      2  \n",
      "60               3          1         2        1      2  \n",
      "217              3          2         2        2      4  \n",
      "143              2          1         5        3      4  \n",
      "30               3          3         5        4      5  \n",
      "22               2          3         3        3      3  \n",
      "24               3          2         4        4      2  \n",
      "127              2          1         2        2      1  \n",
      "176              2          1         1        3      2  \n",
      "79               3          2         4        4      3  \n",
      "264              3          1         3        3      7  \n",
      "237              3          1         3        2      5  \n",
      "120              3          2         2        2      1  \n",
      "196              2          3         2        3      3  \n",
      "245              2          1         3        2      6  \n",
      "168              2          1         1        2      0  \n",
      "6                3          3         4        4      5  \n",
      "239              2          1         3        3      5  \n",
      "73               3          1         5        3      6  \n",
      "84               3          3         5        4      7  \n",
      "56               3          3         5        4      5  \n",
      "25               3          2         1        2      3  \n",
      "97               2          1         3        3      6  \n",
      "147              2          1         1        2      0  \n",
      "19               2          3         2        3      3  \n",
      "\n",
      "[56 rows x 31 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "print(f\"Train Data shape: \\n{data_train}\\n\")\n",
    "print(f\"Test Data shape: \\n{data_test}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>HS_TYPE</th>\n",
       "      <th>SCHOLARSHIP</th>\n",
       "      <th>WORK</th>\n",
       "      <th>ACTIVITY</th>\n",
       "      <th>PARTNER</th>\n",
       "      <th>SALARY</th>\n",
       "      <th>TRANSPORT</th>\n",
       "      <th>LIVING</th>\n",
       "      <th>...</th>\n",
       "      <th>ATTEND</th>\n",
       "      <th>PREP_STUDY</th>\n",
       "      <th>PREP_EXAM</th>\n",
       "      <th>NOTES</th>\n",
       "      <th>LISTENS</th>\n",
       "      <th>LIKES_DISCUSS</th>\n",
       "      <th>CLASSROOM</th>\n",
       "      <th>CUML_GPA</th>\n",
       "      <th>EXP_GPA</th>\n",
       "      <th>GRADE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AGE  GENDER  HS_TYPE  SCHOLARSHIP  WORK  ACTIVITY  PARTNER  SALARY  \\\n",
       "0      2       2        3            3     1         2        2       1   \n",
       "1      2       2        3            3     1         2        2       1   \n",
       "2      2       2        2            3     2         2        2       2   \n",
       "3      1       1        1            3     1         2        1       2   \n",
       "4      2       2        1            3     2         2        1       3   \n",
       "..   ...     ...      ...          ...   ...       ...      ...     ...   \n",
       "275    1       2        2            4     2         1        2       1   \n",
       "276    1       2        2            4     1         2        1       2   \n",
       "277    1       2        1            3     2         2        1       2   \n",
       "278    1       2        2            4     1         1        1       1   \n",
       "279    1       2        2            3     2         2        1       1   \n",
       "\n",
       "     TRANSPORT  LIVING  ...  ATTEND  PREP_STUDY  PREP_EXAM  NOTES  LISTENS  \\\n",
       "0            1       1  ...       1           1          1      3        2   \n",
       "1            1       1  ...       1           1          1      3        2   \n",
       "2            4       2  ...       1           1          1      2        2   \n",
       "3            1       2  ...       1           1          2      3        2   \n",
       "4            1       4  ...       1           2          1      2        2   \n",
       "..         ...     ...  ...     ...         ...        ...    ...      ...   \n",
       "275          1       2  ...       1           1          1      2        2   \n",
       "276          1       1  ...       1           1          1      3        3   \n",
       "277          1       2  ...       1           1          1      2        2   \n",
       "278          1       1  ...       1           1          1      2        1   \n",
       "279          1       2  ...       1           1          1      3        2   \n",
       "\n",
       "     LIKES_DISCUSS  CLASSROOM  CUML_GPA  EXP_GPA  GRADE  \n",
       "0                1          2         1        1      1  \n",
       "1                3          2         2        3      1  \n",
       "2                1          1         2        2      1  \n",
       "3                2          1         3        2      1  \n",
       "4                2          1         2        2      1  \n",
       "..             ...        ...       ...      ...    ...  \n",
       "275              2          2         3        1      7  \n",
       "276              2          2         3        3      7  \n",
       "277              2          1         1        2      7  \n",
       "278              3          1         2        3      7  \n",
       "279              2          1         2        3      7  \n",
       "\n",
       "[280 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_train: \n",
      "     GRADE\n",
      "86       5\n",
      "137      2\n",
      "184      3\n",
      "5        2\n",
      "124      3\n",
      "..     ...\n",
      "188      3\n",
      "71       6\n",
      "106      7\n",
      "270      7\n",
      "102      7\n",
      "\n",
      "[224 rows x 1 columns]\n",
      "\n",
      "labels_test: \n",
      "     GRADE\n",
      "33       2\n",
      "108      6\n",
      "240      6\n",
      "259      6\n",
      "154      0\n",
      "9        0\n",
      "146      0\n",
      "203      4\n",
      "144      3\n",
      "155      0\n",
      "221      4\n",
      "92       7\n",
      "222      5\n",
      "209      4\n",
      "42       1\n",
      "210      4\n",
      "66       5\n",
      "90       6\n",
      "119      2\n",
      "142      1\n",
      "262      7\n",
      "268      7\n",
      "206      4\n",
      "238      5\n",
      "46       5\n",
      "77       7\n",
      "68       5\n",
      "75       7\n",
      "216      4\n",
      "277      7\n",
      "45       3\n",
      "111      2\n",
      "60       2\n",
      "217      4\n",
      "143      4\n",
      "30       5\n",
      "22       3\n",
      "24       2\n",
      "127      1\n",
      "176      2\n",
      "79       3\n",
      "264      7\n",
      "237      5\n",
      "120      1\n",
      "196      3\n",
      "245      6\n",
      "168      0\n",
      "6        5\n",
      "239      5\n",
      "73       6\n",
      "84       7\n",
      "56       5\n",
      "25       3\n",
      "97       6\n",
      "147      0\n",
      "19       3\n",
      "\n",
      "features_train: \n",
      "     AGE  GENDER  HS_TYPE  SCHOLARSHIP  WORK  ACTIVITY  PARTNER  SALARY  \\\n",
      "86     2       2        2            4     2         2        2       1   \n",
      "137    1       1        1            5     2         1        2       1   \n",
      "184    3       2        2            3     2         2        1       1   \n",
      "5      2       2        2            3     2         2        2       2   \n",
      "124    1       1        2            4     1         1        1       1   \n",
      "..   ...     ...      ...          ...   ...       ...      ...     ...   \n",
      "188    1       1        1            5     2         1        1       1   \n",
      "71     1       1        3            4     2         2        2       1   \n",
      "106    1       2        2            4     2         1        2       1   \n",
      "270    1       2        2            3     1         1        2       1   \n",
      "102    1       2        2            3     2         2        1       1   \n",
      "\n",
      "     TRANSPORT  LIVING  ...  IMPACT  ATTEND  PREP_STUDY  PREP_EXAM  NOTES  \\\n",
      "86           4       2  ...       1       1           1          1      3   \n",
      "137          1       1  ...       1       1           1          1      3   \n",
      "184          3       1  ...       1       1           1          1      3   \n",
      "5            1       1  ...       1       1           1          1      1   \n",
      "124          1       3  ...       1       1           2          2      3   \n",
      "..         ...     ...  ...     ...     ...         ...        ...    ...   \n",
      "188          1       1  ...       1       1           1          1      3   \n",
      "71           1       3  ...       1       1           1          1      2   \n",
      "106          1       2  ...       1       1           3          2      2   \n",
      "270          1       1  ...       1       1           1          1      2   \n",
      "102          1       2  ...       1       1           1          1      3   \n",
      "\n",
      "     LISTENS  LIKES_DISCUSS  CLASSROOM  CUML_GPA  EXP_GPA  \n",
      "86         2              3          2         5        4  \n",
      "137        1              3          1         2        4  \n",
      "184        2              2          2         5        4  \n",
      "5          2              1          2         4        4  \n",
      "124        3              2          1         3        3  \n",
      "..       ...            ...        ...       ...      ...  \n",
      "188        2              3          1         5        3  \n",
      "71         3              3          3         2        2  \n",
      "106        2              2          1         4        4  \n",
      "270        1              3          1         2        2  \n",
      "102        1              2          1         3        4  \n",
      "\n",
      "[224 rows x 30 columns]\n",
      "\n",
      "lfeatures_test: \n",
      "     AGE  GENDER  HS_TYPE  SCHOLARSHIP  WORK  ACTIVITY  PARTNER  SALARY  \\\n",
      "33     2       1        2            3     1         2        1       1   \n",
      "108    2       1        1            5     2         1        2       2   \n",
      "240    1       2        2            3     2         1        1       1   \n",
      "259    1       1        2            4     1         1        2       1   \n",
      "154    1       1        2            4     1         1        1       4   \n",
      "9      2       1        2            3     2         2        1       3   \n",
      "146    1       1        2            3     1         1        1       1   \n",
      "203    1       1        2            3     1         2        1       1   \n",
      "144    1       1        1            5     2         2        2       3   \n",
      "155    1       1        2            4     1         1        1       2   \n",
      "221    1       1        2            3     1         1        1       1   \n",
      "92     1       2        2            3     2         2        2       1   \n",
      "222    1       2        3            4     1         1        1       1   \n",
      "209    1       2        2            1     1         2        1       1   \n",
      "42     2       2        2            3     2         1        2       1   \n",
      "210    1       2        2            3     1         1        1       1   \n",
      "66     2       2        2            3     2         2        1       1   \n",
      "90     2       1        2            3     2         1        1       1   \n",
      "119    2       1        2            4     2         1        2       1   \n",
      "142    1       1        1            4     2         2        2       1   \n",
      "262    1       2        2            4     2         1        1       1   \n",
      "268    2       2        2            3     2         2        2       1   \n",
      "206    1       1        2            3     1         1        1       2   \n",
      "238    2       1        2            3     2         1        1       1   \n",
      "46     2       2        2            3     2         2        1       1   \n",
      "77     1       2        1            2     2         2        1       2   \n",
      "68     2       1        2            4     1         2        2       1   \n",
      "75     1       2        2            4     2         1        2       1   \n",
      "216    1       1        2            2     1         2        1       1   \n",
      "277    1       2        1            3     2         2        1       2   \n",
      "45     1       2        2            3     2         2        1       4   \n",
      "111    1       1        1            5     2         1        2       1   \n",
      "60     2       1        2            3     2         2        2       5   \n",
      "217    1       2        2            2     1         2        1       1   \n",
      "143    2       1        2            4     1         1        1       5   \n",
      "30     2       2        2            5     1         1        1       1   \n",
      "22     2       2        2            3     1         2        1       1   \n",
      "24     2       2        2            3     2         2        2       2   \n",
      "127    1       1        2            4     2         2        2       1   \n",
      "176    1       1        2            3     1         1        1       1   \n",
      "79     2       2        2            4     2         2        2       1   \n",
      "264    1       2        1            4     1         1        1       2   \n",
      "237    2       1        2            3     2         2        1       1   \n",
      "120    2       1        1            3     1         1        1       2   \n",
      "196    1       2        1            3     1         2        1       1   \n",
      "245    1       1        2            3     1         1        1       1   \n",
      "168    1       1        2            3     1         1        1       3   \n",
      "6      1       2        2            4     2         2        2       1   \n",
      "239    2       1        2            3     1         1        1       1   \n",
      "73     2       2        2            4     2         2        2       1   \n",
      "84     3       2        3            3     1         2        1       3   \n",
      "56     2       2        2            3     2         1        2       1   \n",
      "25     2       2        2            3     2         2        1       1   \n",
      "97     1       2        2            4     1         2        2       1   \n",
      "147    1       1        2            3     1         1        1       2   \n",
      "19     1       2        1            3     2         2        1       2   \n",
      "\n",
      "     TRANSPORT  LIVING  ...  IMPACT  ATTEND  PREP_STUDY  PREP_EXAM  NOTES  \\\n",
      "33           1       1  ...       1       1           1          1      1   \n",
      "108          2       1  ...       1       2           1          1      2   \n",
      "240          1       1  ...       1       1           1          1      2   \n",
      "259          1       2  ...       1       1           1          1      2   \n",
      "154          2       3  ...       2       1           2          1      2   \n",
      "9            4       2  ...       1       2           1          1      2   \n",
      "146          2       2  ...       1       1           2          1      2   \n",
      "203          1       1  ...       1       1           1          1      2   \n",
      "144          1       1  ...       1       1           2          1      3   \n",
      "155          3       3  ...       1       1           1          1      3   \n",
      "221          1       1  ...       1       1           1          1      3   \n",
      "92           1       1  ...       1       1           1          1      3   \n",
      "222          3       2  ...       1       1           1          1      3   \n",
      "209          1       1  ...       1       1           1          1      3   \n",
      "42           4       2  ...       1       1           1          1      2   \n",
      "210          1       1  ...       1       1           1          1      3   \n",
      "66           1       1  ...       1       1           1          1      3   \n",
      "90           2       3  ...       1       1           1          1      2   \n",
      "119          1       2  ...       1       1           1          2      2   \n",
      "142          1       1  ...       1       1           1          1      3   \n",
      "262          1       1  ...       1       1           1          1      2   \n",
      "268          3       1  ...       1       1           1          1      3   \n",
      "206          1       1  ...       1       1           1          1      2   \n",
      "238          1       1  ...       1       1           1          1      3   \n",
      "46           1       1  ...       1       1           1          1      2   \n",
      "77           2       2  ...       1       2           3          1      2   \n",
      "68           1       1  ...       1       2           1          1      2   \n",
      "75           1       3  ...       1       1           1          1      2   \n",
      "216          1       1  ...       2       1           1          1      2   \n",
      "277          1       2  ...       1       1           1          1      2   \n",
      "45           1       1  ...       1       1           1          1      2   \n",
      "111          1       2  ...       2       1           1          1      3   \n",
      "60           2       1  ...       1       1           1          1      1   \n",
      "217          1       1  ...       1       1           1          1      3   \n",
      "143          2       3  ...       1       1           2          1      2   \n",
      "30           1       2  ...       1       1           2          1      2   \n",
      "22           1       1  ...       1       1           1          2      3   \n",
      "24           1       1  ...       1       1           1          1      2   \n",
      "127          4       3  ...       1       1           1          1      3   \n",
      "176          1       1  ...       1       1           1          1      1   \n",
      "79           1       1  ...       3       1           1          1      3   \n",
      "264          1       1  ...       1       1           1          1      2   \n",
      "237          1       1  ...       1       1           1          1      2   \n",
      "120          2       3  ...       1       2           2          1      3   \n",
      "196          1       1  ...       1       1           1          1      3   \n",
      "245          1       2  ...       1       1           1          1      2   \n",
      "168          2       3  ...       2       1           2          1      3   \n",
      "6            1       3  ...       1       2           1          1      3   \n",
      "239          1       2  ...       1       1           1          1      2   \n",
      "73           1       2  ...       1       1           1          2      3   \n",
      "84           1       2  ...       1       1           3          3      3   \n",
      "56           1       1  ...       1       1           1          2      3   \n",
      "25           1       2  ...       1       1           1          1      2   \n",
      "97           1       3  ...       1       1           1          1      3   \n",
      "147          2       3  ...       1       1           2          1      3   \n",
      "19           2       2  ...       2       1           1          1      3   \n",
      "\n",
      "     LISTENS  LIKES_DISCUSS  CLASSROOM  CUML_GPA  EXP_GPA  \n",
      "33         3              2          2         2        3  \n",
      "108        3              1          2         3        3  \n",
      "240        2              2          2         2        2  \n",
      "259        2              2          1         4        2  \n",
      "154        2              2          1         1        2  \n",
      "9          2              2          2         1        2  \n",
      "146        2              2          1         1        2  \n",
      "203        1              2          2         3        2  \n",
      "144        2              3          1         5        4  \n",
      "155        2              2          1         1        2  \n",
      "221        3              2          2         2        2  \n",
      "92         2              3          3         2        2  \n",
      "222        2              2          1         4        3  \n",
      "209        2              3          2         2        2  \n",
      "42         1              3          1         2        3  \n",
      "210        1              3          2         3        2  \n",
      "66         2              2          3         5        4  \n",
      "90         3              2          3         4        2  \n",
      "119        2              3          1         3        3  \n",
      "142        3              2          1         4        3  \n",
      "262        2              3          1         3        3  \n",
      "268        2              3          2         1        2  \n",
      "206        1              2          2         3        2  \n",
      "238        2              2          2         4        3  \n",
      "46         2              3          1         4        2  \n",
      "77         2              2          2         1        1  \n",
      "68         2              3          2         4        3  \n",
      "75         2              2          2         4        1  \n",
      "216        3              1          2         3        2  \n",
      "277        2              2          1         1        2  \n",
      "45         2              2          1         4        3  \n",
      "111        1              3          3         4        3  \n",
      "60         3              3          1         2        1  \n",
      "217        1              3          2         2        2  \n",
      "143        1              2          1         5        3  \n",
      "30         3              3          3         5        4  \n",
      "22         1              2          3         3        3  \n",
      "24         1              3          2         4        4  \n",
      "127        2              2          1         2        2  \n",
      "176        2              2          1         1        3  \n",
      "79         3              3          2         4        4  \n",
      "264        1              3          1         3        3  \n",
      "237        2              3          1         3        2  \n",
      "120        3              3          2         2        2  \n",
      "196        1              2          3         2        3  \n",
      "245        2              2          1         3        2  \n",
      "168        2              2          1         1        2  \n",
      "6          3              3          3         4        4  \n",
      "239        1              2          1         3        3  \n",
      "73         2              3          1         5        3  \n",
      "84         3              3          3         5        4  \n",
      "56         2              3          3         5        4  \n",
      "25         1              3          2         1        2  \n",
      "97         2              2          1         3        3  \n",
      "147        2              2          1         1        2  \n",
      "19         2              2          3         2        3  \n",
      "\n",
      "[56 rows x 30 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Extracting Labels\n",
    "\n",
    "columns = data_train.columns.to_list()\n",
    "columns_drop = columns.pop(-1)\n",
    "labels_train = data_train.drop(columns, axis=1)\n",
    "labels_test = data_test.drop(columns, axis=1)\n",
    "\n",
    "print(f\"labels_train: \\n{labels_train}\\n\")\n",
    "print(f\"labels_test: \\n{labels_test}\\n\")\n",
    "\n",
    "features_train = data_train.drop(['GRADE'], axis=1)\n",
    "features_test = data_test.drop(['GRADE'], axis=1)\n",
    "print(f\"features_train: \\n{features_train }\\n\")\n",
    "print(f\"lfeatures_test: \\n{features_test }\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ohenc = OneHotEncoder(sparse=False)\n",
    "\n",
    "ohenc_cols = ohenc.fit(features_train.drop(['AGE', 'SCHOLARSHIP', 'SALARY', 'MOTHER_EDU', 'FATHER_EDU', '#_SIBLINGS', 'STUDY_HRS', \n",
    "                'READ_FREQ', 'READ_FREQ_SCI', 'IMPACT', 'ATTEND', 'NOTES', 'LISTENS', 'LIKES_DISCUSS',\n",
    "                'CUML_GPA', 'EXP_GPA'], axis=1)).get_feature_names_out()\n",
    "\n",
    "\n",
    "ord_attribs = ['AGE', 'SCHOLARSHIP', 'SALARY', 'MOTHER_EDU', 'FATHER_EDU', '#_SIBLINGS', 'STUDY_HRS', \n",
    "                'READ_FREQ', 'READ_FREQ_SCI', 'IMPACT', 'ATTEND', 'NOTES', 'LISTENS', 'LIKES_DISCUSS',\n",
    "                'CUML_GPA', 'EXP_GPA']\n",
    "nom_attribs = ['GENDER', 'HS_TYPE', 'WORK', 'ACTIVITY', 'PARTNER', 'TRANSPORT', 'LIVING', 'PARENT_STATUS',\n",
    "                'MOTHER_JOB', 'FATHER_JOB', 'ATTEND_DEPT', 'PREP_STUDY', 'PREP_EXAM', 'CLASSROOM']\n",
    "\n",
    "pipe_cols = ['AGE' ,'GENDER_1' ,'GENDER_2' ,'HS_TYPE_1' ,'HS_TYPE_2' ,'HS_TYPE_3', 'SCHOLARSHIP' ,'WORK_1',\n",
    "             'WORK_2' ,'ACTIVITY_1', 'ACTIVITY_2', 'PARTNER_1' ,'PARTNER_2' ,'SALARY', 'TRANSPORT_1',\n",
    "             'TRANSPORT_2', 'TRANSPORT_3' ,'TRANSPORT_4' ,'LIVING_1' ,'LIVING_2', 'LIVING_3', 'LIVING_4',\n",
    "             'MOTHER_EDU', 'FATHER_EDU', '#_SIBLINGS', 'PARENT_STATUS_1' ,'PARENT_STATUS_2', 'PARENT_STATUS_3',\n",
    "             'MOTHER_JOB_1' ,'MOTHER_JOB_2' ,'MOTHER_JOB_3', 'MOTHER_JOB_4' ,'MOTHER_JOB_5' ,'FATHER_JOB_1' , \n",
    "             'FATHER_JOB_2', 'FATHER_JOB_3' ,'FATHER_JOB_4' ,'FATHER_JOB_5', 'STUDY_HRS', 'READ_FREQ',\n",
    "             'READ_FREQ_SCI',  'ATTEND_DEPT_1', 'ATTEND_DEPT_2', 'IMPACT', 'ATTEND','PREP_STUDY_1' ,'PREP_STUDY_2', \n",
    "             'PREP_STUDY_3', 'PREP_EXAM_1', 'PREP_EXAM_2' ,'PREP_EXAM_3' ,'NOTES', 'LISTENS', 'LIKES_DISCUSS', \n",
    "             'CLASSROOM_1' ,'CLASSROOM_2', 'CLASSROOM_3','CUML_GPA', 'EXP_GPA']\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"Nominal\", OneHotEncoder(), nom_attribs),\n",
    "        (\"Ordinal\", OrdinalEncoder(), ord_attribs)\n",
    "    ])\n",
    "\n",
    "data_prepared = pd.DataFrame(full_pipeline.fit_transform(features_train),columns=pipe_cols, index=features_train.index)\n",
    "#full_pipeline.fit_transform(data_train)\n",
    "#pd.DataFrame(full_pipeline.fit_transform(train_df),columns=train_df.columns, index=train_df.index)\\\n",
    "\n",
    "zero_data = np.zeros(shape=(len(data_prepared),1))\n",
    "\n",
    "#data_prepared.insert(37,\"MOTHER_EDU_6\", zero_data) #Inserting those columns that are not represented in the train data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the following four different models with their default hyperparameter values to be trained using the preprocessed data (0.5 * 4)\n",
    "labelTrainFlat = labels_train.values.ravel()\n",
    "# Gradient Boosting\n",
    "gradientBoosting = OneVsRestClassifier(GradientBoostingClassifier())\n",
    "gradientBoosting = gradientBoosting.fit(data_prepared, labelTrainFlat)\n",
    "\n",
    "# Decision Trees\n",
    "decisionTree = DecisionTreeClassifier()\n",
    "decisionTree = decisionTree.fit(data_prepared,labelTrainFlat)\n",
    "\n",
    "# Random Forests\n",
    "randomForest = RandomForestClassifier()\n",
    "randomForest = randomForest.fit(data_prepared,labelTrainFlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters GradientBoosting: \n",
      "{'estimator__learning_rate': 0.44, 'estimator__min_samples_leaf': 7, 'estimator__min_samples_split': 9, 'estimator__n_estimators': 59}\n",
      "\n",
      "Best estimator GradientBoosting: \n",
      "OneVsRestClassifier(estimator=GradientBoostingClassifier(learning_rate=0.44,\n",
      "                                                         min_samples_leaf=7,\n",
      "                                                         min_samples_split=9,\n",
      "                                                         n_estimators=59))\n",
      "\n",
      "Best score GradientBoosting: \n",
      "0.7120535714285714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parametersGradientBoosting = [\n",
    "    {'estimator__learning_rate': [0.44,0.45,0.46],'estimator__min_samples_leaf': [5,6,7],'estimator__min_samples_split': [7,8,9,10], 'estimator__n_estimators': [57,58,59,60]}\n",
    "]\n",
    "scoringX = {\"accuracy\": \"accuracy\", \"bal_accuracy\": \"balanced_accuracy\", \"F1_macro\": \"f1_macro\"}\n",
    "\n",
    "grid_searchGradientBoosting = GridSearchCV(gradientBoosting, parametersGradientBoosting, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "grid_searchGradientBoosting.fit(data_prepared, labelTrainFlat)\n",
    "\n",
    "print(f\"Best parameters GradientBoosting: \\n{grid_searchGradientBoosting.best_params_}\\n\")\n",
    "print(f\"Best estimator GradientBoosting: \\n{grid_searchGradientBoosting.best_estimator_}\\n\")\n",
    "print(f\"Best score GradientBoosting: \\n{grid_searchGradientBoosting.best_score_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters KNeighbors: \n",
      "{'algorithm': 'auto', 'n_neighbors': 1, 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "Best estimator KNeighbors: \n",
      "KNeighborsClassifier(n_neighbors=1)\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.6595117845117845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# KNeighbors\n",
    "kNeighbors = KNeighborsClassifier()\n",
    "kNeighbors = kNeighbors.fit(data_prepared,labelTrainFlat)\n",
    "\n",
    "parametersKNeighbors = [\n",
    "    {'n_neighbors': [1,2,3],'weights':['uniform', 'distance'],'algorithm':['auto'], 'p': [1,2,3]}\n",
    "]\n",
    "scoringX = {\"accuracy\": \"accuracy\", \"bal_accuracy\": \"balanced_accuracy\", \"F1_macro\": \"f1_macro\"}\n",
    "\n",
    "grid_searchKNeighbors = GridSearchCV(kNeighbors, parametersKNeighbors, cv=3, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "grid_searchKNeighbors.fit(data_prepared, labelTrainFlat)\n",
    "\n",
    "print(f\"Best parameters KNeighbors: \\n{grid_searchKNeighbors.best_params_}\\n\")\n",
    "print(f\"Best estimator KNeighbors: \\n{grid_searchKNeighbors.best_estimator_}\\n\")\n",
    "print(f\"Best score KNeighbors: \\n{grid_searchKNeighbors.best_score_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters Logistic Regression: \n",
      "{'C': 1, 'multi_class': 'ovr', 'penalty': 'l2'}\n",
      "\n",
      "Best estimator Logistic Regression: \n",
      "LogisticRegression(C=1, multi_class='ovr')\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.4668034511784511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "logisticRegression = LogisticRegression()\n",
    "logisticRegression = logisticRegression.fit(data_prepared,labelTrainFlat)\n",
    "\n",
    "parametersLogisticRegression = [\n",
    "    {'multi_class': ['ovr'],'penalty':['none','l2'], 'C': [1,2,3]}\n",
    "]\n",
    "scoringX = {\"accuracy\": \"accuracy\", \"bal_accuracy\": \"balanced_accuracy\", \"F1_macro\": \"f1_macro\"}\n",
    "\n",
    "grid_searchLogisticRegression = GridSearchCV(logisticRegression, parametersLogisticRegression, cv=3, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "grid_searchLogisticRegression.fit(data_prepared, labelTrainFlat)\n",
    "\n",
    "print(f\"Best parameters Logistic Regression: \\n{grid_searchLogisticRegression.best_params_}\\n\")\n",
    "print(f\"Best estimator Logistic Regression: \\n{grid_searchLogisticRegression.best_estimator_}\\n\")\n",
    "print(f\"Best score Logistic Regression: \\n{grid_searchLogisticRegression.best_score_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters DecisionTree: \n",
      "{'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "\n",
      "Best estimator DecisionTree: \n",
      "DecisionTreeClassifier(max_depth=4, min_samples_leaf=4)\n",
      "\n",
      "Best score DecisionTree: \n",
      "0.3375210437710437\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "36 fits failed out of a total of 108.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "36 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.18780781 0.18780781        nan 0.18780781 0.18780781\n",
      "        nan 0.18780781 0.18780781        nan 0.25033033 0.25033033\n",
      "        nan 0.25033033 0.25033033        nan 0.25033033 0.25033033\n",
      "        nan 0.29489489 0.29489489        nan 0.2993994  0.2993994\n",
      "        nan 0.29495495 0.29495495        nan 0.33513514 0.33513514\n",
      "        nan 0.32174174 0.32174174        nan 0.29927928 0.29927928]\n",
      "  warnings.warn(\n",
      "C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan 0.22316182 0.22316182        nan 0.22316182 0.22316182\n",
      "        nan 0.22316182 0.22316182        nan 0.33475019 0.33475019\n",
      "        nan 0.33475019 0.33475019        nan 0.33475019 0.33475019\n",
      "        nan 0.4261745  0.4261745         nan 0.42173005 0.42173005\n",
      "        nan 0.41501864 0.41501864        nan 0.52210291 0.52210291\n",
      "        nan 0.49988069 0.49988069        nan 0.48428039 0.48428039]\n",
      "  warnings.warn(\n",
      "C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.18333333 0.18333333        nan 0.18333333 0.18333333\n",
      "        nan 0.18333333 0.18333333        nan 0.25046296 0.25046296\n",
      "        nan 0.25046296 0.25046296        nan 0.25046296 0.25046296\n",
      "        nan 0.29560185 0.29560185        nan 0.29976852 0.29976852\n",
      "        nan 0.29560185 0.29560185        nan 0.33752104 0.33752104\n",
      "        nan 0.32458965 0.32458965        nan 0.30063131 0.30063131]\n",
      "  warnings.warn(\n",
      "C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan 0.21667015 0.21667015        nan 0.21667015 0.21667015\n",
      "        nan 0.21667015 0.21667015        nan 0.33296784 0.33296784\n",
      "        nan 0.33296784 0.33296784        nan 0.33296784 0.33296784\n",
      "        nan 0.4230256  0.4230256         nan 0.41827414 0.41827414\n",
      "        nan 0.41132969 0.41132969        nan 0.51905202 0.51905202\n",
      "        nan 0.4967609  0.4967609         nan 0.47962963 0.47962963]\n",
      "  warnings.warn(\n",
      "C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.07941806 0.07941806        nan 0.07941806 0.07941806\n",
      "        nan 0.07941806 0.07941806        nan 0.15208118 0.15208118\n",
      "        nan 0.15208118 0.15208118        nan 0.15208118 0.15208118\n",
      "        nan 0.24248192 0.24248192        nan 0.24747955 0.24747955\n",
      "        nan 0.23855098 0.23855098        nan 0.32343343 0.32343343\n",
      "        nan 0.29766227 0.29766227        nan 0.27659776 0.27659776]\n",
      "  warnings.warn(\n",
      "C:\\Users\\adamj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan 0.10426742 0.10426742        nan 0.10426742 0.10426742\n",
      "        nan 0.10426742 0.10426742        nan 0.21781378 0.21781378\n",
      "        nan 0.21781378 0.21781378        nan 0.21781378 0.21781378\n",
      "        nan 0.36864155 0.36864155        nan 0.36567652 0.36567652\n",
      "        nan 0.35090065 0.35090065        nan 0.5096623  0.5096623\n",
      "        nan 0.47405797 0.47405797        nan 0.44367469 0.44367469]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "parametersDecisionTree = [\n",
    "    {'max_depth': [1,2,3,4], 'min_samples_leaf': [4,5,6], 'min_samples_split': [1,2,3]}\n",
    "]\n",
    "\n",
    "grid_searchDecisionTree = GridSearchCV(decisionTree, parametersDecisionTree, cv=3, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "grid_searchDecisionTree.fit(data_prepared, labelTrainFlat)\n",
    "\n",
    "print(f\"Best parameters DecisionTree: \\n{grid_searchDecisionTree.best_params_}\\n\")\n",
    "print(f\"Best estimator DecisionTree: \\n{grid_searchDecisionTree.best_estimator_}\\n\")\n",
    "print(f\"Best score DecisionTree: \\n{grid_searchDecisionTree.best_score_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters RandomForest: \n",
      "{'bootstrap': False, 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 155}\n",
      "\n",
      "Best estimator RandomForest: \n",
      "RandomForestClassifier(bootstrap=False, max_depth=10, n_estimators=155)\n",
      "\n",
      "Best score RandomForest: \n",
      "0.68359375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parametersRandomForest = [\n",
    "    {'n_estimators': [145,150,155,190],'max_depth': [10,12], 'bootstrap': [True, False],\n",
    "     'min_samples_split': [0.05,2]}\n",
    "]\n",
    "\n",
    "grid_searchRandomForest = GridSearchCV(randomForest, parametersRandomForest, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "grid_searchRandomForest.fit(data_prepared, labelTrainFlat)\n",
    "\n",
    "print(f\"Best parameters RandomForest: \\n{grid_searchRandomForest.best_params_}\\n\")\n",
    "\n",
    "print(f\"Best estimator RandomForest: \\n{grid_searchRandomForest.best_estimator_}\\n\")\n",
    "\n",
    "print(f\"Best score RandomForest: \\n{grid_searchRandomForest.best_score_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test Accuracy for GradientBoosting: \n",
      "[0.64285714 0.625      0.63392857 0.625      0.62053571 0.63392857\n",
      " 0.63839286 0.625      0.62053571 0.63839286 0.64732143 0.625\n",
      " 0.64285714 0.63392857 0.63392857 0.63392857 0.68303571 0.67410714\n",
      " 0.67857143 0.67410714 0.67410714 0.67857143 0.67857143 0.6875\n",
      " 0.67410714 0.6875     0.66964286 0.67410714 0.67857143 0.66964286\n",
      " 0.67857143 0.67857143 0.6875     0.69642857 0.69196429 0.69196429\n",
      " 0.69196429 0.6875     0.69196429 0.69642857 0.69642857 0.70535714\n",
      " 0.70535714 0.69642857 0.70089286 0.6875     0.69196429 0.69642857\n",
      " 0.64285714 0.64732143 0.65178571 0.64285714 0.64285714 0.64732143\n",
      " 0.64285714 0.66071429 0.64732143 0.64732143 0.65625    0.63839286\n",
      " 0.65178571 0.64732143 0.65625    0.64285714 0.65625    0.65178571\n",
      " 0.65178571 0.65625    0.65178571 0.64285714 0.64732143 0.64732143\n",
      " 0.65625    0.65178571 0.65625    0.66071429 0.65625    0.65178571\n",
      " 0.65178571 0.65625    0.70089286 0.70089286 0.6875     0.70089286\n",
      " 0.68303571 0.69642857 0.6875     0.69196429 0.70089286 0.69196429\n",
      " 0.6875     0.69642857 0.6875     0.69196429 0.69196429 0.69642857\n",
      " 0.65178571 0.66517857 0.65625    0.65625    0.65625    0.65625\n",
      " 0.66071429 0.65625    0.65625    0.65178571 0.66071429 0.65178571\n",
      " 0.65178571 0.66964286 0.66071429 0.66071429 0.66517857 0.66517857\n",
      " 0.67410714 0.65625    0.66517857 0.66964286 0.66964286 0.66964286\n",
      " 0.66517857 0.66517857 0.65625    0.66964286 0.67410714 0.66964286\n",
      " 0.66964286 0.65178571 0.66964286 0.67857143 0.68303571 0.67410714\n",
      " 0.67410714 0.67857143 0.66517857 0.67410714 0.67410714 0.66071429\n",
      " 0.66964286 0.68303571 0.68303571 0.67410714 0.68303571 0.67857143]\n",
      "\n",
      "Balanced Test Accuracy for GradientBoosting: \n",
      "[0.64639137 0.6296503  0.63802083 0.62909226 0.62462798 0.63802083\n",
      " 0.64248512 0.6296503  0.62518601 0.64192708 0.65085565 0.62909226\n",
      " 0.64639137 0.63802083 0.63857887 0.63857887 0.69084821 0.6811756\n",
      " 0.68694196 0.6811756  0.6811756  0.68638393 0.68638393 0.69475446\n",
      " 0.68191964 0.69419643 0.67726935 0.68173363 0.68582589 0.67726935\n",
      " 0.68563988 0.68508185 0.69419643 0.70256696 0.69866071 0.69921875\n",
      " 0.69866071 0.69363839 0.69735863 0.70368304 0.70386905 0.71149554\n",
      " 0.71205357 0.70182292 0.70758929 0.69419643 0.69735863 0.70368304\n",
      " 0.64732143 0.65104167 0.65625    0.64787946 0.64787946 0.65104167\n",
      " 0.64732143 0.66462054 0.65104167 0.65215774 0.65959821 0.6421131\n",
      " 0.65569196 0.65104167 0.66071429 0.64657738 0.66183036 0.65662202\n",
      " 0.65792411 0.66052827 0.65662202 0.64880952 0.65141369 0.65085565\n",
      " 0.66183036 0.65662202 0.66238839 0.66499256 0.66183036 0.65662202\n",
      " 0.65792411 0.66052827 0.70814732 0.70814732 0.6953125  0.70758929\n",
      " 0.68973214 0.70368304 0.69475446 0.69866071 0.70814732 0.69977679\n",
      " 0.69419643 0.70442708 0.69419643 0.69921875 0.69921875 0.70386905\n",
      " 0.65587798 0.66927083 0.65904018 0.65959821 0.6609003  0.66015625\n",
      " 0.66350446 0.65959821 0.66164435 0.65569196 0.66350446 0.65513393\n",
      " 0.65643601 0.67317708 0.66350446 0.66350446 0.66815476 0.66815476\n",
      " 0.67596726 0.65978423 0.66815476 0.67150298 0.67150298 0.67150298\n",
      " 0.66815476 0.66759673 0.65978423 0.67261905 0.67466518 0.67150298\n",
      " 0.67150298 0.65531994 0.67466518 0.68377976 0.68712798 0.67801339\n",
      " 0.67801339 0.68247768 0.67020089 0.67857143 0.67987351 0.66573661\n",
      " 0.67596726 0.68768601 0.68768601 0.67857143 0.68638393 0.68247768]\n",
      "\n",
      "Mean F1 Macro for GradientBoosting: \n",
      "[0.62960852 0.61609388 0.61969839 0.60629136 0.60497053 0.62135791\n",
      " 0.62184833 0.60982557 0.60672312 0.62402292 0.63565189 0.60703801\n",
      " 0.63222604 0.61683986 0.61861424 0.61959018 0.6814332  0.67250661\n",
      " 0.67692244 0.67082982 0.67279985 0.67621944 0.67541885 0.68512867\n",
      " 0.67072563 0.68625679 0.66727192 0.67112172 0.67587269 0.66735955\n",
      " 0.67833288 0.67506798 0.6787988  0.69136779 0.68359553 0.68475764\n",
      " 0.68237548 0.67845983 0.6852457  0.68750187 0.68910036 0.70032966\n",
      " 0.69819491 0.68814463 0.69629584 0.68543163 0.68471047 0.68765054\n",
      " 0.63279132 0.63670035 0.64256545 0.63176257 0.63514593 0.6387083\n",
      " 0.6314406  0.65119876 0.63550875 0.63726616 0.6411919  0.62645308\n",
      " 0.63830761 0.63622411 0.64710444 0.62972689 0.64906492 0.64517158\n",
      " 0.64497091 0.651523   0.64495652 0.63527551 0.64187497 0.63976233\n",
      " 0.64929792 0.64517158 0.64638773 0.65261478 0.64929792 0.64559771\n",
      " 0.64454478 0.65183831 0.69624186 0.6954545  0.68226791 0.6980904\n",
      " 0.67796995 0.69499801 0.68347967 0.68943196 0.69843378 0.68748603\n",
      " 0.68437956 0.69580739 0.68289419 0.68790225 0.68696958 0.6921287\n",
      " 0.64409822 0.65552698 0.64919094 0.64624315 0.64521216 0.6460934\n",
      " 0.65244963 0.64654077 0.64840069 0.6411131  0.65290481 0.64406273\n",
      " 0.64000383 0.66149081 0.65181778 0.65027719 0.66016415 0.65598113\n",
      " 0.66669646 0.64883073 0.66016415 0.66438561 0.66416916 0.66327026\n",
      " 0.65677652 0.65997896 0.64575416 0.66259535 0.66591896 0.66438561\n",
      " 0.66416916 0.64504316 0.66173447 0.6744261  0.67924902 0.66929901\n",
      " 0.66636142 0.67420654 0.65977535 0.67097477 0.66674366 0.65444168\n",
      " 0.66452286 0.67933874 0.67850649 0.67049459 0.67910662 0.67476358]\n",
      "\n",
      "Mean Test Accuracy for Decision Trees: \n",
      "[       nan 0.18780781 0.18780781        nan 0.18780781 0.18780781\n",
      "        nan 0.18780781 0.18780781        nan 0.25033033 0.25033033\n",
      "        nan 0.25033033 0.25033033        nan 0.25033033 0.25033033\n",
      "        nan 0.29489489 0.29489489        nan 0.2993994  0.2993994\n",
      "        nan 0.29495495 0.29495495        nan 0.33513514 0.33513514\n",
      "        nan 0.32174174 0.32174174        nan 0.29927928 0.29927928]\n",
      "\n",
      "Balanced Test Accuracy for Decision Trees: \n",
      "[       nan 0.18333333 0.18333333        nan 0.18333333 0.18333333\n",
      "        nan 0.18333333 0.18333333        nan 0.25046296 0.25046296\n",
      "        nan 0.25046296 0.25046296        nan 0.25046296 0.25046296\n",
      "        nan 0.29560185 0.29560185        nan 0.29976852 0.29976852\n",
      "        nan 0.29560185 0.29560185        nan 0.33752104 0.33752104\n",
      "        nan 0.32458965 0.32458965        nan 0.30063131 0.30063131]\n",
      "\n",
      "Mean F1 Macro for Decision Trees: \n",
      "[       nan 0.07941806 0.07941806        nan 0.07941806 0.07941806\n",
      "        nan 0.07941806 0.07941806        nan 0.15208118 0.15208118\n",
      "        nan 0.15208118 0.15208118        nan 0.15208118 0.15208118\n",
      "        nan 0.24248192 0.24248192        nan 0.24747955 0.24747955\n",
      "        nan 0.23855098 0.23855098        nan 0.32343343 0.32343343\n",
      "        nan 0.29766227 0.29766227        nan 0.27659776 0.27659776]\n",
      "\n",
      "Mean Test Accuracy for Random Forests: \n",
      "[0.57142857 0.54464286 0.58035714 0.58482143 0.64285714 0.62946429\n",
      " 0.63392857 0.63839286 0.58482143 0.57589286 0.59375    0.57589286\n",
      " 0.66964286 0.64285714 0.66964286 0.67410714 0.59821429 0.58928571\n",
      " 0.60267857 0.60267857 0.66964286 0.65625    0.67857143 0.66517857\n",
      " 0.60714286 0.60267857 0.58928571 0.60714286 0.65178571 0.66517857\n",
      " 0.66517857 0.65178571]\n",
      "\n",
      "Balanced Test Accuracy for Random Forests: \n",
      "[0.57793899 0.55115327 0.58835565 0.5905878  0.64955357 0.63709077\n",
      " 0.64248512 0.64546131 0.59040179 0.58333333 0.59895833 0.5827753\n",
      " 0.6765253  0.64936756 0.67708333 0.6796875  0.60416667 0.59393601\n",
      " 0.60974702 0.60900298 0.67596726 0.66127232 0.68359375 0.67075893\n",
      " 0.61365327 0.6108631  0.5952381  0.61476935 0.65587798 0.67243304\n",
      " 0.67020089 0.65792411]\n",
      "\n",
      "Mean F1 Macro for Random Forests: \n",
      "[0.56741669 0.53235765 0.57231605 0.57522515 0.63753059 0.62411772\n",
      " 0.62355884 0.62287248 0.57884099 0.57631852 0.59295123 0.56863523\n",
      " 0.66738672 0.63998674 0.66642268 0.67066517 0.58914439 0.57844292\n",
      " 0.59121723 0.59438027 0.66139005 0.65030611 0.67249476 0.66312672\n",
      " 0.59942945 0.59055574 0.57052415 0.59788846 0.65029596 0.65459767\n",
      " 0.664555   0.64753507]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the grid search cross-validation results listing the above mentioned evaluation methods (3)\n",
    "cross_val_resultsGB = grid_searchGradientBoosting.cv_results_\n",
    "cross_val_resultsDT = grid_searchDecisionTree.cv_results_\n",
    "cross_val_resultsRF = grid_searchRandomForest.cv_results_\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Mean Test Accuracy for GradientBoosting: \\n{cross_val_resultsGB['mean_test_accuracy']}\\n\")\n",
    "print(f\"Balanced Test Accuracy for GradientBoosting: \\n{cross_val_resultsGB['mean_test_bal_accuracy']}\\n\")\n",
    "print(f\"Mean F1 Macro for GradientBoosting: \\n{cross_val_resultsGB['mean_test_F1_macro']}\\n\")\n",
    "\n",
    "#DTC\n",
    "print(f\"Mean Test Accuracy for Decision Trees: \\n{cross_val_resultsDT['mean_test_accuracy']}\\n\")\n",
    "print(f\"Balanced Test Accuracy for Decision Trees: \\n{cross_val_resultsDT['mean_test_bal_accuracy']}\\n\")\n",
    "print(f\"Mean F1 Macro for Decision Trees: \\n{cross_val_resultsDT['mean_test_F1_macro']}\\n\")\n",
    "\n",
    "#RFC\n",
    "print(f\"Mean Test Accuracy for Random Forests: \\n{cross_val_resultsRF['mean_test_accuracy']}\\n\")\n",
    "print(f\"Balanced Test Accuracy for Random Forests: \\n{cross_val_resultsRF['mean_test_bal_accuracy']}\\n\")\n",
    "print(f\"Mean F1 Macro for Random Forests: \\n{cross_val_resultsRF['mean_test_F1_macro']}\\n\")\n",
    "\n",
    "#NB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Prediction: \n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1]\n",
      "\n",
      "Dummy Score: \n",
      "0.13839285714285715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use a dummy classifier to identify a simple baseline (i.e., a majority class baseline) so that you can compare your prediction results (3)\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(data_prepared, labelTrainFlat)\n",
    "DummyClassifier(strategy='most_frequent')\n",
    "print(f\"Dummy Prediction: \\n{dummy_clf.predict(data_prepared)}\\n\") \n",
    "print(f\"Dummy Score: \\n{dummy_clf.score(data_prepared, labelTrainFlat)}\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75         6\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.67      0.33      0.44         6\n",
      "           3       0.67      0.29      0.40         7\n",
      "           4       0.78      0.88      0.82         8\n",
      "           5       0.83      0.50      0.62        10\n",
      "           6       0.44      0.57      0.50         7\n",
      "           7       0.62      0.62      0.62         8\n",
      "\n",
      "    accuracy                           0.55        56\n",
      "   macro avg       0.58      0.52      0.52        56\n",
      "weighted avg       0.62      0.55      0.56        56\n",
      "\n",
      "[[6 0 0 0 0 0 0 0]\n",
      " [3 0 0 0 0 0 0 1]\n",
      " [1 1 2 0 0 0 1 1]\n",
      " [0 3 0 2 1 0 1 0]\n",
      " [0 0 0 0 7 0 0 1]\n",
      " [0 2 0 0 1 5 2 0]\n",
      " [0 2 0 0 0 1 4 0]\n",
      " [0 0 1 1 0 0 1 5]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ohenc_test = OneHotEncoder(sparse=False)\n",
    "ohenc_cols_test = ohenc.fit(features_test.drop(['AGE', 'SCHOLARSHIP', 'SALARY', 'MOTHER_EDU', 'FATHER_EDU', '#_SIBLINGS', 'STUDY_HRS', \n",
    "                'READ_FREQ', 'READ_FREQ_SCI', 'IMPACT', 'ATTEND', 'NOTES', 'LISTENS', 'LIKES_DISCUSS',\n",
    "                'CUML_GPA', 'EXP_GPA'], axis=1)).get_feature_names_out()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "missing_cols_from_test = ['MOTHER_JOB_5', 'LIVING_4', 'FATHER_EDU_6']\n",
    "missing_cols_from_train = ['MOTHER_EDU_6']\n",
    "\n",
    "ord_attribs_test = ['AGE', 'SCHOLARSHIP', 'SALARY', 'MOTHER_EDU', 'FATHER_EDU', '#_SIBLINGS', 'STUDY_HRS', \n",
    "                'READ_FREQ', 'READ_FREQ_SCI', 'IMPACT', 'ATTEND', 'NOTES', 'LISTENS', 'LIKES_DISCUSS',\n",
    "                'CUML_GPA', 'EXP_GPA']\n",
    "nom_attribs_test = ['GENDER', 'HS_TYPE', 'WORK', 'ACTIVITY', 'PARTNER', 'TRANSPORT', 'LIVING', 'PARENT_STATUS',\n",
    "                'MOTHER_JOB', 'FATHER_JOB', 'ATTEND_DEPT', 'PREP_STUDY', 'PREP_EXAM', 'CLASSROOM']\n",
    "\n",
    "pipe_cols_test = ['AGE' ,'GENDER_1' ,'GENDER_2' ,'HS_TYPE_1' ,'HS_TYPE_2' ,'HS_TYPE_3', 'SCHOLARSHIP' ,'WORK_1',\n",
    "             'WORK_2' ,'ACTIVITY_1', 'ACTIVITY_2', 'PARTNER_1' ,'PARTNER_2' ,'SALARY', 'TRANSPORT_1',\n",
    "             'TRANSPORT_2', 'TRANSPORT_3' ,'TRANSPORT_4' ,'LIVING_1' ,'LIVING_2', 'LIVING_3',\n",
    "             'MOTHER_EDU', 'FATHER_EDU', '#_SIBLINGS', 'PARENT_STATUS_1' ,'PARENT_STATUS_2', 'PARENT_STATUS_3',\n",
    "             'MOTHER_JOB_1' ,'MOTHER_JOB_2' ,'MOTHER_JOB_3', 'MOTHER_JOB_4' ,'FATHER_JOB_1' , \n",
    "             'FATHER_JOB_2', 'FATHER_JOB_3' ,'FATHER_JOB_4' ,'FATHER_JOB_5', 'STUDY_HRS', 'READ_FREQ',\n",
    "             'READ_FREQ_SCI',  'ATTEND_DEPT_1', 'ATTEND_DEPT_2', 'IMPACT', 'ATTEND','PREP_STUDY_1' ,'PREP_STUDY_2', \n",
    "             'PREP_STUDY_3', 'PREP_EXAM_1', 'PREP_EXAM_2' ,'PREP_EXAM_3' ,'NOTES', 'LISTENS', 'LIKES_DISCUSS', \n",
    "             'CLASSROOM_1' ,'CLASSROOM_2', 'CLASSROOM_3','CUML_GPA', 'EXP_GPA']\n",
    "\n",
    "\n",
    "full_pipeline_test = ColumnTransformer([\n",
    "        (\"Nominal\", OneHotEncoder(), nom_attribs),\n",
    "        (\"Ordinal\", OrdinalEncoder(), ord_attribs)\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "data_prepared_test = pd.DataFrame(full_pipeline_test.fit_transform(features_test),columns=pipe_cols_test, index=features_test.index)\n",
    "missing_cols_df = pd.DataFrame(0, index=np.arange(56), columns=missing_cols_from_test)\n",
    "res = list(set(ohenc_cols).difference(set(ohenc_cols_test)))\n",
    "\n",
    "zero_data = np.zeros(shape=(len(data_prepared_test),1))\n",
    "\n",
    "\n",
    "data_prepared_test.insert(31,\"MOTHER_JOB_5\", zero_data) #Inserting those columns that are not represented in the test data\n",
    "data_prepared_test.insert(21,\"LIVING_4\", zero_data)\n",
    "\n",
    "#data_prepared_test.insert(43,\"FATHER_EDU_6\", zero_data)\n",
    "\n",
    "\n",
    "\n",
    "# obtain predictions on test data using the best model from GridSearchCV (i.e., .best_estimator_) (2)\n",
    "predictions_test = grid_searchGradientBoosting.best_estimator_.predict(data_prepared_test)\n",
    "\n",
    "# generate the classification report and the confusion matrix for test predictions (3)\n",
    "print(classification_report(labels_test.values.ravel(),predictions_test))\n",
    "print(confusion_matrix(labels_test, predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af4e0a0d28143374aa5d305078a03b698686e6b7df811af5a427e46b8cc107ac"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
